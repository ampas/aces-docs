{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ACES Documentation \u00b6 System Documentation \u00b6 Project Organization and Development Procedure \u00b6 Provides details on the organizational and decision making structure to be used in the development of the ACES . Versioning System \u00b6 Describes versioning numbers and format of TransformIDs for components the ACES system. UX Guidelines \u00b6 Provides guidelines on how best to present ACES terminology and concepts within products to end-users. Alternate Viewing Pipeline \u00b6 Describes an alternate approach to implementing and presenting the ACES viewing pipeline. ACES White Point Derivation \u00b6 Describes the derivation of the ACES white point and why the chromaticity coordinates were chosen. System Components \u00b6 Component Names \u00b6 Describes preferred terminology for key ACES component names for ACES 1.0. Input Transforms (IDTs) \u00b6 Describes methods to create Input Transforms (IDTs) for use within ACES . Look Modification Transforms \u00b6 Describes the design, integration and use of Look Modification Transforms. Reference Gamut Compression Specification \u00b6 Specifies a Look Transform to bring pixel values within AP1. Reference Gamut Compression User Guide \u00b6 Describes suggested user workflows for on set, dailies, visual effects, and finishing using the ACES Reference Gamut Compression ( RGC ) Reference Gamut Compression Implementation Guide \u00b6 Implementation guidelines related to the usage of the Reference Gamut Compression. Common LUT Format ( CLF ) Specification \u00b6 Specifies a flexible XML -based file format for color Look-Up Tables ( LUTs ) and other basic image operators. Common LUT Format ( CLF ) Implementation Guide \u00b6 Implementation guidelines related to the usage of the Common LUT Format. ACES Metadata File ( AMF ) Specification \u00b6 Specifies a \u2018sidecar\u2019 XML file intended to exchange the metadata required to recreate ACES viewing pipelines. ACES Metadata File ( AMF ) Implementation Guidelines and Best Practices \u00b6 Implementation guidelines and best practices related to the usage of the ACES Metadata File ( AMF ) in various workflows ACES Encodings \u00b6 ACES 2065-1 \u00b6 Specifies ACES , the fundamental colorimetric encoding in the Academy Color Encoding System. See SMPTE ST 2065-1 ACEScct \u00b6 Defines a logarithmic colorimetric encoding more appropriate for legacy color correction operators. ACEScg \u00b6 Defines a colorimetric encoding appropriate as a working space for use in CGI tools such as compositors, paint and rendering systems. ACEScc \u00b6 Defines a logarithmic colorimetric encoding appropriate for legacy color correction operators. ACESproxy \u00b6 Defines an integer logarithmic colorimetric encoding appropriate for on-set preview and on-set look management applications. Informative Notes (legacy documents) \u00b6 SMPTE standards supercede these legacy documents and links to purchase the standards are included in the next section . Some informative notes on some of the ACES -related SMPTE standards are provided via Technical Bulletins. In most cases, these include the original Academy documents that were modified into the SMPTE standards documents. Academy Color Encoding Specification ( ACES ) \u00b6 Provides background and contextual information on SMPTE ST 2065-1:2012. ACES Image Container File (OpenEXR) \u00b6 Provides background and contextual information on SMPTE ST 2065-4:2013. ADX Image Container File (DPX) \u00b6 Provides background and contextual information on SMPTE ST 268:2003 Am1:2012. APD and ADX \u00b6 Provides background and contextual information related to SMPTE ST 2065-2:2012 and SMPTE ST 2065-3:2012. SMPTE Standards \u00b6 Below are the ACES -related standards documents published through SMPTE to date. Those wishing to implement ACES should adhere to the SMPTE standards. These must be purchased in order to view. SMPTE ST 2065-1 - Academy Color Encoding Specification \u00b6 SMPTE ST 2065-2 - Academy Printing Density (APD) \u2014 Spectral Responsivities, Reference Measurement Device and Spectral Calculation \u00b6 SMPTE ST 2065-3 - Academy Density Exchange Encoding (ADX) \u2014 Encoding Academy Printing Density (APD) Values \u00b6 SMPTE ST 2065-4 - ACES Image Container File Layout \u00b6 SMPTE ST 2065-5 - Material Exchange Format \u2014 Mapping ACES Image Sequences into the MXF Generic Container \u00b6 SMPTE ST 2067-50 - SMPTE Standard - Interoperable Master Format \u2014 Application #5 ACES \u00b6 SMPTE ST 268:2014 \u2013 File Format for Digital Moving Picture Exchange (DPX) \u2013 Amendment 1 \u00b6 [data-md-color-scheme=\"aces-light\"] { --md-typeset-a-color: #OOOOOO;} [data-md-color-scheme=\"slate\"] { --md-typeset-a-color: #FFFFFF;} .icons { color: #e0b700; scale: 0.9; position: relative; top: 2px;} .new-icons { color: #e0b700; scale: 1.3; position: relative; top: 2px; left: 5px;} p { position: relative; top: -10px;} .md-sidebar--secondary .md-nav__list .md-nav__list {display: none}","title":"ACES Documentation"},{"location":"#aces-documentation","text":"","title":"ACES Documentation"},{"location":"#system-documentation","text":"","title":"System Documentation"},{"location":"#project-organization-and-development-procedure","text":"Provides details on the organizational and decision making structure to be used in the development of the ACES .","title":" Project Organization and Development Procedure"},{"location":"#versioning-system","text":"Describes versioning numbers and format of TransformIDs for components the ACES system.","title":" Versioning System"},{"location":"#ux-guidelines","text":"Provides guidelines on how best to present ACES terminology and concepts within products to end-users.","title":" UX Guidelines"},{"location":"#alternate-viewing-pipeline","text":"Describes an alternate approach to implementing and presenting the ACES viewing pipeline.","title":" Alternate Viewing Pipeline"},{"location":"#aces-white-point-derivation","text":"Describes the derivation of the ACES white point and why the chromaticity coordinates were chosen.","title":" ACES White Point Derivation"},{"location":"#system-components","text":"","title":"System Components"},{"location":"#component-names","text":"Describes preferred terminology for key ACES component names for ACES 1.0.","title":" Component Names"},{"location":"#input-transforms-idts","text":"Describes methods to create Input Transforms (IDTs) for use within ACES .","title":" Input Transforms (IDTs)"},{"location":"#look-modification-transforms","text":"Describes the design, integration and use of Look Modification Transforms.","title":" Look Modification Transforms"},{"location":"#reference-gamut-compression-specification","text":"Specifies a Look Transform to bring pixel values within AP1.","title":" Reference Gamut Compression Specification "},{"location":"#reference-gamut-compression-user-guide","text":"Describes suggested user workflows for on set, dailies, visual effects, and finishing using the ACES Reference Gamut Compression ( RGC )","title":" Reference Gamut Compression User Guide "},{"location":"#reference-gamut-compression-implementation-guide","text":"Implementation guidelines related to the usage of the Reference Gamut Compression.","title":" Reference Gamut Compression Implementation Guide "},{"location":"#common-lut-format-clf-specification","text":"Specifies a flexible XML -based file format for color Look-Up Tables ( LUTs ) and other basic image operators.","title":" Common LUT Format (CLF) Specification"},{"location":"#common-lut-format-clf-implementation-guide","text":"Implementation guidelines related to the usage of the Common LUT Format.","title":" Common LUT Format (CLF) Implementation Guide "},{"location":"#aces-metadata-file-amf-specification","text":"Specifies a \u2018sidecar\u2019 XML file intended to exchange the metadata required to recreate ACES viewing pipelines.","title":" ACES Metadata File (AMF) Specification"},{"location":"#aces-metadata-file-amf-implementation-guidelines-and-best-practices","text":"Implementation guidelines and best practices related to the usage of the ACES Metadata File ( AMF ) in various workflows","title":" ACES Metadata File (AMF) Implementation Guidelines and Best Practices "},{"location":"#aces-encodings","text":"","title":"ACES Encodings"},{"location":"#aces-2065-1","text":"Specifies ACES , the fundamental colorimetric encoding in the Academy Color Encoding System. See SMPTE ST 2065-1","title":" ACES 2065-1"},{"location":"#acescct","text":"Defines a logarithmic colorimetric encoding more appropriate for legacy color correction operators.","title":" ACEScct"},{"location":"#acescg","text":"Defines a colorimetric encoding appropriate as a working space for use in CGI tools such as compositors, paint and rendering systems.","title":" ACEScg"},{"location":"#acescc","text":"Defines a logarithmic colorimetric encoding appropriate for legacy color correction operators.","title":" ACEScc"},{"location":"#acesproxy","text":"Defines an integer logarithmic colorimetric encoding appropriate for on-set preview and on-set look management applications.","title":" ACESproxy"},{"location":"#informative-notes-legacy-documents","text":"SMPTE standards supercede these legacy documents and links to purchase the standards are included in the next section . Some informative notes on some of the ACES -related SMPTE standards are provided via Technical Bulletins. In most cases, these include the original Academy documents that were modified into the SMPTE standards documents.","title":"Informative Notes (legacy documents)"},{"location":"#academy-color-encoding-specification-aces","text":"Provides background and contextual information on SMPTE ST 2065-1:2012.","title":" Academy Color Encoding Specification (ACES)"},{"location":"#aces-image-container-file-openexr","text":"Provides background and contextual information on SMPTE ST 2065-4:2013.","title":" ACES Image Container File (OpenEXR)"},{"location":"#adx-image-container-file-dpx","text":"Provides background and contextual information on SMPTE ST 268:2003 Am1:2012.","title":" ADX Image Container File (DPX)"},{"location":"#apd-and-adx","text":"Provides background and contextual information related to SMPTE ST 2065-2:2012 and SMPTE ST 2065-3:2012.","title":" APD and ADX"},{"location":"#smpte","text":"Below are the ACES -related standards documents published through SMPTE to date. Those wishing to implement ACES should adhere to the SMPTE standards. These must be purchased in order to view.","title":"SMPTE Standards"},{"location":"#aces-2065","text":"","title":" SMPTE ST 2065-1 - Academy Color Encoding Specification"},{"location":"#smpte-st-2065-2-academy-printing-density-apd-spectral-responsivities-reference-measurement-device-and-spectral-calculation","text":"","title":" SMPTE ST 2065-2 - Academy Printing Density (APD) \u2014 Spectral Responsivities, Reference Measurement Device and Spectral Calculation"},{"location":"#smpte-st-2065-3-academy-density-exchange-encoding-adx-encoding-academy-printing-density-apd-values","text":"","title":" SMPTE ST 2065-3 - Academy Density Exchange Encoding (ADX) \u2014 Encoding Academy Printing Density (APD) Values"},{"location":"#smpte-st-2065-4-aces-image-container-file-layout","text":"","title":" SMPTE ST 2065-4 - ACES Image Container File Layout"},{"location":"#smpte-st-2065-5-material-exchange-format-mapping-aces-image-sequences-into-the-mxf-generic-container","text":"","title":" SMPTE ST 2065-5 - Material Exchange Format \u2014 Mapping ACES Image Sequences into the MXF Generic Container"},{"location":"#smpte-st-2067-50-smpte-standard-interoperable-master-format-application-5-aces","text":"","title":" SMPTE ST 2067-50 - SMPTE Standard - Interoperable Master Format \u2014 Application #5 ACES"},{"location":"#smpte-st-2682014-file-format-for-digital-moving-picture-exchange-dpx-amendment-1","text":"[data-md-color-scheme=\"aces-light\"] { --md-typeset-a-color: #OOOOOO;} [data-md-color-scheme=\"slate\"] { --md-typeset-a-color: #FFFFFF;} .icons { color: #e0b700; scale: 0.9; position: relative; top: 2px;} .new-icons { color: #e0b700; scale: 1.3; position: relative; top: 2px; left: 5px;} p { position: relative; top: -10px;} .md-sidebar--secondary .md-nav__list .md-nav__list {display: none}","title":" SMPTE ST 268:2014 \u2013 File Format for Digital Moving Picture Exchange (DPX) \u2013 Amendment 1"},{"location":"glossary/","text":"Terms and Definitions \u00b6 A \u00b6 Academy Color Encoding Specification ( ACES ) RGB color encoding for exchange of image data that have not been color rendered, between and throughout production and postproduction, within the Academy Color Encoding System. ACES is specified in SMPTE ST 2065-1. ACES RGB relative exposure values Relative responses to light of the ACES Reference Image Capture Device, determined by the integrated spectral responsivities of its color channels and the spectral radiances of scene stimuli. ACES unity neutral A triplet of ACES RGB relative exposure values all of which have unity magnitude. ACES Metadata File ( AMF ) Metadata \u201csidecar\u201d XML -based file that contains information describing a collection of image files color-managed using the Academy Color Encoding System ( ACES ). ACES Encodings Color encoding specifications specified as part of the Academy Color Encoding System, e.g., ACES2065-1, ACEScc, etc. ACES File Formats Digital data containers specified as part of the Academy Color Encoding System, e.g., ACES Metadata Files, ACES Image Container ( SMPTE ST2065-4), etc. ACES Product Partners Companies that integrate ACES concepts and components into their products and/or services. ACES System Complete set of components that comprise the Academy Color Encoding System. ACES System Release Published ACES System. ACES Transforms Color transformations specified as part of the Academy Color Encoding System, e.g., Reference Rendering Transform ( RRT ), Output Device Transforms ( ODT ), etc. ACES Viewing Transform Combined RRT and ACES Output Device Transform. American Society of Cinematographers Color Decision List ASC CDL A set of file formats for the exchange of basic primary color grading information between equipment and software from different manufacturers. ASC CDL provides for Slope, Offset and Power operations applied to each of the red, green and blue channels and for an overall Saturation operation affecting all three. B \u00b6 C \u00b6 chromatic adaptation process by which the visual mechanism adjusts in response to the radiant energy to which the eyes are exposed. chromaticity property of a color stimulus defined by the ratios of each tristimulus value of the color stimulus to their sum. Color Transform Langage ( CTL ) small open-source programming language, consisting of an interpreter and one or more CLT modules, that has been designed to serve as a building block for digital color management systems. CTL modules (files) files containing Color Transformation Language code. Note: CTL files are the primary documentation for ACES transforms. D \u00b6 DateTime (reference: ISO 8601:2004 ) timestamp format The DateTime is specified in the following form YYYY-MM-DDThh:mm:ss{offset} where: YYYY indicates the year MM indicates the month DD indicates the day T indicates the start of the required time section hh indicates the hour mm indicates the minute ss indicates the second {offset} time zone offset from UTC Note All components are required. Example 2014-11-20T12:24:13-8:00 E \u00b6 Edit Decision List ( EDL ) list used in the post-production process of film editing and video editing containing an ordered sequence of reel and timecode data representing where each video clip can be obtained in order to conform to the final cut. Extensible Markup Language ( XML ) a markup language and file format for storing, transmitting, and reconstructing arbitrary data. It defines a set of rules for encoding documents in a format that is both human-readable and machine-readable F \u00b6 G \u00b6 H \u00b6 I \u00b6 Implementation Transforms ACES System transforms implemented by ACES Product Partners, likely as a Color Look-up Table or as GPU or CPU code. Internet Engineering Task Force ( IETF ) an open standards organization, which develops and promotes voluntary Internet standards, in particular the technical standards that comprise the Internet protocol suite (TCP/IP). J \u00b6 K \u00b6 L \u00b6 Look Transform ( LMT ) Look Modification Transform ( deprecated term ) ACES transform which applies a global look or other modification to scene-referred image data. M \u00b6 N \u00b6 O \u00b6 P \u00b6 Q \u00b6 R \u00b6 Reference Gamut Compression ( RGC ) ACES LMT which compresses scene-referred image data to within the AP1 gamut. Reference Rendering Transform ( RRT ) Core ACES transform that converts scene-referred image data that conforms to SMPTE ST 2065-1:2012 to output-referred image data. RFN technical specification or organizational note published by the Internet Engineering Task Force ( IETF ) S \u00b6 T \u00b6 TransformIDs Transform Identifiers string identifying the ACES transform. Note Please see the ACES System Versioning Specification for more information on the format to use for TransformIDs. U \u00b6 Universal(ly) Unique Identifier ( UUID ) 128-bit label used for information in computer systems published in various standards including ISO /IEC 11578:1996 \"Information technology \u2013 Open Systems Interconnection \u2013 Remote Procedure Call (RPC)\" V \u00b6 W \u00b6 X \u00b6 Y \u00b6 Z \u00b6","title":"Glossary"},{"location":"glossary/#terms-and-definitions","text":"","title":"Terms and Definitions"},{"location":"glossary/#a","text":"Academy Color Encoding Specification ( ACES ) RGB color encoding for exchange of image data that have not been color rendered, between and throughout production and postproduction, within the Academy Color Encoding System. ACES is specified in SMPTE ST 2065-1. ACES RGB relative exposure values Relative responses to light of the ACES Reference Image Capture Device, determined by the integrated spectral responsivities of its color channels and the spectral radiances of scene stimuli. ACES unity neutral A triplet of ACES RGB relative exposure values all of which have unity magnitude. ACES Metadata File ( AMF ) Metadata \u201csidecar\u201d XML -based file that contains information describing a collection of image files color-managed using the Academy Color Encoding System ( ACES ). ACES Encodings Color encoding specifications specified as part of the Academy Color Encoding System, e.g., ACES2065-1, ACEScc, etc. ACES File Formats Digital data containers specified as part of the Academy Color Encoding System, e.g., ACES Metadata Files, ACES Image Container ( SMPTE ST2065-4), etc. ACES Product Partners Companies that integrate ACES concepts and components into their products and/or services. ACES System Complete set of components that comprise the Academy Color Encoding System. ACES System Release Published ACES System. ACES Transforms Color transformations specified as part of the Academy Color Encoding System, e.g., Reference Rendering Transform ( RRT ), Output Device Transforms ( ODT ), etc. ACES Viewing Transform Combined RRT and ACES Output Device Transform. American Society of Cinematographers Color Decision List ASC CDL A set of file formats for the exchange of basic primary color grading information between equipment and software from different manufacturers. ASC CDL provides for Slope, Offset and Power operations applied to each of the red, green and blue channels and for an overall Saturation operation affecting all three.","title":"A"},{"location":"glossary/#b","text":"","title":"B"},{"location":"glossary/#c","text":"chromatic adaptation process by which the visual mechanism adjusts in response to the radiant energy to which the eyes are exposed. chromaticity property of a color stimulus defined by the ratios of each tristimulus value of the color stimulus to their sum. Color Transform Langage ( CTL ) small open-source programming language, consisting of an interpreter and one or more CLT modules, that has been designed to serve as a building block for digital color management systems. CTL modules (files) files containing Color Transformation Language code. Note: CTL files are the primary documentation for ACES transforms.","title":"C"},{"location":"glossary/#d","text":"DateTime (reference: ISO 8601:2004 ) timestamp format The DateTime is specified in the following form YYYY-MM-DDThh:mm:ss{offset} where: YYYY indicates the year MM indicates the month DD indicates the day T indicates the start of the required time section hh indicates the hour mm indicates the minute ss indicates the second {offset} time zone offset from UTC Note All components are required. Example 2014-11-20T12:24:13-8:00","title":"D"},{"location":"glossary/#e","text":"Edit Decision List ( EDL ) list used in the post-production process of film editing and video editing containing an ordered sequence of reel and timecode data representing where each video clip can be obtained in order to conform to the final cut. Extensible Markup Language ( XML ) a markup language and file format for storing, transmitting, and reconstructing arbitrary data. It defines a set of rules for encoding documents in a format that is both human-readable and machine-readable","title":"E"},{"location":"glossary/#f","text":"","title":"F"},{"location":"glossary/#g","text":"","title":"G"},{"location":"glossary/#h","text":"","title":"H"},{"location":"glossary/#i","text":"Implementation Transforms ACES System transforms implemented by ACES Product Partners, likely as a Color Look-up Table or as GPU or CPU code. Internet Engineering Task Force ( IETF ) an open standards organization, which develops and promotes voluntary Internet standards, in particular the technical standards that comprise the Internet protocol suite (TCP/IP).","title":"I"},{"location":"glossary/#j","text":"","title":"J"},{"location":"glossary/#k","text":"","title":"K"},{"location":"glossary/#l","text":"Look Transform ( LMT ) Look Modification Transform ( deprecated term ) ACES transform which applies a global look or other modification to scene-referred image data.","title":"L"},{"location":"glossary/#m","text":"","title":"M"},{"location":"glossary/#n","text":"","title":"N"},{"location":"glossary/#o","text":"","title":"O"},{"location":"glossary/#p","text":"","title":"P"},{"location":"glossary/#q","text":"","title":"Q"},{"location":"glossary/#r","text":"Reference Gamut Compression ( RGC ) ACES LMT which compresses scene-referred image data to within the AP1 gamut. Reference Rendering Transform ( RRT ) Core ACES transform that converts scene-referred image data that conforms to SMPTE ST 2065-1:2012 to output-referred image data. RFN technical specification or organizational note published by the Internet Engineering Task Force ( IETF )","title":"R"},{"location":"glossary/#s","text":"","title":"S"},{"location":"glossary/#t","text":"TransformIDs Transform Identifiers string identifying the ACES transform. Note Please see the ACES System Versioning Specification for more information on the format to use for TransformIDs.","title":"T"},{"location":"glossary/#u","text":"Universal(ly) Unique Identifier ( UUID ) 128-bit label used for information in computer systems published in various standards including ISO /IEC 11578:1996 \"Information technology \u2013 Open Systems Interconnection \u2013 Remote Procedure Call (RPC)\"","title":"U"},{"location":"glossary/#v","text":"","title":"V"},{"location":"glossary/#w","text":"","title":"W"},{"location":"glossary/#x","text":"","title":"X"},{"location":"glossary/#y","text":"","title":"Y"},{"location":"glossary/#z","text":"","title":"Z"},{"location":"guides/amf/","text":"ACES Metadata File Implementation Guidelines and Best Practices \u00b6 Scope \u00b6 This document is a guide that recommends implementation guidelines and best practices related to the usage of the ACES Metadata File ( AMF ) in various workflows. These workflows may involve one or more tools that support the AMF specification and this guide attempts to help both implementers and users in order to facilitate interoperability. References \u00b6 The following standards, specifications, articles, presentations, and texts are referenced in this text: Academy S-2019-001, ACES Metadata File ( AMF ) IETF RFC 4122, A Universally Unique IDentifier ( UUID ) URN Namespace Introduction \u00b6 The Academy Color Encoding System ( ACES ) is a color processing framework that enables the mix of various sources within a standardized color space in order to produce one or more outputs. While ACES is a living framework and is actively developed and adopted, it also comes with various points that can be configured. These points of configuration are either related to the sources used (Input Transforms), a creative look (Look Transforms), the desired outputs (Output Transforms), or the Version Number (i.e. ACES v1.1) of the core transforms built into the ACES system. ACES does not specify these configuration points directly or associate them with actual images or shots during production, and this is the very reason why AMF exists. AMF is the configuration file that allows a precise setup for an ACES pipeline. Besides this basic goal, AMF is also the tool of choice to transmit and exchange configuration parameters in order to ensure consistency within a workflow and across the entire ecosystem of tools that are used within that workflow. Target Audience \u00b6 AMF is a sidecar file specified using the XML markup language, and as such it can be processed by machines and at the same time created/modified by users. This document targets both AMF users and AMF implementers because both groups need the same level of understanding in order to design AMF -enabled workflows and tools that support those workflows. What is AMF \u00b6 AMF is an XML specification that describes the configuration of an ACES color pipeline, together with the various input transforms, look transforms and output transforms. AMF is a \"sidecar\" element, usually accompanying some visual material such as a video file, a sequence of frames, or a whole timeline. In the case of a timeline, more than one AMF file can be used if the timeline requires different configurations of the ACES pipeline. It is also worth mentioning that several AMF files can reference the same visual material. The opposite is equally true as all these visual elements can share a single AMF file or a whole set of them. This of course is entirely dependent on the workflow, and tools implementing AMF should be prepared to deal with this flexibility. In general, the relationship between the visual elements and the AMF files can be described as a \"many to many\" relationship. Why is AMF needed \u00b6 The ACES framework is expanding and becoming richer in terms of input, look, and output transforms. AMF describes the exact list of these different transforms, in the order in which they have been or should be applied to obtain the desired result. graph LR A1[Input Media] --> B(Input Transform) subgraph AMF Complete Processing Path Description B --> C1(Look Transform) C1 --> D1(Output Transform) end A2[ACES Material] ---> C2(Look Transform) subgraph AMF Partial Processing Path Description C2 --> D2(Output Transform) end AMF Processing Path Description This is a powerful feature because it can describe both configurations that must be used to create a specific output, or configurations that have been used to create a specific output. graph TB B1 --> A1(AMF <br/>Look Modification Transform <br/> Chain) B2 --> A1 B3 --> A1 subgraph B1(\"ASC-CDL<br/>or<br/>External LMT<br/>(active)\") B2(\"ASC-CDL<br/>or<br/>External LMT<br/>(disabled)\") B3(\"ASC-CDL<br/>or<br/>External LMT<br/>(active)\") end classDef disabled opacity: 0.5 class B2 disabled Each block in the chain can be an ASC-CDL or an external LUT. Blocks can be enabled or disabled Finally, another feature of AMF is the ability to document a \"change log\" in an ACES color pipeline. This is called the \"archived pipeline\" and will be discussed later in the document. The \u201capplied\u201d attribute \u00b6 Each transform in an AMF can be tagged with the attribute called applied - which indicates whether a transform has already been applied ( applied=true ), in which case the transform has already been baked into the image, or if the transform has not been applied ( applied=false ), in which case the transform should be loaded as part of the viewing pipeline. One use case of this might be when using the ACES Gamut Compression transform, which may be baked into SMPTE ST 2065-1 ACES image data, and it is essential to communicate to downstream software that it has already been applied, as to not double-apply the transform, or invert it if necessary. Lifecycle of AMF \u00b6 This section describes the life cycle of an AMF and how it could be used within each production stage. Camera \u00b6 While on set, AMF could be imported in-camera and used to apply color pipeline settings for video and file output, or exported to a camera card when using a camera\u2019s ACES viewing pipeline. See section 7 for more on cameras reading/writing AMF . Monitor \u00b6 Some professional monitors allow import of LUTs to apply looks in-device. AMF could replace proprietary or uncommon LUT formats for improved interoperability. On-set live grading \u00b6 An AMF may be read by on-set live grading software for the purpose of on-set monitoring and color grading within ACES . If anything is altered within the domain of the pipeline defined in the AMF , a new AMF is created to reflect those modifications. For example, an ACES pipeline is established in an AMF before production, then CDL adjustments are created during production to create an updated AMF accordingly. Dailies \u00b6 In a dailies tool, a pre-created AMF could be read and associated with OCF (Original Camera Files) to apply pipeline settings (for viewing and rendering). This could be done either by manual association or automatically. In the process of creating the dailies, the color pipeline coming from an existing AMF may be modified and updated. AMFs are written out with media to be passed to editorial software. Commonly used interchange files (e.g. EDL or ALE ) can be used to conform AMF files with OCF , see below for more details. Editorial \u00b6 Editorial software can apply pipeline settings provided by AMF (s) when importing media to automatically set up viewing and rendering. VFX \u00b6 Read AMF (s) when importing plates into VFX software and apply pipeline settings for viewing. Given the prevalence of OpenColorIO across VFX software, it is likely that a translation from AMF to OpenColorIO ( OCIO ) would be required. Color Grading \u00b6 When in color grading, AMF could be conformed to a timeline and associated with OCF to apply pipeline settings (for viewing and rendering). These applications should also allow for look development in ACES and subsequent exporting of AMF . Review \u00b6 Review software could automatically apply ACES pipeline settings for viewing purposes by reading AMF (s) when importing media or by manually applying AMF (s) to imported media. Mastering and Archiving \u00b6 Read AMF (s) when importing media and apply pipeline settings for viewing. Consolidate AMF (s) to meet specific archival delivery requirements. Considerations on reading/writing AMF \u00b6 This section outlines various scenarios related to the reading and writing of AMF files. Scenario Read - An AMF is read when importing media and used to populate a color pipeline for viewing and rendering. Write - A new AMF is written in order to be passed along to the next production stage. If a new AMF is done from a previous AMF , the previous pipeline might be archived in the section. RAW Clips AMF does not include any metadata for demosaic settings. Implementations need to ensure that the image is demosaicked to the appropriate color space before the Input Transform defined in the AMF is applied. User input may be required. If software chooses to directly demosaic a RAW image to ACES , the Input Transform defined in the AMF must be ignored. n/a Input Transform Conflict A clip has already been loaded into the software, and an Input Transform is already applied. Default behaviour should be to override that Input Transform with what\u2019s specified in the AMF , but the user should be prompted. n/a Output Transform Conflict If the AMF specifies an Output Transform that is in conflict with the respective shot\u2019s Output Transform, then this conflict must be handled. The default behaviour should be to stick with the project-wide Output Transform, but it may be useful to indicate a conflict to the user. Example: An AMF is generated from a software platform that uses the Rec709_100nits transform, and is then read by a software platform that is using an HDR Output Transform. The Output Transform that was indeed used for viewing should be specified in the AMF . Manual AMF Batch Import/Export Consider the use of commonly used interchange files (e.g. EDL or ALE ) to batch import AMF \u2019s to a timeline. Ideally, the software would allow for a partial import of only the Input, Look, or Output Transforms of a given AMF . When exporting a batch of AMF \u2019s for an entire timeline, consider exporting commonly used interchange files (e.g. EDL or ALE ) to create an association between Clips and the exported AMF files. Inter- AMF Output Transform Conflict If AMF \u2019s are batch imported into a single timeline, and at least two of them have different Output Transforms defined, consider prompting the user if this inconsistency exists, and provide appropriate options to address. This has the assumption that the user will only be using one Output Transform at a time for an entire timeline. n/a Pipeline Override If an AMF has already been applied to a shot, or if project/timeline settings apply, and a subsequent AMF is read for that shot, consider prompting the user before overriding pipeline. Ideally, the software would allow for a partial import of only the Input, Look, or Output Transforms of a given AMF . Consider including multiple AMF transform pipelines by making use of AMF \u2019s aces:archivedPipeline element. Updating Look Transforms n/a Local changes to transforms in the AMF should not affect any other transforms if the pipeline structure doesn\u2019t change, e.g. when only updating CDL values, but none of the other transforms change, the AMF structure should not be changed and only the CDL values should be updated. Any changes to the transform pipeline will result in a new AMF and global values, e.g. the dateTime element, are therefore expected to change. If CLF (s) are used in the pipeline, consider using CLF UUID and/or its hash to make sure that the CLF has not changed. Look Transform Support If an AMF references a Look Transform with a format that the application does not support reading, consider notifying the user that the format is unsupported, so it is clear the error is unrelated to the AMF itself. When producing a new Look Transform for an AMF export, consider defaulting to CLF , a format that ensures high interoperability,, especially for any operations other than ASC CDL . It\u2019s important to consider what to do when using CDL operations vs other grading operations and how these should be reflected in the AMF document: in elaborated pipeline where CDL are \u201cin between\u201d other more sophisticated grading operations, it might be required to let the user identify and decide over what CDL operations should be treated as such and which ones can be baked with other operations into a consolidated CLF Cameras Import AMF in-camera and apply pipeline settings for video and file output. An AMF loaded in camera could specify over SDI how to treat the incoming signal (ie Output Transform) There are reasonable expectations that any in-camera processing, for the foreseeable future, will be done utilizing small 3D LUTs at the highest complexity. Therefore, applications of an ACES pipeline in-camera may be limited in precision. When should a camera generate an AMF ? If a camera generates an AMF , where should it be written? #1 Preferred Method: Embedded in the OCF , e.g.REDCODE RAW R3D #2 Preferred Method: AMF should live in the same directory as its associated clip #3 Preferred Method: * A single folder with all AMF files Metadata Population Parse the AMF for its filename and aces:uuid and write these to the appropriate metadata fields for each clip. If the AMF associated with a clip changes, the value relative to the AMF metadata fields within the editorial software should change and adopt the new values. So when writing commonly used interchange files (e.g. EDL or ALE ) the correspondent values are correct. Applied Tag When reading an AMF file that has the applied=true attribute for a specific transform, the software should NOT apply the transform to the file, since it has already been applied to the image itself. Consider reporting it to the user if applicable (e.g. a \u201chistory\u201d log of the transforms is accessible for each clip) When exporting AMF \u2019s from a timeline of clips that have not been rendered yet, each transform in the AMF should be tagged as applied=false . However, when rendering new files, consider having the ability to export new AMF \u2019s files simultaneously as part of the same deliverable and, in this case, each transform that is actually baked in should be tagged as applied=true in the AMF (e.g. the Input Transform if rendering OpenEXR ACES 2065-1 VFX pulls, or everything when exporting 709 proxies for editorial). Archived Pipelines Consider allowing the user to toggle between different ACES pipelines that are recorded in the aces:archivedPipeline element. Otherwise, aces:archivedPipeline elements should be preserved for any new AMF \u2019s subsequently created for the same shots. If the software is updating a pre-existing AMF , the written AMF should include the appropriate aces:archivedPipeline element. Structure of AMF \u00b6 AMF is a specification based on the XML markup language. It is fully described in Academy Specification S-2019-001 . The specification also comes with an XML Schema that can be used to validate the AMF documents. The XML Schema is publicly available here: https://github.com/ampas/aces-dev/tree/master/formats/amf The guidelines and best practices in this document are provided to help both implementers and users to take full advantage of AMF . It is strongly recommended to use the specification as a reference in order to better understand the concepts described here. AMF document sections \u00b6 AMF documents are mainly divided in 3 sections: aces:amfInfo - this section provides descriptive information about the AMF itself. aces:clipId - this section provides a reference to the visual material ( OCF or rendered images) that this AMF is applicable for. aces:pipeline - this section describes the ACES pipeline configuration. General descriptive information \u00b6 The aces:amfInfo element contains various sub-elements that provide descriptive information about the AMF document but also a mechanism to help identification. More specifically two sub-elements deserve some consideration: aces:dateTime aces:uuid The mandatory aces:dateTime element contains the creation and modification date. The aces:uuid element is optional and is designed to carry a Universally Unique Identifier (also known as Globally Unique Identifier, or GUID on some systems). The Universally Unique Identifier is specified in IETF RFC 4122 as well as other ISO and ITU documents. Both aces:dateTime and aces:uuid elements are not filled in by a human operator but rather automatically generated by the tool used to create the AMF document. AMF naming and identification \u00b6 In general, the most common method that everyone uses to distinguish between two files is by comparing file names and/or their creation and/or modification date in the file system. However, this method quickly reveals itself ineffective when files are exchanged between various computers and operating systems because these file properties can easily be changed without any sort of warning. As explained above, AMF files usually come in large numbers and are moved across various systems and processed by various tools during their life cycle. Because of this situation, a better approach is to make good use of the information contained in the document itself. However, to avoid common pitfalls like overwriting files, the following file naming convention is recommended: AMF files should conform to the following file naming convention: <description>_<date>_<time>.amf <description> should describe the following, if applicable: Purpose: the use case of the AMF file (eg. \u201cdailies\u201d, \u201cSDR_709\u201d, \u201c VFX -Pull\u201d) Clip: Clip ID as in the AMF specification Show Name: Title or other identifiers of the associated show Author: Author of the AMF <date> is the date of creation, using the format YYYY-MM-DD <time> is the time of creation, using the format HHMMSSZ (trailing \u201cZ\u201d indicating \u201cZulu\u201d time, see below) Values for <date> and <time> are determined at the start of the operation that results in the creation of the AMF file and the values are represented using the Coordinated Universal Time ( UTC ) standard. Example: Dailies_ShowName_A002R2EC_2019-01-07_080228Z.amf Using date and time mechanism \u00b6 As mentioned above, the aces:dateTime is a mandatory element and it is defined using the standard XML type xs:dateTime. Because this definition is very flexible, it is strongly recommended for the tools to always use the most explicit form that includes the year, month and day, the time of the day in hours, minutes and seconds as well as the time zone. This practice ensures that the creation and modification dates and times are giving a good indication on the location where the document was created/modified. Using the unique identifier mechanism \u00b6 A more elaborate identification mechanism can also be used, by taking advantage of the aces:uuid element. Since this element is optional, one cannot count on its presence, however it is strongly recommended to use it. When doing so, the UUID becomes a much safer tool to distinguish between to AMF documents. UUIDs are automatically generated and they shall never be hand-crafted. Combining several identification mechanisms \u00b6 In order to improve the identification mechanism, one can combine both the UUID checks and creation/modification times. This might be helpful if two AMF documents contain the same UUID but have different creation/modification dates. In practice, when using dedicated tools to create and manage AMF files, such situations should not occur, but AMF files can still be manually altered. If this is the case, further inspection of the AMF documents can help to distinguish them. Such advanced methods will be discussed later in the document. It is worth mentioning here that there are situations where two or more AMF documents can have the same unique identifier but have different creation dates and time. It is then recommended that tools encountering this situation switch to the most recent version of the AMF document based on the date and time. Informing the user and logging conflicts \u00b6 Because of the large number of AMF documents involved in a workflow, it might not be practical to inform the user of every error encountered. However these errors should be logged by the tools using AMF and options should be offered to select the various identification rules, e.g. unique identifier first (if available), then the creation date and time. Clip information and association \u00b6 As described in the previous sections, AMF can be used with different targets, i.e. single file video clips, image sequences, compositions, etc. This flexibility implies that the AMF specification does not prescribe a specific way to create the connection with the target material. Instead, the specification offers different connection mechanisms via the aces:clipId, an optional structure that in turn contains child elements to help with the handling of the various situations. The first important observation to make is that the aces:clipId element itself is defined as optional. In this context, optional does not mean that the presence or absence of the aces:clipId element does not affect the workflow and how tools that support AMF behave. The term optional must be understood as a switch between two categories of workflow: the first does not connect an AMF file to a specific visual material and the second does connect an AMF file to a specific visual material. Depending on the workflow in use, an implementation must handle the presence or absence correctly and report errors if necessary. Typically, the XML validation only will not be enough to distinguish between a valid AMF file and an invalid one, since the aces:clipId element is optional. In other words, the aces:clipId does not dictate how the AMF document is handled. It is the workflow that dictates the behavior. aces:clipId is not present \u00b6 The absence of the aces:clipId element is important when the connection between the AMF document and the visual material is handled by a higher level protocol. The simplest higher level protocol that comes immediately to mind is the use of the file system and some sort of naming convention. For instance, a folder can contain a video clip and the related AMF file like this: ./myVideoClip.mxf ./myVideoClip.amf In this simple situation, an implementation that can read the the myVideoClip file could also look for a secondary file named myVideoClip.amf and if it is present and if it is a valid AMF document consider that there is a \"connection\" between the two files and act accordingly. While this seems to be a natural thing to do, it is certainly something to avoid. First of all, this kind of \"connection\" would work in a limited number of situations and then it would also prevent more elaborated workflows from existing. Consider the following modified example: ./myVideoClip.mxf ./myVideoClip.mov ./myVideoClip.amf In this variant, it's impossible to guess if myVideoClip.amf is related to myVideoClip.mxf or to myVideoClip.mov or to both files. To solve this problem, the aces:clipId element must be used to establish the desired connection between the AMF document and the correct targeted visual material. A single AMF document can be \"shared\" by multiple video clips or image sequences or even compositions. While it's certainly possible to invent a solution based on the file system naming capabilities via a fixed folder/file structure and naming convention, it is not recommended. In practice, workflows that involve multiple visual material elements, and one or more AMF documents, shared or not, make use of a control file that acts like a database, describing the complex relationships that may exist. This handbook defines the use of AMF in conjunction with some popular commonly used interchange files: Avid Log Exchange ( ALE ) CMX3600 Edit Decision List ( EDL ) The AMF Implementation Group explored the use of AMF with higher level protocols as well and those will eventually be described in a future version of this handbook. A future version may also describe the use of AMF with OpenTimelineIO. aces:clipId is present \u00b6 As briefly described before, the aces:clipId is a complex element, containing the following sub-elements: aces:clipName and one of the following: aces:file aces:sequence aces:uuid All these sub-elements are mandatory when aces:clipId is used, but it's important to remember that aces:sequence, aces:file and aces:uuid cannot coexist. They are mutually excluding each other and therefore are used for specific variants in a workflow. aces:clipName \u00b6 The aces:clipName is used to carry the name of the target visual material element, but not the file name of that element. Typically aces:clipName is the same as the file name but without the file extension or the frame number digits in the case of a file sequence. aces:file \u00b6 The aces:file element is used to carry the actual file name of the target visual material element. It can carry the full absolute path and the file name, a relative path and the file name or simply the file name (base name and extension) of the target visual material element. As it is the case with file names in general, path information and special characters supported or not supported by various file systems must be taken into account. The goal here is not to describe all the possibilities, but rather to recommend some best practices: * If the path (absolute or relative) is used in the file name, it should be limited to cases when the AMF document is only used within a closed system where the rules can be clearly defined. * Special characters or Unicode names can be used, but in general they might be a source of problems. While not forbidden, their use should be tested in the context of the desired workflow to ensure that all the tools and operating systems involved correctly support the selected convention. A good practice however would be to stick with ASCII characters only and avoid using path-like structures in file names. aces:sequence \u00b6 The aces:sequence is similar to aces:file, however it is primarily designed to handle image sequences. Image sequences usually follow a file name pattern and the only difference between two files of the same sequence, is a number which indicates the file's position in the sequence. Moreover, the number is using a fixed number of digits where the unused digits are replaced with zeroes. aces:sequence requires three different attributes to fully define a sequence of files: idx : a special character that the filename pattern uses to represent digits (e.g.#) min : a number that represents the first file in the sequence max : a number that represents the last file in the sequence In other words, min and max define a range of frame numbers and they are both part of the sequence (included). aces:uuid \u00b6 The last method for connecting the AMF document to a visual material element is by using aces:uuid. In this particular case, the connection between the AMF document and the actual visual material element is clearly handled elsewhere and not at the file system level. Various workflows will be described later that make use of the aces:uuid instead of aces:file or aces:sequence. However it's important to note that using UUID is probably the safest method , especially when the workflow is distributed across multiple tools, operating systems and even geographic locations. ACES pipeline configuration \u00b6 The ACES pipeline section is a list of ordered elements that define various steps of the ACES color pipeline. The pipeline is described by the aces:pipeline element. In turn, this element contains a list of sub-elements that describe the configuration of the various color processing stages that exist in the ACES color processing framework. Below is the list of sub-elements that can be found in the aces:pipeline element: aces:pipelineInfo aces:inputTransform aces:lookTransform aces:outputTransform These elements must appear in this exact order. Although these steps are described separately, this does not imply that a system has to process all pixels in a frame of visual material one step at a time. Some systems might do it while some others might need to crunch the various processing steps into a single transform, typically a 3D Lookup Table (3D LUT ). Moreover a system may choose to optimize the processing of the various steps, depending on the given situation. The only constraint is that the color processing must follow the steps in the order described above. aces:pipelineInfo \u00b6 The aces:pipelineInfo element extends the set of properties found in the AMF document identification by adding an element to define the ACES system version. The role of this element is to specify the ACES system version targeted by this AMF file in order to produce the correct output. The system version is a crucial piece of information as it allows us to achieve interoperability and archivability. The aces:pipelineInfo element can (and should) be used to validate the AMF document itself. The following sections that describe the use of the input transforms, look transforms and output transforms mention the use of transform identifiers. Transform identifiers are also \"tagged\" with the ACES system version to ensure a match between the pipeline system version and the various transform identifiers. The validity of transform identifiers within the scope of a given ACES system version will be described later in a dedicated section. aces:inputTransform \u00b6 This element defines the input transform that is optionally applied to the source material referenced by aces:clipId. The input transforms can be either standard transforms defined within the ACES framework or custom transforms. Custom transforms can be referenced by their transform ID or referenced as external files/resources. Standard transforms can only be referenced by their transform ID. graph BT B1(ACES Input Transform Identifier) --> A1(AMF Input Transform) B2(Custom Input Transform Identifier) --> A1 B3(\"External Input Transform (e.g. CLF)\") --> A1 AMF Input Transform Support AMF can describe one Input Transform as an identifier or external reference An important observation must be made here: the aces:inputTransform is entirely optional. This implies that an AMF document can work in different environments, i.e with sources made of raw material, color pre-processed material and ACES only material. These different use cases will be discussed later in this document. If an aces:inputTransform element is present, then it must also define the \"applied\" attribute that will allow an AMF -aware tool to know if the input transform is provided for information purposes only or if it needs to be executed. aces:lookTransform \u00b6 This element is repeated for every step that defines a custom color processing in the ACES color space (e.g. color grading). There are 3 kinds of look transforms: Standard transforms defined within the ACES framework (such as Gamut Compression) \u25cb Standard transforms can only be referenced by their transform id. Embedded ASC - CDL transforms Embedded ASC - CDL transforms carry their parameters within the file and do not rely on any external information. External transforms stored in various formats ( ASC CDL XML , CLF , etc) External transforms can be referenced by either a unique ID or by a file name, described later in this document. aces:lookTransform elements are optional, and therefore AMF documents do not mandate any color processing beyond the processing provided by the ACES color processing framework. If an aces:lookTransform element is present, then it must also define the \"applied\" attribute that will allow an AMF -aware tool to know if the look transform is provided for information purposes only or if it needs to be executed. aces:outputTransform \u00b6 Finally, this element closes the list and defines both the RRT and ODT (or a combined Output Transform) to use in order to produce a presentable result. The RRT and ODT can be either specified independently of each other: <aces:outputTransform> <aces:referenceRenderingTransform> <aces:transformId>urn:ampas:aces:transformId:v1.5:RRT.a1.0.3</aces:transformId> </aces:referenceRenderingTransform> <aces:outputDeviceTransform> <aces:transformId>urn:ampas:aces:transformId:v1.5:ODT.Academy.P3D60_48nits.a1.0.3</aces:transformId> </aces:outputDeviceTransform> </aces:outputTransform> or combined: <aces:outputTransform> <aces:transformId>urn:ampas:aces:transformId:v1.5:RRTODT.Academy.Rec2020_1000nits_15nits_ST2084.a1.1.0</aces:transformId> </aces:outputTransform> The RRT and ODT (as well as the combined versions) are standard color transforms defined within the ACES framework. AMF & external LMT referencing rules \u00b6 Using <aces:file> \u00b6 The simplest way to reference external LMTs is to use the aces:file element. However, some care must be taken, depending on the workflow and also on the system or device generating the AMF document. The aces:file element is defined as an XML standard type called xs:anyURI. This type allows a very large set of possibilities by using the Uniform Resource Identifier (URI) syntax: file access on a local or remote file system, HTTP or FTP access and much more. All of these possibilities are identified by a scheme, which is a predefined syntax to allow unambiguous interpretation of the URI. Although there are situations where this might not be possible.This document will mainly focus on the file access on computer file systems or embedded file systems (e.g. in-camera). File access is accomplished by the use of the file:// scheme as a prefix to the file location. It is assumed that in a file system centric workflow, the omission of the file:// scheme means that the URI is the actual file name of the external resource, i.e. the LMT . This is probably the most common use. Resolving the file location by the means of the file name may still be problematic, especially because of how various file systems identify disks or volumes. In order to simplify the file name resolution, the following rules are recommended: Avoid the use absolute file names, i.e. file names that contain the full path from the root of the disk or volume Avoid using external LMTs in folders that exist at a higher level in the file system hierarchy than the location of the AMF document Avoid the use of \"current path\" and \"one level up\" path segments as they might not be interpreted correctly by the systems and/or devices that need to work with the AMF document and its externally referenced resources. Example: For an AMF file with the following location: C:\\MyAMFDocuments\\myAMF.amf The external resources, i.e. LMTs, should be located either at the same level, like this: C:\\MyAMFDocuments\\myAMF.amf C:\\MyAMFDocuments\\myLookTransform.clf or in a sub-folder like this: C:\\MyAMFDocuments\\myAMF.amf C:\\MyAMFDocuments\\myAMFLooks\\myLookTransform_First.clf C:\\MyAMFDocuments\\myAMFLooks\\myLookTransform_Second.clf In addition to the recommendations listed above, it is also highly recommended to avoid deep hierarchies for the sub-folders as these can easily cause trouble when the files are moved to a file system with limitations on the file path length. If the external resources cannot be stored in the same folder as the AMF document or in sub-folders relative to the AMF document's location, then the system/device working with the AMF document should provide some user interface means to allow the selection of the location. If automation, without user intervention, is desired, the system/device should provide a configuration file to specify the location. File name characters \u00b6 As stated before, modern file systems are very permissive in terms of file naming. Moreover, most systems have either no limit on the file name length or a very large limit that exceeds easily most of the use cases. Taking advantage of these file system features might not be a good practice though. These limitations differ among the file systems in use and migrating files from one file system to another might result in errors or even truncated file names. In order to avoid problems at the file system level, consider following these rules: Keep files name lengths under 128 characters, file name extension included Restrict the file name extension to 3 characters Use only alphabetical characters for the file name extension Use the native or recommended file name extension for the external resource (e.g. CLF or clf for the Common LUT Format) File naming conventions \u00b6 AMF does not impose a strict file naming convention on the external resources. However it is also highly recommended that a proper and meaningful one is adopted when naming those resources. Proper file naming conventions not only ease the inspection of the files in a file system but also can provide a better reading when displayed in the graphical user interface of the system/device used to manage them. Since these systems/devices can have a limited display room, short names should be considered. Retrieving external LMTs via HTTP \u00b6 The resources identified by a URI using the \"http\" or \"https\" schemes can be retrieved as the response to a GET request to the URI. When working with CLF -based LMTs, care must be taken to clearly indicate the content type in the HTTP headers. For instance AMF and CLF are XML -based specifications and HTTP allows the content type to signal XML in many different ways. Two popular ones are: text/xml application/xml These should be preferred in a HTTP transaction when working with AMF and CLF . HTTP transactions can require authentication in order to access the AMF and the LMTs. Authentication and encryption topics are outside the scope of this document. Nevertheless it's important to consider these issues in a workflow that is distributed around various locations as not all systems/devices support the HTTP security features Using <aces:uuid> \u00b6 CLF ProcessList root element shall have the id attribute set with the sameUUID, e.g: AMF <aces:uuid>urn:uuid:1258F89C-0ED7-4A79-0E2-36F97E8FF9F1</aces:uuid> CLF <ProcessList xmlns=\"urn:AMPAS:CLF:v3.0\" id=\"urn:uuid:1258F89C-0ED7-4A79-B0E2-36F97E8FF9F1\" compCLFversion=\"3.0\"> </ProcessList> The CLF files can be located anywhere and the product supporting AMF + CLF must provide the configuration options to locate the CLFassets, or,search for the CLF files in the local folder for the corresponding CLF files\u2022recursive search in subfolders should be supported (option) Annex \u00b6 Avid Log Exchange ( ALE ) support \u00b6 The Avid Log Exchange ( ALE ) format supports custom metadata elements through the definition of dedicated columns in the ALE table. In order to support AMF linkage through ALE , the following columns are defined: AMF_UUID AMF_NAME These two columns enable the linkage of AMF files, independently for every clip listed in the ALE file. Both AMF_UUID and AMF_NAME are defined as optional. The linkage rules are described below. AMF_UUID \u00b6 The AMF_UUID column shall be used to convey the AMF UUID from the amf:Info/uuid element. The format of the column entries must use the canonical textual representation, the 16 octets of a UUID are represented as 32 hexadecimal (base-16) digits, displayed in 5 groups separated by hyphens, in the form 8-4-4-4-12 for a total of 36 characters (32 alphanumeric characters and 4 hyphens): afe122be-59d3-4360-ad69-33c10108fa7a The AMF_UUID column is optional. AMF_NAME \u00b6 AMF_NAME shall be used to convey the AMF file name located in the same folder as the .ale source file: clip_001.amf The AMF_NAME is optional. When present, it should indicate the file name of the AMF document related to the clip. The AMF file must reside locally in the same folder as the ALE file. No sub-folder structure is permitted. While AMF files can have any name, it is recommended to follow the restrictions imposed by the ALE Specification, i.e. to use the UNC Path syntax. Linkage Rules \u00b6 Since both AMF_UUID and AMF_NAME are optional, there are four possible combinations that can occur: AMF_UUID and AMF_NAME are both absent: In this case, no AMF file can be associated with the clip and is treated like a regular ALE file AMF_UUID is present and AMF_NAME is absent: In this case the host product must look for the corresponding AMF files into a database, using the UUID as a key to match the AMF file and the corresponding clip. Please note that the word \"database\" does not imply any specific implementation. This feature many not be supported by the host product AMF_UUID is absent and AMF_NAME is present: In this case, the AMF_NAME column contains file names for AMF files that should be located at the same level in the file system (i.e. same folder) as the ALE file, or in a subfolder. The linkage is based on the file name and the UUID of the AMF files (if present) is ignored AMF_UUID and AMF_NAME are both present: In this case, the host product can select between the methods described in 2) and 3). However, it is recommended to rely on the UUID in priority. The host product can provide an option to select the matching rule ( UUID or file name). It is desirable to also provide a matching rule that checks both the UUID and file name. Remarks \u00b6 Since the ALE file can reference a large number of clips, it is recommended that the host product presents the issues encountered during the linkage and validation process as a log. ALE files can carry inline ASC parameters. When using AMF with ALEs, the inline ASC parameters should be absent to avoid confusion, or ignored if present. AMF files can have an optional aces:clipId element that is used to identify the clip that the AMF is related to. The aces:clipId element can carry a reference using different methods (e.g. file name, UUID , etc). It is strongly recommended that the clip identification method used in AMF correlates with the method used in the ALE files (e.g. file name). If the same AMF file is shared by multiple clips, it is recommended to avoid the use of aces:clipId or ignore it. A validation process can log any differences and present the results to the user of the product/tool processing the ALE + AMF files Edit Decision List ( EDL ) support \u00b6 The CMX3600 Edit Decision List ( EDL ) format supports custom extensions through the definition of dedicated directives following the edit statements in the decision list. In order to support AMF linkage through EDL , the following directives are defined: AMF_UUID AMF_NAME These two directives enable the linkage of AMF files, independently for every clip listed in the EDL file. Both AMF_UUID and AMF_NAME are defined as optional. The linkage rules are described below. AMF_UUID \u00b6 The AMF_UUID column shall be used to convey the AMF UUID from the amf:Info/uuid element. The format of the column entries must use the canonical textual representation, the 16 octets of a UUID are represented as 32 hexadecimal (base-16) digits, displayed in 5 groups separated by hyphens, in the form 8-4-4-4-12 for a total of 36 characters (32 alphanumeric characters and 4 hyphens): afe122be-59d3-4360-ad69-33c10108fa7a The AMF_UUID column is optional. When present, it should indicate a path to the AMF file that is relative to the folder where the ALE file is located. The path hierarchy MUST not contain the parent folder or local folder distinguished values, i.e. \"..\" and \".\" to avoid any confusion. The path and AMF file name must use characters from the set a-z, A-Z, 0-9, - (dash), _ (underscore) and \".\". No path segment shall use more than 128 characters and the total length shall not exceed 1024 characters. AMF_NAME \u00b6 AMF_NAME shall be used to convey the AMF file name located in the same folder as the .edl source file: clip_001.amf The AMF_NAME is optional. When present, it should indicate the file name of the AMF document related to the clip. The AMF file must reside locally in the same folder as the EDL file. No sub-folder structure is permitted. While AMF file can have any name, it is recommended to use the same base name as the clip file that the AMF document relates to. Moreover to ensure portability across file systems and operating systems it is recommended to use characters from the set a-z, A-Z, 0-9, - (dash), _ (underscore) and \".\". The AMF file name should use no more than 1024 characters. Linkage Rules \u00b6 Since both AMF_UUID and AMF_NAME are optional, there are four possible combinations that can occur: AMF_UUID and AMF_NAME are both absent In this case, no AMF file can be associated with the clip AMF_UUID is present and AMF_NAME is absent In this case the host product must look for the corresponding AMF files into a database, using the UUID as a key to match the AMF file and the corresponding clip. Please note that the word \"database\" does not imply any specific implementation. This feature many not be supported by the host product AMF_UUID is absent and AMF_NAME is present In this case, the AMF_NAME column contains file names for AMF files that should be located at the same level in the file system (i.e. same folder) as the EDL file, or in a subfolder. The linkage is based on the file name and the UUID of the AMF files (if present) is ignored AMF_UUID and AMF_NAME are both present In this case, the host product can select between the methods described in 2) and 3). However, it is recommended to rely on the UUID in priority. The host product can provide an option to select the matching rule ( UUID or file name). It is desirable to also provide a matching rule that checks both the UUID and file name. EDL event example \u00b6 ... 010 Clip1 V C 05:40:12:18 05:40:14:09 01:00:29:16 01:00:31:07 * AMF_NAME clip_001.amf * AMF_UUID afe122be-59d3-4360-ad69-33c10108fa7a ... Remarks \u00b6 Since each entry in the EDL file can use any of the combinations of AMF_UUID and AMF_NAME described above, it is recommended that the host product presents the issues encountered during the linkage and validation process as a log. EDL files can carry inline ASC parameters. When using AMF with EDLs, the inline ASC parameters should be absent to avoid confusion, or ignored if present. AMF files can have an optional aces:clipId element that is used to identify the clip that the AMF is related to. The aces:clipId element can carry a reference using different methods (e.g. file name, UUID , etc). It is strongly recommended that the clip identification method used in AMF correlates with the method used in the EDL files (e.g. file name). If the same AMF file is shared by multiple clips, it is recommended to avoid the use of aces:clipId or ignore it. A validation process can log any differences and present the results to the user of the product/tool processing the EDL + AMF files. @import \"../../stylesheets/sections.css\"","title":"Index"},{"location":"guides/amf/#aces-metadata-file-implementation-guidelines-and-best-practices","text":"","title":"ACES Metadata File Implementation Guidelines and Best Practices"},{"location":"guides/amf/#scope","text":"This document is a guide that recommends implementation guidelines and best practices related to the usage of the ACES Metadata File ( AMF ) in various workflows. These workflows may involve one or more tools that support the AMF specification and this guide attempts to help both implementers and users in order to facilitate interoperability.","title":"Scope"},{"location":"guides/amf/#references","text":"The following standards, specifications, articles, presentations, and texts are referenced in this text: Academy S-2019-001, ACES Metadata File ( AMF ) IETF RFC 4122, A Universally Unique IDentifier ( UUID ) URN Namespace","title":"References"},{"location":"guides/amf/#introduction","text":"The Academy Color Encoding System ( ACES ) is a color processing framework that enables the mix of various sources within a standardized color space in order to produce one or more outputs. While ACES is a living framework and is actively developed and adopted, it also comes with various points that can be configured. These points of configuration are either related to the sources used (Input Transforms), a creative look (Look Transforms), the desired outputs (Output Transforms), or the Version Number (i.e. ACES v1.1) of the core transforms built into the ACES system. ACES does not specify these configuration points directly or associate them with actual images or shots during production, and this is the very reason why AMF exists. AMF is the configuration file that allows a precise setup for an ACES pipeline. Besides this basic goal, AMF is also the tool of choice to transmit and exchange configuration parameters in order to ensure consistency within a workflow and across the entire ecosystem of tools that are used within that workflow.","title":"Introduction"},{"location":"guides/amf/#target-audience","text":"AMF is a sidecar file specified using the XML markup language, and as such it can be processed by machines and at the same time created/modified by users. This document targets both AMF users and AMF implementers because both groups need the same level of understanding in order to design AMF -enabled workflows and tools that support those workflows.","title":"Target Audience"},{"location":"guides/amf/#what-is-amf","text":"AMF is an XML specification that describes the configuration of an ACES color pipeline, together with the various input transforms, look transforms and output transforms. AMF is a \"sidecar\" element, usually accompanying some visual material such as a video file, a sequence of frames, or a whole timeline. In the case of a timeline, more than one AMF file can be used if the timeline requires different configurations of the ACES pipeline. It is also worth mentioning that several AMF files can reference the same visual material. The opposite is equally true as all these visual elements can share a single AMF file or a whole set of them. This of course is entirely dependent on the workflow, and tools implementing AMF should be prepared to deal with this flexibility. In general, the relationship between the visual elements and the AMF files can be described as a \"many to many\" relationship.","title":"What is AMF"},{"location":"guides/amf/#why-is-amf-needed","text":"The ACES framework is expanding and becoming richer in terms of input, look, and output transforms. AMF describes the exact list of these different transforms, in the order in which they have been or should be applied to obtain the desired result. graph LR A1[Input Media] --> B(Input Transform) subgraph AMF Complete Processing Path Description B --> C1(Look Transform) C1 --> D1(Output Transform) end A2[ACES Material] ---> C2(Look Transform) subgraph AMF Partial Processing Path Description C2 --> D2(Output Transform) end AMF Processing Path Description This is a powerful feature because it can describe both configurations that must be used to create a specific output, or configurations that have been used to create a specific output. graph TB B1 --> A1(AMF <br/>Look Modification Transform <br/> Chain) B2 --> A1 B3 --> A1 subgraph B1(\"ASC-CDL<br/>or<br/>External LMT<br/>(active)\") B2(\"ASC-CDL<br/>or<br/>External LMT<br/>(disabled)\") B3(\"ASC-CDL<br/>or<br/>External LMT<br/>(active)\") end classDef disabled opacity: 0.5 class B2 disabled Each block in the chain can be an ASC-CDL or an external LUT. Blocks can be enabled or disabled Finally, another feature of AMF is the ability to document a \"change log\" in an ACES color pipeline. This is called the \"archived pipeline\" and will be discussed later in the document.","title":"Why is AMF needed"},{"location":"guides/amf/#the-applied-attribute","text":"Each transform in an AMF can be tagged with the attribute called applied - which indicates whether a transform has already been applied ( applied=true ), in which case the transform has already been baked into the image, or if the transform has not been applied ( applied=false ), in which case the transform should be loaded as part of the viewing pipeline. One use case of this might be when using the ACES Gamut Compression transform, which may be baked into SMPTE ST 2065-1 ACES image data, and it is essential to communicate to downstream software that it has already been applied, as to not double-apply the transform, or invert it if necessary.","title":"The \u201capplied\u201d attribute"},{"location":"guides/amf/#lifecycle-of-amf","text":"This section describes the life cycle of an AMF and how it could be used within each production stage.","title":"Lifecycle of AMF"},{"location":"guides/amf/#camera","text":"While on set, AMF could be imported in-camera and used to apply color pipeline settings for video and file output, or exported to a camera card when using a camera\u2019s ACES viewing pipeline. See section 7 for more on cameras reading/writing AMF .","title":"Camera"},{"location":"guides/amf/#monitor","text":"Some professional monitors allow import of LUTs to apply looks in-device. AMF could replace proprietary or uncommon LUT formats for improved interoperability.","title":"Monitor"},{"location":"guides/amf/#on-set-live-grading","text":"An AMF may be read by on-set live grading software for the purpose of on-set monitoring and color grading within ACES . If anything is altered within the domain of the pipeline defined in the AMF , a new AMF is created to reflect those modifications. For example, an ACES pipeline is established in an AMF before production, then CDL adjustments are created during production to create an updated AMF accordingly.","title":"On-set live grading"},{"location":"guides/amf/#dailies","text":"In a dailies tool, a pre-created AMF could be read and associated with OCF (Original Camera Files) to apply pipeline settings (for viewing and rendering). This could be done either by manual association or automatically. In the process of creating the dailies, the color pipeline coming from an existing AMF may be modified and updated. AMFs are written out with media to be passed to editorial software. Commonly used interchange files (e.g. EDL or ALE ) can be used to conform AMF files with OCF , see below for more details.","title":"Dailies"},{"location":"guides/amf/#editorial","text":"Editorial software can apply pipeline settings provided by AMF (s) when importing media to automatically set up viewing and rendering.","title":"Editorial"},{"location":"guides/amf/#vfx","text":"Read AMF (s) when importing plates into VFX software and apply pipeline settings for viewing. Given the prevalence of OpenColorIO across VFX software, it is likely that a translation from AMF to OpenColorIO ( OCIO ) would be required.","title":"VFX"},{"location":"guides/amf/#color-grading","text":"When in color grading, AMF could be conformed to a timeline and associated with OCF to apply pipeline settings (for viewing and rendering). These applications should also allow for look development in ACES and subsequent exporting of AMF .","title":"Color Grading"},{"location":"guides/amf/#review","text":"Review software could automatically apply ACES pipeline settings for viewing purposes by reading AMF (s) when importing media or by manually applying AMF (s) to imported media.","title":"Review"},{"location":"guides/amf/#mastering-and-archiving","text":"Read AMF (s) when importing media and apply pipeline settings for viewing. Consolidate AMF (s) to meet specific archival delivery requirements.","title":"Mastering and Archiving"},{"location":"guides/amf/#considerations-on-readingwriting-amf","text":"This section outlines various scenarios related to the reading and writing of AMF files. Scenario Read - An AMF is read when importing media and used to populate a color pipeline for viewing and rendering. Write - A new AMF is written in order to be passed along to the next production stage. If a new AMF is done from a previous AMF , the previous pipeline might be archived in the section. RAW Clips AMF does not include any metadata for demosaic settings. Implementations need to ensure that the image is demosaicked to the appropriate color space before the Input Transform defined in the AMF is applied. User input may be required. If software chooses to directly demosaic a RAW image to ACES , the Input Transform defined in the AMF must be ignored. n/a Input Transform Conflict A clip has already been loaded into the software, and an Input Transform is already applied. Default behaviour should be to override that Input Transform with what\u2019s specified in the AMF , but the user should be prompted. n/a Output Transform Conflict If the AMF specifies an Output Transform that is in conflict with the respective shot\u2019s Output Transform, then this conflict must be handled. The default behaviour should be to stick with the project-wide Output Transform, but it may be useful to indicate a conflict to the user. Example: An AMF is generated from a software platform that uses the Rec709_100nits transform, and is then read by a software platform that is using an HDR Output Transform. The Output Transform that was indeed used for viewing should be specified in the AMF . Manual AMF Batch Import/Export Consider the use of commonly used interchange files (e.g. EDL or ALE ) to batch import AMF \u2019s to a timeline. Ideally, the software would allow for a partial import of only the Input, Look, or Output Transforms of a given AMF . When exporting a batch of AMF \u2019s for an entire timeline, consider exporting commonly used interchange files (e.g. EDL or ALE ) to create an association between Clips and the exported AMF files. Inter- AMF Output Transform Conflict If AMF \u2019s are batch imported into a single timeline, and at least two of them have different Output Transforms defined, consider prompting the user if this inconsistency exists, and provide appropriate options to address. This has the assumption that the user will only be using one Output Transform at a time for an entire timeline. n/a Pipeline Override If an AMF has already been applied to a shot, or if project/timeline settings apply, and a subsequent AMF is read for that shot, consider prompting the user before overriding pipeline. Ideally, the software would allow for a partial import of only the Input, Look, or Output Transforms of a given AMF . Consider including multiple AMF transform pipelines by making use of AMF \u2019s aces:archivedPipeline element. Updating Look Transforms n/a Local changes to transforms in the AMF should not affect any other transforms if the pipeline structure doesn\u2019t change, e.g. when only updating CDL values, but none of the other transforms change, the AMF structure should not be changed and only the CDL values should be updated. Any changes to the transform pipeline will result in a new AMF and global values, e.g. the dateTime element, are therefore expected to change. If CLF (s) are used in the pipeline, consider using CLF UUID and/or its hash to make sure that the CLF has not changed. Look Transform Support If an AMF references a Look Transform with a format that the application does not support reading, consider notifying the user that the format is unsupported, so it is clear the error is unrelated to the AMF itself. When producing a new Look Transform for an AMF export, consider defaulting to CLF , a format that ensures high interoperability,, especially for any operations other than ASC CDL . It\u2019s important to consider what to do when using CDL operations vs other grading operations and how these should be reflected in the AMF document: in elaborated pipeline where CDL are \u201cin between\u201d other more sophisticated grading operations, it might be required to let the user identify and decide over what CDL operations should be treated as such and which ones can be baked with other operations into a consolidated CLF Cameras Import AMF in-camera and apply pipeline settings for video and file output. An AMF loaded in camera could specify over SDI how to treat the incoming signal (ie Output Transform) There are reasonable expectations that any in-camera processing, for the foreseeable future, will be done utilizing small 3D LUTs at the highest complexity. Therefore, applications of an ACES pipeline in-camera may be limited in precision. When should a camera generate an AMF ? If a camera generates an AMF , where should it be written? #1 Preferred Method: Embedded in the OCF , e.g.REDCODE RAW R3D #2 Preferred Method: AMF should live in the same directory as its associated clip #3 Preferred Method: * A single folder with all AMF files Metadata Population Parse the AMF for its filename and aces:uuid and write these to the appropriate metadata fields for each clip. If the AMF associated with a clip changes, the value relative to the AMF metadata fields within the editorial software should change and adopt the new values. So when writing commonly used interchange files (e.g. EDL or ALE ) the correspondent values are correct. Applied Tag When reading an AMF file that has the applied=true attribute for a specific transform, the software should NOT apply the transform to the file, since it has already been applied to the image itself. Consider reporting it to the user if applicable (e.g. a \u201chistory\u201d log of the transforms is accessible for each clip) When exporting AMF \u2019s from a timeline of clips that have not been rendered yet, each transform in the AMF should be tagged as applied=false . However, when rendering new files, consider having the ability to export new AMF \u2019s files simultaneously as part of the same deliverable and, in this case, each transform that is actually baked in should be tagged as applied=true in the AMF (e.g. the Input Transform if rendering OpenEXR ACES 2065-1 VFX pulls, or everything when exporting 709 proxies for editorial). Archived Pipelines Consider allowing the user to toggle between different ACES pipelines that are recorded in the aces:archivedPipeline element. Otherwise, aces:archivedPipeline elements should be preserved for any new AMF \u2019s subsequently created for the same shots. If the software is updating a pre-existing AMF , the written AMF should include the appropriate aces:archivedPipeline element.","title":"Considerations on reading/writing AMF"},{"location":"guides/amf/#structure-of-amf","text":"AMF is a specification based on the XML markup language. It is fully described in Academy Specification S-2019-001 . The specification also comes with an XML Schema that can be used to validate the AMF documents. The XML Schema is publicly available here: https://github.com/ampas/aces-dev/tree/master/formats/amf The guidelines and best practices in this document are provided to help both implementers and users to take full advantage of AMF . It is strongly recommended to use the specification as a reference in order to better understand the concepts described here.","title":"Structure of AMF"},{"location":"guides/amf/#amf-document-sections","text":"AMF documents are mainly divided in 3 sections: aces:amfInfo - this section provides descriptive information about the AMF itself. aces:clipId - this section provides a reference to the visual material ( OCF or rendered images) that this AMF is applicable for. aces:pipeline - this section describes the ACES pipeline configuration.","title":"AMF document sections"},{"location":"guides/amf/#general-descriptive-information","text":"The aces:amfInfo element contains various sub-elements that provide descriptive information about the AMF document but also a mechanism to help identification. More specifically two sub-elements deserve some consideration: aces:dateTime aces:uuid The mandatory aces:dateTime element contains the creation and modification date. The aces:uuid element is optional and is designed to carry a Universally Unique Identifier (also known as Globally Unique Identifier, or GUID on some systems). The Universally Unique Identifier is specified in IETF RFC 4122 as well as other ISO and ITU documents. Both aces:dateTime and aces:uuid elements are not filled in by a human operator but rather automatically generated by the tool used to create the AMF document.","title":"General descriptive information"},{"location":"guides/amf/#clip-information-and-association","text":"As described in the previous sections, AMF can be used with different targets, i.e. single file video clips, image sequences, compositions, etc. This flexibility implies that the AMF specification does not prescribe a specific way to create the connection with the target material. Instead, the specification offers different connection mechanisms via the aces:clipId, an optional structure that in turn contains child elements to help with the handling of the various situations. The first important observation to make is that the aces:clipId element itself is defined as optional. In this context, optional does not mean that the presence or absence of the aces:clipId element does not affect the workflow and how tools that support AMF behave. The term optional must be understood as a switch between two categories of workflow: the first does not connect an AMF file to a specific visual material and the second does connect an AMF file to a specific visual material. Depending on the workflow in use, an implementation must handle the presence or absence correctly and report errors if necessary. Typically, the XML validation only will not be enough to distinguish between a valid AMF file and an invalid one, since the aces:clipId element is optional. In other words, the aces:clipId does not dictate how the AMF document is handled. It is the workflow that dictates the behavior.","title":"Clip information and association"},{"location":"guides/amf/#aces-pipeline-configuration","text":"The ACES pipeline section is a list of ordered elements that define various steps of the ACES color pipeline. The pipeline is described by the aces:pipeline element. In turn, this element contains a list of sub-elements that describe the configuration of the various color processing stages that exist in the ACES color processing framework. Below is the list of sub-elements that can be found in the aces:pipeline element: aces:pipelineInfo aces:inputTransform aces:lookTransform aces:outputTransform These elements must appear in this exact order. Although these steps are described separately, this does not imply that a system has to process all pixels in a frame of visual material one step at a time. Some systems might do it while some others might need to crunch the various processing steps into a single transform, typically a 3D Lookup Table (3D LUT ). Moreover a system may choose to optimize the processing of the various steps, depending on the given situation. The only constraint is that the color processing must follow the steps in the order described above.","title":"ACES pipeline configuration"},{"location":"guides/amf/#amf-external-lmt-referencing-rules","text":"","title":"AMF &amp; external LMT referencing rules"},{"location":"guides/amf/#using-acesfile","text":"The simplest way to reference external LMTs is to use the aces:file element. However, some care must be taken, depending on the workflow and also on the system or device generating the AMF document. The aces:file element is defined as an XML standard type called xs:anyURI. This type allows a very large set of possibilities by using the Uniform Resource Identifier (URI) syntax: file access on a local or remote file system, HTTP or FTP access and much more. All of these possibilities are identified by a scheme, which is a predefined syntax to allow unambiguous interpretation of the URI. Although there are situations where this might not be possible.This document will mainly focus on the file access on computer file systems or embedded file systems (e.g. in-camera). File access is accomplished by the use of the file:// scheme as a prefix to the file location. It is assumed that in a file system centric workflow, the omission of the file:// scheme means that the URI is the actual file name of the external resource, i.e. the LMT . This is probably the most common use. Resolving the file location by the means of the file name may still be problematic, especially because of how various file systems identify disks or volumes. In order to simplify the file name resolution, the following rules are recommended: Avoid the use absolute file names, i.e. file names that contain the full path from the root of the disk or volume Avoid using external LMTs in folders that exist at a higher level in the file system hierarchy than the location of the AMF document Avoid the use of \"current path\" and \"one level up\" path segments as they might not be interpreted correctly by the systems and/or devices that need to work with the AMF document and its externally referenced resources. Example: For an AMF file with the following location: C:\\MyAMFDocuments\\myAMF.amf The external resources, i.e. LMTs, should be located either at the same level, like this: C:\\MyAMFDocuments\\myAMF.amf C:\\MyAMFDocuments\\myLookTransform.clf or in a sub-folder like this: C:\\MyAMFDocuments\\myAMF.amf C:\\MyAMFDocuments\\myAMFLooks\\myLookTransform_First.clf C:\\MyAMFDocuments\\myAMFLooks\\myLookTransform_Second.clf In addition to the recommendations listed above, it is also highly recommended to avoid deep hierarchies for the sub-folders as these can easily cause trouble when the files are moved to a file system with limitations on the file path length. If the external resources cannot be stored in the same folder as the AMF document or in sub-folders relative to the AMF document's location, then the system/device working with the AMF document should provide some user interface means to allow the selection of the location. If automation, without user intervention, is desired, the system/device should provide a configuration file to specify the location.","title":"Using &lt;aces:file&gt;"},{"location":"guides/amf/#file-name-characters","text":"As stated before, modern file systems are very permissive in terms of file naming. Moreover, most systems have either no limit on the file name length or a very large limit that exceeds easily most of the use cases. Taking advantage of these file system features might not be a good practice though. These limitations differ among the file systems in use and migrating files from one file system to another might result in errors or even truncated file names. In order to avoid problems at the file system level, consider following these rules: Keep files name lengths under 128 characters, file name extension included Restrict the file name extension to 3 characters Use only alphabetical characters for the file name extension Use the native or recommended file name extension for the external resource (e.g. CLF or clf for the Common LUT Format)","title":"File name characters"},{"location":"guides/amf/#file-naming-conventions","text":"AMF does not impose a strict file naming convention on the external resources. However it is also highly recommended that a proper and meaningful one is adopted when naming those resources. Proper file naming conventions not only ease the inspection of the files in a file system but also can provide a better reading when displayed in the graphical user interface of the system/device used to manage them. Since these systems/devices can have a limited display room, short names should be considered.","title":"File naming conventions"},{"location":"guides/amf/#retrieving-external-lmts-via-http","text":"The resources identified by a URI using the \"http\" or \"https\" schemes can be retrieved as the response to a GET request to the URI. When working with CLF -based LMTs, care must be taken to clearly indicate the content type in the HTTP headers. For instance AMF and CLF are XML -based specifications and HTTP allows the content type to signal XML in many different ways. Two popular ones are: text/xml application/xml These should be preferred in a HTTP transaction when working with AMF and CLF . HTTP transactions can require authentication in order to access the AMF and the LMTs. Authentication and encryption topics are outside the scope of this document. Nevertheless it's important to consider these issues in a workflow that is distributed around various locations as not all systems/devices support the HTTP security features","title":"Retrieving external LMTs via HTTP"},{"location":"guides/amf/#using-acesuuid","text":"CLF ProcessList root element shall have the id attribute set with the sameUUID, e.g: AMF <aces:uuid>urn:uuid:1258F89C-0ED7-4A79-0E2-36F97E8FF9F1</aces:uuid> CLF <ProcessList xmlns=\"urn:AMPAS:CLF:v3.0\" id=\"urn:uuid:1258F89C-0ED7-4A79-B0E2-36F97E8FF9F1\" compCLFversion=\"3.0\"> </ProcessList> The CLF files can be located anywhere and the product supporting AMF + CLF must provide the configuration options to locate the CLFassets, or,search for the CLF files in the local folder for the corresponding CLF files\u2022recursive search in subfolders should be supported (option)","title":"Using &lt;aces:uuid&gt;"},{"location":"guides/amf/#annex","text":"","title":"Annex"},{"location":"guides/amf/#avid-log-exchange-ale-support","text":"The Avid Log Exchange ( ALE ) format supports custom metadata elements through the definition of dedicated columns in the ALE table. In order to support AMF linkage through ALE , the following columns are defined: AMF_UUID AMF_NAME These two columns enable the linkage of AMF files, independently for every clip listed in the ALE file. Both AMF_UUID and AMF_NAME are defined as optional. The linkage rules are described below.","title":"Avid Log Exchange (ALE) support"},{"location":"guides/amf/#edit-decision-list-edl-support","text":"The CMX3600 Edit Decision List ( EDL ) format supports custom extensions through the definition of dedicated directives following the edit statements in the decision list. In order to support AMF linkage through EDL , the following directives are defined: AMF_UUID AMF_NAME These two directives enable the linkage of AMF files, independently for every clip listed in the EDL file. Both AMF_UUID and AMF_NAME are defined as optional. The linkage rules are described below.","title":"Edit Decision List (EDL) support"},{"location":"guides/clf/","text":"@import \"../../stylesheets/sections.css\" Common LUT Format ( CLF ) Implementation Guide \u00b6 Introduction \u00b6 Look-up tables, or LUTs , are a common method for communicating color transformations. Many software and hardware providers develop LUT formats uniquely designed for use in their systems. Since these formats were designed to work in specific use cases, they often prove inadequate for interchangeability between applications or systems. To further complicate matters, some LUT formats use the same file extensions which make them appear to be compatible when they are not. If there are already a dozen or more confusing LUT formats, why should you as a developer consider adding support for yet another one? While the myriad LUT formats already available are fundamentally useful in theory, each lacks one or more features that can be critical in meeting the demands of today\u2019s sophisticated workflows. Existing formats can lack the quality, versatility, and metadata required to meet the demands of modern systems. The Common LUT Format ( CLF ) provides flexibility to enclose transforms from simple to complex. Due to a lack of interchangeability of color transforms between tools, LUTs are frequently abused as a catch-all. Even simple color-space transformations, such as the application of a matrix or a logarithmic shaper function are often \u201cbaked\u201d to crude LUT formats resulting in unfortunate losses in precision. As a solution, CLF allows for a range of common mathematical operators to be specified precisely, in addition to supporting traditional 1D- and 3D- LUTs in the file. Because CLF files are floating-point capable, extremely flexible, and well documented, they are an excellent candidate for use in modern workflows. CLFs are also ideal for archival purposes because the format is well-specified and documented. There is also a high-quality, open source implementation freely available on GitHub. Format Comparison Table \u00b6 Features/Formats CLF 3dl Adobe (Iridas) cube Resolve cube Truelight cube Cinespace cube ASC CDL Imageworks spi3d ICC Profile Provider Academy / ASC Discreet Adobe Blackmagic Filmlight Rising Sun ASC Imageworks ICC Maintained public documentation \u2705 \u274c \u2705 \u2705 \u2705 \u274c \u2705 \u274c \u2705 Implementation guide \u2705 \u274c \u274c \u274c \u274c \u274c \u2705 \u274c \u2705 Allows shaper LUT \u2705 \u274c \u274c \u2705 \u2705 \u2705 \u274c \u274c \u2705 Is not limited to log or video data on input \u2705 \u274c \u274c \u2705 \u2705 \u2705 \u274c \u274c \u274c Unconstrained ordering of processing elements \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u274c Floating-point table values \u2705 \u274c \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 Rich metadata \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u2705 Test suite provided \u2705 \u274c \u274c \u274c \u274c \u274c \u2705 \u274c \u2705 Text-based \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u274c Can define operations in linear floating-point space \u2705 \u274c \u274c \u274c \u274c \u274c \u2705 \u274c \u2705 GUID support \u2705 \u274c \u274c \u274c \u274c \u274c \u2705 \u274c \u2705 Supports mathematical operators \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u274c Target Audience \u00b6 This document is primarily intended for application developers who want to add CLF support to their product. It defines requirements, tests, and provides recommendations that, if followed, will lead to robust support for CLF . Implementers who follow the guidance in this document can have confidence that their product is implementing the specification correctly. The document may also be of interest to those using CLF to author transforms and who want to understand how the CLFs will be used by applications. This guide should be read in conjunction with the CLF Specification (v 3.0) . Note The specification was previously referred to by its document number - \"S-2014-006\". Although the spec had \"2014\" in the name, the document has been updated more recently than that. Version 3 of CLF was introduced with the release of ACES 1.2 in 2020 and the most recent editorial updates were in 2021. The current version of the specification now lives at the above link. A Quick Introduction to CLF \u00b6 Below is a basic example of a simple CLF file. Despite the word ' LUT ' in the name of the format, these very simple examples do not contain any type of LUT whatsoever. Instead, the CLF is being used to communicate a set of ASC CDL adjustments ( Example 1 ), and encapsulate a YCbCr to RGB conversion ( Example 2 ). There are a few key points that these examples demonstrate: CLF is an XML document and therefore conforms to the requirements of any XML document. There is one ProcessList , which can contain any number of ProcessNodes . (A ProcessNode is an operator such as a Matrix or LUT3D .) A CLF may or may not contain \u201c LUTs \u201d (despite the name). Some parts are optional and others are required. CLF provides a richer metadata model than other LUT formats - it\u2019s not just numbers. Good metadata is highly encouraged and helps make the CLF file self-documenting. Every CLF must have a unique id attribute. The bit-depth attributes control formatting but not precision. Color coding for the following two examples: red is required blue is optional green are comments Example 1: \u00b6 ASC CDL Implementation < ?xml version=\"1.0\" encoding=\"UTF-8\"? > <!-- Required: XML Version and Encoding declaration --> <!-- Required: ProcessList element with \u2018id\u2019 and \u2018compCLFversion\u2019 --> <!-- name and xmlns are optional --> < ProcessList compCLFversion =\"3.0\" id =\"b4cca59a-9428-49c0-8e91-868718c4e526\" name =\"FwdNoClamp style\" xmlns =\"urn:AMPAS:CLF:v3.0\"> < Description >CDL with FwdNoClamp style</ Description > < ASC_CDL id =\"clf/ctf no-clamp fwd\" inBitDepth =\"10i\" outBitDepth =\"8i\" style =\"FwdNoClamp\"> < SOPNode > < Slope > 1.000000 1.000000 0.800000</ Slope > < Offset >-0.020000 0.000000 0.150000</ Offset > < Power > 1.050000 1.150000 1.400000</ Power > </ SOPNode > < SatNode > < Saturation >0.750000</ Saturation > </ SatNode > </ ASC_CDL > </ ProcessList > Example 2: \u00b6 BT.709 YCbCr (SMPTE/legal range) to RGB (full range) <?xml version=\"1.0\" encoding=\"UTF-8\"? > <!-- Line above is required: XML Version and Encoding declaration --> <!-- Required: ProcessList element with \u2018id\u2019 and \u2018compCLFversion\u2019 --> < ProcessList id =\"0befc138-3757-45f0-a080-83bebb77baf2\" compCLFversion =\"3.0\"> <!-- Optional: ProcessList Description --> < Description >BT.709 YCbCr (legal) to RGB (full)</ Description > <!-- Optional: InputDescriptor / OutputDescriptor --> < InputDescriptor >YCbCr</ InputDescriptor > < OutputDescriptor >RGB</ OutputDescriptor > <!-- Required: One or more ProcessNode elements --> <!-- inBitDepth and OutBitDepth are required, id is optional --> <!-- If in/outBitDepth values are different, the scale factor between them must also be applied to the matrix coefficients! --> < Matrix id =\"815ebbac-550a-453b-a1e6-bf93779fc9c8\" inBitDepth =\"32f\" outBitDepth =\"32f\"> <!-- Optional: ProcessNode description --> < Description >Input offsets for legal range luma and color difference channels</ Description > <!-- White space formatting is recommended, but optional --> <!-- Array element is required for a Matrix ProcessNode --> < Array dim =\"3 4\"> <!-- when dim=\u201d3 4\u201d, the 4th column is offset terms --> 1.0 0.0 0.0 -0.0625 0.0 1.0 0.0 -0.5 0.0 0.0 1.0 -0.5 </ Array > </ Matrix > <!-- Additional ProcessNodes are applied in order --> < Matrix id =\"deceda6e-8fee-471a-8599-fa513c17f3cf\" inBitDepth =\"32f\" outBitDepth =\"32f\"> < Description >BT.709 YCbCr to RGB matrix</ Description > < Array dim =\"3 3\"> 1.16893193493151 0.000000000000000 1.799743966238840 1.16893193493151 -0.214081616673236 -0.534991005624129 1.16893193493151 2.120653355189730 -0.000000000000000 </ Array > </ Matrix > </ ProcessList > Open Source Example Implemention \u00b6 As you explore CLF and work to implement it into your product(s), it may be helpful to refer to some existing tools that already provide full CLF functionality. The tools described here are included in the open source project OpenColorIO ( OCIO ) v2. More details and the full installation process for OCIO can be found at https://www.opencolorio.org . ociochecklut \u00b6 The command-line utility ociochecklut can be used to load a CLF file and process an RGB triplet through the CLF file. It will report any errors that are encountered in parsing the file. If no RGB triplet is provided to process through the CLF file, then a list of the ProcessNodes contained in the LUT are returned. This tool is installed as part of OCIO v2. Here is sample output using the CLF in the example section (assuming it is saved as a file called 709_ycbcr-to-rgb.clf ): Summarizing the contents of the CLF : $ ociochecklut 709_ycbcr-to-rgb.clf Transform operators: <MatrixTransform direction=forward, fileindepth=32f, fileoutdepth=32f, matrix=1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1, offset=-0.0625 -0.5 -0.5 0> <MatrixTransform direction=forward, fileindepth=32f, fileoutdepth=32f, matrix=1.16893193493151 0 1.79974396623884 0 1.16893193493151 -0.214081616673236 -0.534991005624129 0 1.16893193493151 2.12065335518973 -0 0 0 0 0 1, offset=0 0 0 0> Evaluating the RGB value [0.5, 0.4, 0.3]: $ ociochecklut 709_ycbcr-to-rgb.clf 0.5 0.4 0.3 0.1514589 0.6398141 0.2993424 ocioconvert \u00b6 The command-line utility ocioconvert can be used to apply a CLF file to an image. To apply a CLF file, use the --lut option. A variety of image file formats are supported. This tool is installed as a part of OCIO v2, although it first requires installation of OpenImageIO. Processing the input image syntheticChart.01.exr to the output image output_image.exr through the CLF from the previous example: $ ocioconvert --lut 709_ycbcr-to-rgb.clf syntheticChart.01.exr output_image.exr ociomakeclf \u00b6 The command-line utility ociomakeclf will convert any LUT format supported by OpenColorIO into CLF format. The --csc option may be used to create an ACES Look Transform that is compatible with the ACES Metadata File ( AMF ). This tool is installed as a part of OCIO v2. Convert the LUT oldLUT.3dl to CLF format: $ ociomakeclf oldLUT.3dl oldLUT.clf Convert the look LUT acescctLUT.3dl that expects and produces ACEScct values to an ACES Look Transform in CLF format that expects and produces ACES2065-1 values: $ ociomakeclf acescctLUT.3dl LMT.clf --csc ACEScct Minimum Requirements \u00b6 Introduction \u00b6 The products anticipated to implement CLF can be categorized into two broad categories: one for final production-level finished images and one for preview/proxy images. Due to the fundamental differences in the products, different requirements are provided for the two categories. Finishing Tier \u00b6 The primary category of products, dubbed the Finishing Tier , includes software implementations that have the logic and processing power available to parse and apply ProcessNode operations using floating-point calculations and in sequential order. Finishing Tier products provide the highest quality image processing and have the tightest tolerances, prioritizing accuracy in computation results. Finishing Tier products should be used to create images when the highest image fidelity is required in pipelines utilizing CLF files. Minimum Requirements \u00b6 Products in the Finishing Tier category shall: Pass all the Read Tests Pass the Finishing Tier Apply Tests In addition to the minimum requirements, Finishing Tier products should review the \" Writing CLFs \" section and conform their CLF implementation to those recommendations wherever possible. Preview Tier \u00b6 The second category of implementations are described as Preview Tier devices. These are products that, due to limited processing power or technical constraints, cannot implement a CLF ProcessList exactly and instead require that CLF files be \u201dbaked\u201d or collapsed into a simpler representation (for example, a single 3D- LUT ). Hardware devices such as on-set LUT boxes would be an example of devices that might fall into this category. As the name implies, Preview Tier products are suitable for creating images such as for on-set viewing, where the requirements for accuracy and/or flexibility are lower than for the Finishing Tier. CLF is designed as a modern LUT format that can handle floating-point input and output pixels. However, the current ecosystem of devices still includes many products that work primarily on integer-encoded signals (e.g. HD-SDI and HDMI video) and do not support floating-point image data, including scene-linear encodings such as ACES2065-1. These types of devices would fall in the Preview Tier and CLF may be used to encapsulate any of the LUTs that are currently used in such devices. But there is no expectation that these devices will be able to accurately process other CLFs that contain transforms expecting scene-linear inputs or outputs. Note that although the processing requirements are lower for the Preview Tier, the read requirements are not. In other words, even Preview Tier devices must be able to read all of the files in the test suite. But as described in the section \" Applying CLFs \", if a Preview Tier device detects ProcessNodes that it does not support, there are two options: Inform the user of this situation and do not attempt to process the file. Attempt to bake the CLF down into a representation supported by the device. The user should be given some indication that they are seeing an approximation of the original CLF . Minimum Requirements \u00b6 Products in the Preview Tier category shall: Pass all the Read Tests Pass the Preview Tier Apply test Reading CLFs \u00b6 This section describes the general requirements for parsing CLF files, the provided test suite, and the steps for validating an implementation using the test suite. General Parsing Requirements \u00b6 Requirements: \u00b6 Version Support Implementations are expected to support v3 of the CLF Specification . Backwards compatibility for versions prior to v3 is optional. Error Handling An implementation must check that a file is valid, and if not, issue an error or warning to the user hinting at what the problem is. The tool ociochecklut ( described above ) provides good examples of the types of errors that could be issued when illegal syntax is detected. Metadata reading An implementation must (at a minimum) be able to display to the user the contents of these key metadata fields: Top-level ProcessList Description elements InputDescriptor , OutputDescriptor Precision and formatting of numeric values Implementations must be able to read at least 32-bit float precision, though 64-bit precision is desirable for ProcessNodes other than LUT1D and LUT3D . Note that the CLF specification defines the numeric values as \u201cxs:float\u201d type, that is, XML Schema floats. Parsers should be able to handle all of the details of this format (e.g., integers without a decimal point, missing leading 0 on decimal values, the presence of a leading \u201c+\u201d, etc.). Note that an integer is a legal xs:float. Recommendations \u00b6 XML is designed to be extensible, and XML files often contain data that was not defined in the specification. However, the desire for extensibility must be balanced against the need to detect erroneous content. On occasion, unrecognized XML elements may be detected. In those instances, the following logic is recommended: If the unrecognized element is at the ProcessNode level (in other words, the top level of the ProcessList ), it should produce an error, or at least a warning. If the unrecognized element is within a ProcessNode , a warning should be issued. If the unrecognized element is within the Info block, it may be ignored. CLF File Test Suite \u00b6 A number of test files are provided for implementers to test their system and demonstrate that their implementation can robustly handle all features of CLF v3. The tests provided in the OpenColorIO repository on Github include both legal and illegal test files. The file name and description in each file identifies what the file is testing. The test files confirm that each ProcessNode is functioning per the CLF specification. For ProcessNodes that allow for different styles or parameters, either separate test files or single test files with multiple ProcessNode variations are provided to check that all styles and parameters are functional. Standard files are expected to be processed without error. A number of \"illegal\" test files with various syntax errors are also provided to test the error handling capability of implementations. Illegal files should not be processed and the system should generate an appropriate error message. Test Procedure \u00b6 Download the OpenColorIO repository from GitHub at the URL: https://github.com/AcademySoftwareFoundation/OpenColorIO If you are not familiar with Git, that\u2019s fine. Simply click on the green button that says Code and select \u201cDownload ZIP\u201d. Unzip this file on your computer and you will have all of the test files. The test files are in the directory: OpenColorIO/tests/data/files/clf You may refer to a description of each test file in Annex B . For each legal test file: Read the file into your product and verify that it loads successfully. For each illegal test file (these are the files in the clf/illegal subdirectory): Read the file into your product and ensure that the user is notified that it is not a legal CLF file. Ideally, the nature of the problem should be communicated to the user. Verify that none of these files load successfully. They should not result in a processed image. If an implementation needs to pass through the unprocessed image, it should communicate clearly to the user in some other way that there was an error. Applying CLFs \u00b6 General \u00b6 For CLF to be useful, it is important that different products output the same results when applying the same CLF to the same input. This section describes the different expectations for Finishing Tier and Preview Tier products. Each category has their own metric and defined tolerances. Finishing Tier \u00b6 Tolerances \u00b6 The Finishing Tier is intended to cover software-based implementations such as products for tasks including color correction and compositing. It is expected that these implementations will use floating-point math to apply the contents of the CLF , without converting it into a significantly different representation. Hence fairly tight tolerances may be expected. A CLF may be used to apply arbitrary color space conversions and so the input and output images may be in arbitrary color spaces, including video, logarithmic, and scene-linear color encodings. Both integer and wide-range floating-point pixel values are expected. Video and logarithmic encodings are typically sufficiently perceptually uniform that a simple absolute error metric such as (actual \u2013 aim) may be used. However, scene-linear encodings require a tolerance that is tighter for dark colors and looser for bright colors - in other words, a relative rather than absolute metric. This is due to the approximately logarithmic nature of human color perception (although the metric is actually computed per channel). When comparing an aim and actual value, a basic relative error metric has the form: (actual \u2013 aim) / aim However this can become overly sensitive when the values being compared become very small. In the limit, when the aim value is zero, the result is either infinity or NaN. Therefore it is useful to use a \u201csafe-guarded relative error metric\u201d that places a lower bound on the denominator: actual \u2013 aim) / max(aim, lower_bound) . This effectively transitions the error metric from being a relative error metric for bright and normal colors to an absolute error metric when approaching a certain noise floor determined by the lower_bound constant. A reasonable lower_bound constant for images in ACES2065-1 color space would be 0.1. It is also necessary to handle the case where the aim value may be negative, in which case the final error metric becomes: abs(actual \u2013 aim) / max(abs(aim), 0.1) <= 0.002 This is essentially a relative tolerance of +/\u2013 one part in 500 above 0.1 and an absolute tolerance of +/\u2013 0.0002 below 0.1. It is expected that implementations in the Finishing Tier will be using floating-point software calculations and the processing will be applied this way regardless of whether the color encodings involved are video, logarithmic, or scene-linear. Since relative tolerances are well-suited to verifying floating-point math, the safe-guarded relative error metric will be used for all Finishing Tier tolerances even though this may be perceptually either too tight or too loose when processing video or logarithmic pixel values. Above the lower bound transition, the tolerance for implementations in the Finishing Tier is a relative error of plus or minus one part in 500. For comparison, half-float numbers are spaced at a relative distance of one part in 1024. (In the literature on the subject of floating-point math, this distance is called a \u201cunit of least precision,\u201d or ULP.) So the tolerance for the metric is only slightly more loose than the precision imposed by the storage of images as half-float OpenEXR files. To validate the tolerance, testing was conducted using various processing modes in OpenColorIO. For example, various forms of CPU optimization were applied and the results were compared to the unoptimized reference version. These included optimizations such as concatenating adjacent matrices and approximating standard library logarithm and power functions with faster but less precise versions. Likewise, processing on the GPU was compared to the CPU reference version. The test image that was used is the one described in Annex A, so it sampled the full range of half-float numbers. The fact that all of these processing variations passed the specified error tolerance indicates that it should be an achievable performance level for a wide range of products. Test Procedure \u00b6 The collection of test CLF files are included in the OpenColorIO repository, as described in Annex B . Process the source image (whose contents are described in Annex A ) through your implementation for each of the CLFs described in Annex C . The processed reference frames to be used for comparison may be downloaded as described in Annex C , or you may generate them yourself using the steps described in Annex K The command-line application oiiotool , which is installed as a component of OpenImageIO, can be used to compare pixels between two images and evaluate the metric specified in this section. A Python script for doing this is provided with OpenColorIO. Here are the steps for how to install and run it: Install OpenImageIO. Download the OpenColorIO source code from the URL: https://github.com/AcademySoftwareFoundation/OpenColorIO Unzip the downloaded source code package. In a shell, cd to the directory where the OpenColorIO source code was unzipped, and then cd into the sub-directory share/clf . This directory contains the Python script. In the shell, type: $ python compare_clf_test_frames.py <PATH-TO-REFERENCE-IMAGES> <PATH-TO-ACTUAL-IMAGES> replacing the two items in brackets with the path to the downloaded reference images and the path to your implementation's actual images. The script iterates over the images in the directory and prints the oiiotool command being run. It will then print either 'Test passed' or 'Test failed' after each command and then at the end will summarize with 'All tests passed' or 'These tests failed' with a list of the failed images. Alternate Test Procedure \u00b6 Implementers may also choose to use other tools or implement their own tools to compare pixel values and calculate the metrics. In that case, proceed as follows to compare your actual images to the aim reference images described in Annex C : For each CLF identified in the Finishing Tier test list in Annex C : Use your implementation to process the test frame through each legal CLF file. Calculate the error metric: abs(actual \u2013 aim) / max(abs(aim), 0.1) Verify that: max error <= 0.002 no Infinity or NaN values are created Preview Tier \u00b6 LUT Baking \u00b6 Preview Tier devices/implementations typically are not able to handle the full flexibility of the CLF processing model. If the contents of the CLF correspond to what the device may natively apply, then it is reasonable to expect fairly tight processing tolerances. However, if the CLF contains many ops that must be converted (or \"baked\") into some other representation in order to be applied in device hardware, then it may be unreasonable to demand the same level of performance. Different tolerances would need to be established for each CLF in the test suite depending on the contents and complexity of each CLF and on the details of how it is baked. Therefore, the current version of this guide only tests the ability to process a single LUT3D (e.g. a baked result, not the baking process itself). So all Preview Tier devices must at least handle the LUT3D apply test but implementers will need to decide how to handle CLFs that are more complicated. One approach is to simply inform the user that the CLF contains operators that cannot be processed by that implementation. Another approach is to attempt to bake the CLF into a form that the implementation is able to process. Annex E provides an introduction to the topic of baking. Implementations should notify users if their CLF is being baked into a significantly different structure in order to be processed by the device. (Simple adjustments such as concatenating adjacent matrices into a single matrix do not fall into this category, but combining multiple operators into a single LUT3D certainly does.) Implementers are strongly advised to document the CLF structures that they are able to apply exactly, without need of baking. This would allow users to plan their processing accordingly in order to make best use of the device. Advanced users will be able to generate CLFs in order to obtain the best accuracy possible, given the restrictions. Tolerances \u00b6 The Preview Tier is intended to cover devices such as on set LUT boxes that work on live SDI video signals. These devices are intended to process video or logarithmic encodings and typically do not handle floating-point pixel values. Therefore, a simple absolute error metric may be used. Integer values should be normalized to [0,1] by dividing by the maximum integer value (e.g., 1023, 4095, 65535), yielding an absolute error metric applied to normalized values: \\[ {\\text{abs}(actual \u2013 aim) <= 0.002} \\] This is essentially a tolerance of +/\u2013 two 10-bit code values, if applied to a 10-bit signal, or equivalently +/\u2013 eight 12-bit code values, if applied to a 12-bit signal, etc. Test Procedure \u00b6 The process of verification for the Preview Tier is to check for correct implementation of a LUT3D with tetrahedral interpolation using an integer test image. For the CLF identified in the Preview Tier test list in Annex D : Use your implementation to process the Preview Tier DPX source image (see Annex D ) and produce an integer DPX result. Compare your result to the DPX reference frame provided (see Annex D ), and calculate the error metric described in the preceding paragraphs: If using OpenImageIO, the command would be: $ oiiotool <aim-image> <actual-image> --absdiff --rangecheck 0,0,0 .002,.002,.002 -o /tmp/tmp.dpx This command will print something like this: 0 < 0,0,0 0 > .002,.002,.002 1048576 within range If the second line of the result indicates that there are 0 pixels greater than 0.002, then the test passed. (Note that oiiotool works in normalized units, so 0.002 is actually equivalent to 0.002 x 1023 = 2.046 10-bit code values.) Writing CLFs \u00b6 Not all products must support writing CLFs, depending on the way they are used. If your product supports the writing of CLF files, it must adhere to the CLF specification. Some important highlights and recommendations for implementation default behavior, or for users authoring CLFs by hand, are described in the following sections. File Extension \u00b6 The extension used for CLF files should be a .clf at the end of the file name. Indentation \u00b6 CLF files may be opened and read by users during troubleshooting, so readability is desirable. In particular, the following formatting is recommended for indentation: Use 2-4 spaces to indent relative to a parent item. A new indented line should be used after the starting element tag for complex XML types. For compactness, simple XML types may be placed on a single line. Arrays (contained in Matrix , LUT1D , LUT3D ) should use line breaks to present data visually (e.g., by aligning columns of R, G, B). Large blocks of lines of numbers do not need to be indented since they are already visually distinct and there is no point adding spaces in front of thousands of lines (e.g., in the case of large LUTs ). Long text strings (e.g. in a Description tag) should not contain embedded wrapping and indentation. It is better to let the application software determine where to wrap long lines of text in order to present them best in its own user interface. Indentation example (using made-up element names): \u00b6 <aTag> <simpleType>This does not require a line break.</simpleType> <complexType> <simpleType>This is a simpleType in a complexType.</simpleType> <simpleType>Here's a long text line that shouldn't be wrapped in the CLF since the app will decide where to wrap it.</simpleType> </complexType> <simpleTypeWithParam param=0.5 /> <Array dim=\"3 4\"> 1.0 0.0 0.0 -0.3 0.0 1.0 0.0 -0.5 0.0 0.0 1.0 -0.5 </Array> </aTag> Use of XML Comments \u00b6 CLF authors should avoid using XML comments to encapsulate metadata or important information. Most parsers ignore comments, so if a CLF gets read and rewritten, comments that were previously there may go missing. Any important information should be enclosed in provided metadata XML elements and attributes (e.g., the ProcessList's Info element). Discrete Operations \u00b6 Finishing Tier products should, whenever possible, encapsulate discrete math operations with one or more ProcessNodes in a ProcessList rather than simply exporting a 1D- and/or 3D- LUT . For example, a common color space conversion should use discrete Log and Matrix nodes, where appropriate, rather than a single LUT3D . Precision and Range of Numeric Values \u00b6 Ensure your implementation writes a sufficient number of digits. Even though image processing will typically be done at 32-bit floating-point precision, intermediate calculations (for example, combining matrices) may be done at higher precision. Also, take note that the bit-depth attributes do not impose range or quantization limits. Hence you should not impose these limits unnecessarily. For example, for a LUT1D with an outBitDepth of 10i , the normal range would be expected to be 0 to 1023. However, it is legal to exceed this range and also to use fractional values. Thus, values such as [-10.5, 0.01, 1055.2] could be legal values. Please refer to the Implementation Notes on Bit Depth section of the CLF specification for more detail. The id Attribute \u00b6 Every CLF is required to have an id attribute at the ProcessList level. The specification does not impose any restrictions on the formatting of this attribute. However, it should be noted that an ACES Metadata File that references a CLF file prefers that the id attribute contains a UUID object according to RFC 4122. Therefore, it is recommended that implementations use a UUID to fill the id attribute when writing new CLF files. Note that the id attribute is optional at the ProcessNode level. Storage of Proprietary Metadata \u00b6 If an application wants to store \"dark metadata\" that is meaningful only for a special purpose within proprietary products or workflows, this is easily accomplished. Indeed this is one of the frequently cited benefits of the XML encoding. However, it is important that CLF writers are respectful of certain guidelines to ensure the CLF file remains usable by other readers. If you need to add proprietary metadata, please respect the following: Check the CLF spec to see if there is already an element whose purpose matches what you are trying to store. If not, you may create a custom XML element to store your metadata. As described in the spec, this should typically be placed within the Info block. You may add additional custom elements and attributes under your main element as needed in order to easily represent your information. Avoid using the standard existing elements such as Description in a way that is inconsistent with their purpose. Avoid placing custom elements at the ProcessNode level since that would make it an illegal file that most parsers will reject. Other Metadata Considerations \u00b6 Inaccurate metadata is worse than no metadata. Implementers should make it as regular and easy as possible for the user to set required CLF metadata when writing a file. Accurate metadata is critical for other users to be able to understand the intended usage of the CLF file, especially the Description , InputDescriptor , and OutputDescriptor tags. If known by the application, the application should fill in the InputDescriptor and OutputDescriptor tags automatically. At this time, no standard list of values (i.e., text strings) for color spaces or other common settings is defined. When writing a CLF to represent an ACES Look Transform, the CLF should adhere to the structure and metadata described in Annex F . If translating an ACES CTL (Color Transformation Language) file into CLF , set the ACESTransformID and ACESUserName (under the Info block of metadata) using the corresponding strings from the CTL header. [Examples 13] and [14] in [section 6] of the specification show CLFs using this feature. Helpful Hints for a Successful Implementation \u00b6 Matrix Order \u00b6 Take note that the order of coefficients in the Matrix ProcessNode follows the usual convention in color science but that this is the transposition of both the order sometimes used in computer graphics and the order used in CTL . The Matrix section of the CLF Specification clearly documents the ordering of matrix coefficients that must be used. Also, note that the 3x4 matrix includes an offset value after each of the three matrix values. LUT3D Serialization Order \u00b6 As described in the LUT3D section of the CLF Specification , take note that the LUT3D ProcessNode serializes the LUT entries in blue-fastest order. This is a commonly used ordering (for example it is used by the common .3dl format) but some other formats use red-fastest ordering (e.g., .cube format). Gamma Polarity \u00b6 As described in the Exponent section of the CLF Specification , take note that the Exponent ProcessNode uses the specified parameter directly in the power function for the forward direction. This is the same usage as in an ASC CDL power. But take care since often \"gamma\" operators in color processing software apply the inverse of the power for the forward direction. Bit-Depth Attributes Don't Affect Processing Precision \u00b6 As called out in the CLF specification, the inBitDepth and outBitDepth attributes of ProcessNodes are not intended to control the processing precision, which should normally be 32-bit floating-point. Rather, these attributes simply determine the scaling of various parameter values such as matrix and LUT entries. Please refer to the Bit Depth section of the CLF Specification for the details. Conversion Between Bit-Depths \u00b6 When interpreting the inBitDepth and outBitDepth attributes, conversions happen using \"power of two minus 1\" scaling rather than \"power of 2\" scaling. Please refer to the section on conversion between bit depths in the CLF Specification for the details. Appendices \u00b6 Annex A: Test Image \u00b6 A 16-bit OpenEXR test image was designed with many ramps and other values which should be useful for testing any CLF and/or CLF implementation. The image includes: 33x33 cube spanning -1.0 to 1.0 33x33 cube spanning -65504 to 65504 an ACES2065-1 ColorChecker chart 0-1 grayscale ramps ColorChecker values and primaries/secondaries ramped in \u00bd stop increments a set of ramps designed to generate a spiderweb when viewed on a vectorscope extents lattice ramps designed to produce a bounding box around all possible normal positive and negative values when viewed in 3D Specific details for each of the image subsections can be found in the README at https://github.com/alexfry/CLFTestImage The test image (named CLF_Finishing_SourceImage_v008.exr ) is included along with the processed reference images in the download referenced in Annex C and D . Annex B: CLF Test Suite Listing \u00b6 These test files may be found in the OpenColorIO repository on GitHub: https://github.com/AcademySoftwareFoundation/OpenColorIO The files are in the sub-directory: OpenColorIO/tests/data/files/clf Note: Some of the test files intentionally use unusual or difficult syntax to give a thorough test for parsers. They are not all intended as \"best practice\" examples. Legal test files \u00b6 An implementation should be able to load and process these files successfully. Index Filename Ops tested Description Notes 0010 aces_to_video_with_look.clf Matrix, Log, CDL , Lut3D ACES2065-1 to ACEScct, CDL , then ACES Output Transform Interpolation=tetrahedral 0020 cdl_all_styles.clf CDL One ASC CDL of each style 0030 cdl_clamp_fwd.clf CDL Basic single CDL Has newlines in Slope element 0040 cdl_missing_sat.clf CDL Basic single CDL without SatNode 0050 cdl_missing_sop.clf CDL Basic single CDL without SOPNode 0060 cdl_missing_style.clf CDL Basic single CDL , relying on default style 0070 difficult_syntax.clf Matrix, Lut1D Legal file with lots of unusual formatting to stress parsers 0080 exponent_all_styles.clf Exponent, Range One Exponent of each style 0090 info_example.clf Matrix Info metadata element with app-specific elements 0100 inverseOf_id_test.clf Lut1D Example of inverseOf ProcessList attribute 0110 log_all_styles.clf Log, Range At least one Log op of each style and LogParams usage 0120 lut1d_32f_example.clf Lut1D Basic 65x1 32f/32f Lut1D Array is monotonic decreasing 0130 lut1d_comp.clf Lut1D Two Lut1D ops, 2x1 8i/8i and 32x3 8i/32f Channels of the 32x3 are unequal 0140 lut1d_example.clf Lut1D Basic 65x1 8i/12i Lut1D Array values exceed nominal 12i range and must not be clamped 0150 lut1d_half_domain_raw_half_set.clf Lut1D Lut1D 65536x1 16f/16f using halfDomain and rawHalfs 0160 lut1d_long.clf Lut1D Lut1D 131072x1 32f/16f Array contains occasional duplicate/quantized values 0170 lut3d_17x17x17_10i_12i.clf Lut3D Typical Lut3D 17x17x17 10i/12i No interpolation set (should use trilinear) 0180 lut3d_bizarre.clf Lut3D Unusual 3x3x3 10i/10i Lut3D, interpolation=tetrahedral Array values exceed nominal 10i range and must not be clamped 0190 lut3d_identity_12i_16f.clf Lut3D Basic identity 2x2x2 12i/16f Lut3D Interpolation=tetrahedral 0200 lut3d_preview_tier_test.clf Lut3D Typical Lut3D 33x33x33 32f/10i, tetrahedral This is the file used for the Preview-tier processing test. Values clamped to [4,1019]. 0210 matrix_3x4_example.clf Matrix Matrix 3x4 10i/12i, includes \"+\" and \"e-1\" in Array The 10i/12i depths requires normalizing the Array values by 1023/4095 0220 matrix_example_utf8.clf Matrix Matrix 3x3 32f/32f Matrix Description uses non-ASCII characters 0230 matrix_example.clf Matrix Matrix 3x3 32f/32f Uses the legal dim=\"3 3 3\" syntax allowed for CLF v2 compatibility 0240 matrix_no_newlines.clf Matrix Matrix 3x4 10i/10i, compact formatting with no newlines 0250 matrix_windows.clf Matrix Identity Matrix 3x3 16f/12i, Windows line-endings Per section 3.2.6 of the spec, Linux newlines should be used. But for maximum robustness, ideally other line-endings should be tolerated 0260 multiple_ops.clf All ops Tests at least one of all ops 0270 range_test1_clamp.clf Range Range 8i/32f with Clamp style The 8i minIn/maxIn values require normalizing by 1/255 0280 range_test1_noclamp.clf Range Range 8i/32f with noClamp style 0290 range_test2.clf Range Range 32f/16f, minValue only, with Clamp style 0300 range.clf Range Range 16i/16i, relying on default style (Clamp) The 16i values require normalizing by 1/65535 0310 tabulation_support.clf Lut3D Lut3D 3x3x3 10i/10i, interpolation=tetrahedral The Array RGB values are only separated by tabs 0320 xyz_to_rgb.clf Matrix, Range, Lut1D Matrix 3x3 32f/32f, Range, and Lut1D 128x3 32f/32f The Lut1D Array columns are unequal Illegal test files \u00b6 These files should not load successfully and the implementation should indicate that it is not a legal file. The files are in the directory: OpenColorIO/tests/data/files/clf/illegal Index Filename Ops tested Description Notes 0010 array_bad_dimension.clf Matrix Array dim attribute has 10 numbers 0020 array_bad_value.clf Matrix Array has \"P\" for the 4th value rather than a number 0030 array_missing_values.clf Matrix Array has 3 values instead of 9 0040 array_too_many_values.clf Matrix Array has 18 values instead of 9 0050 cdl_bad_power.clf CDL One of the power values is 0 0060 cdl_bad_sat.clf CDL Saturation has 2 values instead of 1 0070 cdl_bad_slope.clf CDL Slope has 2 values rather than 3 0080 cdl_bad_style.clf CDL Style is \"invalid_cdl_style\" 0090 cdl_missing_offset.clf CDL The SOPNode is missing the Offset element 0100 cdl_missing_power.clf CDL The SOPNode is missing the Power element 0110 cdl_missing_slope.clf CDL The SOPNode is missing the Slope element 0120 exponent_bad_param.clf Exponent The basicFwd style may not use the offset attribute 0130 exponent_bad_value.clf Exponent The monCurveFwd style requires exponent to be >= 1 0140 image_png.clf None File is a binary PNG image, not actually a CLF file 0150 indexMap_test2.clf Lut3D The IndexMap element is no longer allowed in CLF v3 0160 log_bad_param.clf Log The linToLog style may not contain the linSideBreak parameter 0170 log_bad_style.clf Log Style is \"invalidStyle\" 0180 log_bad_version.clf Log The compCLFversion = 2.0, Log was introduced in v3 0190 log_missing_breakpnt.clf Log The cameraLogToLin style must have the linSideBreak parameter 0200 lut1d_half_domain_missing_values.clf Lut1D A half-domain LUT must have 65536 values 0210 lut1d_half_domain_set_false.clf Lut1D The halfDomain attribute may only have the value \"true\" 0220 lut1d_raw_half_set_false.clf Lut1D The rawHalfs attribute may only have the value \"true\" 0230 lut3d_unequal_size.clf Lut3D The Array dimension is 2x2x3x3 0240 matrix_end_missing.clf Matrix There is no element 0250 process_list_bad_version.clf Matrix The compCLFversion = \"three\" 0260 process_list_higher_version.clf Matrix The compCLFversion = \"3.2\" 0270 process_list_missing.clf Matrix The ProcessList element is missing 0280 range_bad_noclamp.clf Range The noClamp style must have both min and max values 0290 range_bad_values.clf Range The minInValue must be less than the maxInValue 0300 range_empty.clf Range The Range element must have at least min or max values 0310 range_nonmatching_clamp.clf Range A one-sided Range must use the same normalized value for in and out Because the bit-depths differ, the values are not actually the same 0320 transform_bad_outdepth.clf Matrix The outBitDepth is \"16d\" 0330 transform_bitdepth_mismatch.clf Matrix, Lut1D The inBitDepth does not match the previous outBitDepth Also missing the XML header (though this is legal) 0340 transform_corrupted_tag.clf Matrix The closing ProcessList element is incorrect 0350 transform_element_end_missing.clf Matrix The closing ProcessList element is missing 0360 transform_empty.clf None The ProcessList must have at least one ProcessNode operator 0370 transform_id_empty.clf Log The ProcessList id attribute must not be empty 0380 transform_missing_id.clf Log The ProcessList id attribute must be present 0390 transform_missing_inbitdepth.clf Lut1D The inBitDepth attribute is missing 0400 transform_missing_outbitdepth.clf Lu1D The outBitDepth attribute is missing 0410 transform_missing.clf None There is nothing except the XML header 0420 unknown_elements.clf Matrix, Lut1D, Lut3D The ProcessList contains unknown elements outside the Info element Annex C: Finishing Tier Apply Test CLF List \u00b6 The list of CLF files for the Finishing Tier apply test is the complete list of legal files in Annex B . Processed reference images may be downloaded from here: CLF Apply Test Images Annex D: Preview Tier Apply Test CLF List \u00b6 The CLF file for the Preview Tier apply test is simply: lut3d_preview_tier_test.clf Processed reference images may be downloaded from here: CLF Apply Test Images Annex E: Baking a CLF for Preview Tier Implementation \u00b6 Because CLF allows a fairly powerful set of processing operators that may be assembled into pipelines of any ordering and any length, it will not be possible to exactly evaluate all CLFs on hardware or software that has a fixed processing pipeline. (In other words, the implementation must allow the CLF file itself to specify the pipeline of operators for a given color transform.) Converting color transforms into a simpler structure to make them simpler to evaluate is known as baking . This is often done to meet the needs of a particular hardware implementation. There are a number of factors that make the process of accurately baking color transforms a difficult and complicated subject: CLF is intended to support the needs of floating-point scene-linear color spaces and therefore the range of possible input and output values extends from very small to very large numbers (both positive and negative). A given CLF may expect virtually any color space (scene-linear, camera log, video, etc.) on input and another completely different space on output. The flexible nature of CLF and the way a chain of operators is built up makes it fairly easy for the function to have abrupt changes in slope. For example, at the edge of a gamut boundary, or due to a conversion into an internal working space for a look transform. These slope changes are usually not captured accurately when the transform is baked. The human visual system is often able to detect fairly small errors in color reproduction, particularly in dark colors. All of that said, there are many successful products that have used a baking process. For example, this technique is often used in products designed for on-set production monitoring involving look transforms. So it is highly likely that baking of CLFs could be a successful strategy for Preview Tier products. The key will be to clearly document the types of color transforms that may be successfully baked and those that the user should avoid. Integer-based implementations in the Preview Tier will typically be processing video or logarithmic color space encodings. So for example, if the documentation suggests avoiding use of CLFs expecting scene-linear color spaces on input, that is probably fine since (hopefully!) no one will be trying to send raw scene-linear values through an integer connection such as SDI video. The accuracy of the baking process may be judged by sending images through both the original CLF and the baked CLF and comparing them. OpenColorIO or any product that passes the Finishing Tier tests could be used for this type of comparison. But keep in mind that the result will depend on many factors, including the input and output color spaces and the internal structure of the original CLF . So even though one CLF may bake accurately through a given baking process, it certainly does not mean that all of them will. Testing with a range of user transforms is essential. OpenColorIO may be used to experiment with baking CLFs using the command-line tool ociobakelut . For example, here is a command that takes an original CLF named complicated.clf and bakes it into a single LUT3D with a cube dimension of 33x33x33 called simple.clf : $ ociobakelut --lut complicated.clf --cubesize 33 --format \"Academy/ASC Common LUT Format\" --v simple.clf You may edit the resulting CLF XML file in a text editor to add the interpolation=\"tetrahedral\" attribute to the LUT3D and any desired metadata. For CLFs that convert from one perceptually uniform color space to another (i.e., between most logarithmic and video color spaces), this will often be reasonably accurate for Preview Tier devices. Increasing the cube size will improve accuracy (the default cubesize is 64x64x64). However, this would not work well for baking a CLF that expects a scene-linear color space on input. In those situations, the usual technique is to add some kind of a \"shaper\" LUT1D or other non-linear transform in front of the LUT3D that will convert the linear values into something more perceptually uniform. A more modern and compact technique that takes advantage of the CLF capabilities would be to insert a Log ProcessNode rather than a LUT1D , but the most appropriate technique would be based on the needs of the given implementation. The ociobakelut tool is able to bake with shaper LUTs , but it requires an OCIO config file to define the input, output, and shaper spaces. But for the use-case here, the input is just a single CLF file, so there is no OCIO config file to use. OpenColorIO could still be used to do these more advanced types of baking, but it would require some scripting. One approach would be to create a config file that references the original CLF as a file transform and includes an appropriate shaper space. Another approach would be to just use the OCIO API directly to write your own baking tool, using the ociobakelut code for inspiration. (And if so, we encourage you to contribute it back to the OCIO project!) The ociobakelut command supports many arguments; use the -h argument for a summary. For example, note that you may supply many --lut arguments on the command line and they will all be baked together into the result. You may also consult the Baking LUT \u2019s section of the OCIO documentation for a tutorial on using ociobakelut . Annex F: Using CLF to represent ACES Look Transforms \u00b6 Historically, look workflows have been based on applying a look in some kind of logarithmic color space, for example, a camera log space. This is partly because the existing infrastructure was built for integer pixel formats and did not support floating-point pixel formats. (The Preview Tier described above is an attempt to define requirements for these integer-based devices.) And until CLF , previous LUT formats did not support scene-linear color spaces well. However, the input values and output values of ACES Look Transforms (also known as \"LMTs\") must be ACES2065-1. This is to maintain universality of Look Transforms and not link them to project-specific working spaces. Look Transforms may then convert ACES2065-1 to some other working space internally (e.g., a camera log space) for look application. This is the vision for the future and the ACES Metadata File ( AMF ) format expects implementations to work this way. As an aside, it is recommended that the InputDescriptor and OutputDescriptor be set to ACES2065-1 when authoring Look Transforms as CLFs so it is always clear what the expected input and output color spaces are. The Description tag and other metadata may also be used to provide a more complete description of the look. When look operations are to be performed in a working space other than ACES2065-1, then appropriate conversions to and from the required working space can be prepended and appended within a CLF to communicate the transform. For accuracy, whenever possible, these conversions should be implemented using discrete operations such as Log and Matrix ProcessNodes rather than LUT1D or LUT3D . By using ProcessNodes such as Log and Matrix , a CLF author makes it easier for an implementation to detect and remove any unnecessary conversions when applying the CLF . For example, OpenColorIO will do this when optimizing transform chains. The OCIO tool ociomakeclf can create an ACES Look Transform by prepending and appending the appropriate color space conversions to an existing look LUT file. For example, if an existing look LUT expects ACEScct input and outputs ACEScct, the --csc ACEScct option will add appropriate conversions from ACES2065-1 to ACEScct at the beginning and from ACEScct back to ACES2065-1 at the end. Example: Convert the look CDL cdl_test2.cc that expects and produces ACEScct values to an ACES Look Transform in CLF format that expects and produces ACES2065-1 values: $ ociomakeclf OpenColorIO/tests/data/files/cdl_test2.cc LMT.clf --csc ACEScct This generates the following CLF : <?xml version=\"1.0\" encoding=\"UTF-8\"?> <ProcessList compCLFversion= \"3\" id= \"669980ac1ecd97ab18c1707250a13d20\" > <!-- Header metadata --> <Description> ACES LMT transform built from a look LUT expecting color space: ACEScct </Description> <Description> Original LUT name: OpenColorIO/tests/data/files/cdl_test2.cc </Description> <InputDescriptor> ACES2065-1 </InputDescriptor> <OutputDescriptor> ACES2065-1 </OutputDescriptor> <!-- Convert from ACES2065-1 to ACEScct --> <Matrix inBitDepth= \"32f\" outBitDepth= \"32f\" > <Array dim= \"3 3\" > 1.45143931614567 -0.23651074689374 -0.214928569251925 -0.0765537733960206 1.17622969983357 -0.0996759264375522 0.00831614842569772 -0.00603244979102103 0.997716301365323 </Array> </Matrix> <Log inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"cameraLinToLog\" > <LogParams base= \"2\" linSideSlope= \"1\" linSideOffset= \"0\" logSideSlope= \"0.0570776255707763\" logSideOffset= \"0.554794520547945\" linSideBreak= \"0.0078125\" /> </Log> <!-- Apply the user's CDL look in the ACEScct working space --> <ASC_CDL id= \"cc0001\" inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"FwdNoClamp\" > <SOPNode> <Slope> 1.0 1.0 0.9 </Slope> <Offset> -0.03 -0.02 0.0 </Offset> <Power> 1.25 1.0 1.0 </Power> </SOPNode> <SatNode> <Saturation> 1.7 </Saturation> </SatNode> </ASC_CDL> <!-- Convert from ACEScct back to ACES2065-1 --> <Log inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"cameraLogToLin\" > <LogParams base= \"2\" linSideSlope= \"1\" linSideOffset= \"0\" logSideSlope= \"0.0570776255707763\" logSideOffset= \"0.554794520547945\" linSideBreak= \"0.0078125\" /> </Log> <Matrix inBitDepth= \"32f\" outBitDepth= \"32f\" > <Array dim= \"3 3\" > 0.695452241357452 0.140678696470294 0.163869062172254 0.0447945633720377 0.859671118456422 0.0955343181715404 -0.00552588255811354 0.00402521030597866 1.00150067225213 </Array> </Matrix> </ProcessList> Note that an ACES Look Transform is usually just one component in a larger pipeline of transforms. For example, Preview Tier implementations involving on-set LUT boxes will typically incorporate the Look Transform into a chain of transforms that expect a camera log color space on input and produce a video color space on output. As noted above, the use of explicit Log and Matrix ProcessNodes in a CLF transform allows an implementation to detect unnecessary operations. For example, if an ACES Input Transform were added in front of an ACES Look Transform that begins with the inverse of that Input Transform, the redundant operations could be optimized out for efficiency. Though in some implementations, this will all be baked into a single LUT3D , making such optimizations less necessary. Annex G: Using CLF with AMF \u00b6 The ACES Metadata File ( AMF ) is a \"sidecar\" XML file designed to encapsulate the metadata required to recreate ACES viewing pipelines. An AMF can carry references to one or more CLF files as external ACES Look Transform files. When using a CLF file for ACES applications and especially when in conjunction with AMF , it is recommended that the CLF id attribute of the ProcessList be populated with a uuid . Multiple CLFs can be included by using multiple lookTransform elements in the AMF file. The CLFs are applied in the order in which they appear in the AMF . See the AMF Handbook for more details. Annex H: Identity (no-op) CLF example \u00b6 To avoid doubt in cases where CLF files are exchanged as \u201csidecar\u201d files to batches of media, it may be desirable to use a standard CLF form even when no transform or color modification has been assigned to certain media clips / files. In these cases it may be useful that a \u201cNo-Op\u201d CLF file be included as the associated sidecar file to communicate to downstream users that no transform is assigned. This may be preferred to not providing a sidecar CLF file, as the absence of CLF files for a subset of a larger media batch often raises questions in certain workflows about whether an expected file is missing. For this situation, implementers may generate a minimal CLF file like that shown below, where the ProcessList has a single ProcessNode of the Matrix type with a 3x3 identity matrix. (Implementers do not need to copy this exactly, for example there are other operators that also give an identity and details like the id string will differ.) <?xml version=\"1.0\" encoding=\"UTF-8\"?> <ProcessList id= \"37efa85b-5bc8-40dc-8ffe-b488a3c013ea\" name= \"No-Op\" compCLFversion= \"3.0\" > <Description> No-Op CLF </Description> <Matrix name= \"identity matrix\" inBitDepth= \"32f\" outBitDepth= \"32f\" > <Array dim= \"3 3\" > 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 </Array> </Matrix> </ProcessList> Annex I: Infinity and NaN handling \u00b6 The CLFs used for the apply tests were specially chosen to avoid floating-point overflows that could turn pixels in the test target image into infinity or NaN. However, with other CLFs, the comparison script described in the other sections may fail if the resulting images have infinity or NaN pixels. The handling of infinity and NaN is challenging in a number of regards. For example: There is not always consensus on what the ideal behavior is. For example, should overflows be clamped to a large finite value or allowed to produce an infinity. There are sometimes performance penalties to be extra rigorous about the handling which are not always warranted. The handling on GPUs tends to vary a lot and often does not match the CPU (where there are clearer specs for what is supposed to happen). Once these values get into a chain of color processing, there can be somewhat unexpected results. For example, (Inf \u2013 Inf) is NaN, likewise, (0 x Inf) is NaN, so quite often an infinity going into a matrix or other operator that mixes the channels results in NaNs coming out. Due to issues such as these, neither the Academy reference CTL for ACES transforms nor OpenColorIO have ideal behavior with respect to the handling of floating-point infinity and NaN. We expect this is true of most other practical implementations and so this initial version of the Implementation Guide does not attempt to validate handling of these values. Annex J: Python code for creating the Preview Tier test LUT \u00b6 Here is some Python code that uses OCIO to create the test LUT for the Preview Tier. # This script builds the file for the Preview Tier test from the CLF test suite. import PyOpenColorIO as ocio import numpy as np v = np . linspace ( 0 , 1 , 33 ) # v = # array([ 0. , 0.03125, 0.0625 , 0.09375, 0.125 , 0.15625, # 0.1875 , 0.21875, 0.25 , 0.28125, 0.3125 , 0.34375, # 0.375 , 0.40625, 0.4375 , 0.46875, 0.5 , 0.53125, # 0.5625 , 0.59375, 0.625 , 0.65625, 0.6875 , 0.71875, # 0.75 , 0.78125, 0.8125 , 0.84375, 0.875 , 0.90625, # 0.9375 , 0.96875, 1. ]) # Convert the vector into the values for a Lut3D. Uses blue-fastest order. a1 , a2 , a3 = np . meshgrid ( v , v , v ) gr = np . column_stack (( a2 . ravel (), a1 . ravel (), a3 . ravel ())) # At this point, gr is a 35937 x 3 array with min=0 and max=1. # Build transforms to convert from ACEScct to Rec.709 using an ACES Output Transform. bt1 = ocio . BuiltinTransform ( style = 'ACEScct_to_ACES2065-1' ) bt2 = ocio . BuiltinTransform ( style = 'ACES-OUTPUT - ACES2065-1_to_CIE-XYZ-D65 - SDR-VIDEO_1.0' ) bt3 = ocio . BuiltinTransform ( style = 'DISPLAY - CIE-XYZ-D65_to_REC.1886-REC.709' ) dvt = ocio . GroupTransform ( [ bt1 , bt2 , bt3 ] ) # Set up an OCIO Processor and process the values. config = ocio . Config . CreateRaw () proc = config . getProcessor ( dvt ) cpu = proc . getDefaultCPUProcessor () tmp = gr . astype ( np . float32 ) cpu . applyRGB ( tmp ) # replaces tmp with output # For this example, the goal was to quantize to 10-bits and clamp to [4,1019] # since hardware involving SDI video may not be able to process these values. vals = np . round ( tmp * 1023 ) # vals[0:10,:] = # array([[ 0., 0., 0.], # [ 0., 0., 0.], # [ 0., 0., 0.], # [ 0., 0., 0.], # [ 0., 0., 35.], # [ 0., 0., 52.], # [ 0., 0., 68.], # [ 0., 0., 88.], # [ 0., 0., 114.], # [ 0., 0., 148.]], dtype=float32) vals2 = vals . clip ( 4 , 1019 ) # Now renormalize to [0,1], vectorize, and set the data into a Lut3D. vals2 = vals2 / 1023. lut = ocio . Lut3DTransform () lut . setData ( vals2 . ravel ()) # Set some LUT attributes. lut . setFileOutputBitDepth ( ocio . BIT_DEPTH_UINT10 ) lut . setInterpolation ( ocio . INTERP_TETRAHEDRAL ) fmd = lut . getFormatMetadata () fmd . addChildElement ( 'Description' , 'This LUT is an ACEScct to Rec.709 Output Transform, clamped to [4,1019]' ) # print(lut) # <Lut3DTransform direction=forward, fileoutdepth=10ui, interpolation=tetrahedral, # gridSize=33, minrgb=[0.00391007 0.00391007 0.00391007], maxrgb=[0.99609 0.99609 # 0.99609]> # Add the LUT to a GroupTransform, set the metadata and write. grp = ocio . GroupTransform () grp . appendTransform ( lut ) fmdg = grp . getFormatMetadata () fmdg . setID ( '00001' ) fmdg . setName ( 'Preview-tier Lut3D test' ) fmdg . addChildElement ( 'Description' , 'Test LUT for Preview-tier CLF validation test suite' ) fmdg . addChildElement ( 'InputDescriptor' , 'ACEScct' ) fmdg . addChildElement ( 'OutputDescriptor' , 'Rec.1886 / Rec.709 video' ) # print(grp) # <GroupTransform direction=forward, transforms= # <Lut3DTransform direction=forward, fileoutdepth=10ui, interpolation=tetrahedral, # gridSize=33, minrgb=[0.00391007 0.00391007 0.00391007], # maxrgb=[0.99609 0.99609 0.99609]>> grp . write ( formatName = 'Academy/ASC Common LUT Format' , config = config , fileName = '/tmp/lut3d_preview_tier_test.clf' ) Annex K: Generation of the reference images \u00b6 The processed reference images may be downloaded from the URL provided in Annex C and D above. This section documents how those images were generated. Finishing Tier Reference Images \u00b6 Since OpenColorIO is an actively maintained open source implementation of CLF , it has been used to generate the processed reference images. There is a Python script in the OCIO repository that may be run to generate these images. The script is run as follows (these steps assume a Linux or Mac platform but could also be done on Windows): Install OpenImageIO Install OpenColorIO from source, following the instructions in the OCIO documentation available from opencolorio.org. Given that OIIO was installed in step 1, this should build the ocioconvert command-line tool, which is needed by the Python script. In a shell, cd to the directory where OpenColorIO was installed and then cd into the sub-directory share/clf. This directory contains the Python script as well as a copy of the source target image described in Annex A . In the shell, type: $ python process_clf_test_frames.py <OUTPUT-DIR> replacing <OUTPUT-DIR> with a directory that you want to write the images to. (There are also some other optional arguments that are described if you run the script with just a \"-h\" option, but these are not necessary to generate the reference image set.) Preview Tier Source Image \u00b6 The Preview Tier test uses an integer source image in DPX format. That image was generated from the main Finishing Tier floating-point source image by applying a conversion from ACES2065-1 to ACEScct. It may be generated using the command-line tool oiiotool that is included with OpenImageIO using the following steps (these steps assume a Linux or Mac platform but could also be done on Windows): Install a recent version of OpenImageIO and oiiotool , compiled with OpenColorIO support. Download the OpenColorIO source code, which contains an OCIO config file to use with oiiotool . In a shell, cd to the directory where OpenColorIO was installed and then cd into the sub-directory share/clf . This directory contains a copy of the source target image described in Annex A . Set the OCIO environment variable to point to the following config file in the OCIO repository: docs/configurations/ocio-v2_demo.ocio Run the command: $ oiiotool CLF_Finishing_SourceImage_v008.exr --colorconvert ACES2065-1 ACEScct -d uint10 -o CLF_Preview_SourceImage_v008.dpx Preview Tier Reference Image \u00b6 The Preview Tier reference image may then be generated as follows: Follow steps 1-5 in the previous section. At this point the current directory will be the share/clf sub-directory of the OpenColorIO source code. Run the command: $ oiiotool CLF_Preview_SourceImage_v008.dpx --ociofiletransform ../../tests/data/files/clf/lut3d_preview_tier_test.clf -d uint10 -o lut3d_preview_tier_test.dpx","title":"Index"},{"location":"guides/clf/#common-lut-format-clf-implementation-guide","text":"","title":"Common LUT Format (CLF) Implementation Guide"},{"location":"guides/clf/#introduction","text":"Look-up tables, or LUTs , are a common method for communicating color transformations. Many software and hardware providers develop LUT formats uniquely designed for use in their systems. Since these formats were designed to work in specific use cases, they often prove inadequate for interchangeability between applications or systems. To further complicate matters, some LUT formats use the same file extensions which make them appear to be compatible when they are not. If there are already a dozen or more confusing LUT formats, why should you as a developer consider adding support for yet another one? While the myriad LUT formats already available are fundamentally useful in theory, each lacks one or more features that can be critical in meeting the demands of today\u2019s sophisticated workflows. Existing formats can lack the quality, versatility, and metadata required to meet the demands of modern systems. The Common LUT Format ( CLF ) provides flexibility to enclose transforms from simple to complex. Due to a lack of interchangeability of color transforms between tools, LUTs are frequently abused as a catch-all. Even simple color-space transformations, such as the application of a matrix or a logarithmic shaper function are often \u201cbaked\u201d to crude LUT formats resulting in unfortunate losses in precision. As a solution, CLF allows for a range of common mathematical operators to be specified precisely, in addition to supporting traditional 1D- and 3D- LUTs in the file. Because CLF files are floating-point capable, extremely flexible, and well documented, they are an excellent candidate for use in modern workflows. CLFs are also ideal for archival purposes because the format is well-specified and documented. There is also a high-quality, open source implementation freely available on GitHub.","title":"Introduction"},{"location":"guides/clf/#format-comparison-table","text":"Features/Formats CLF 3dl Adobe (Iridas) cube Resolve cube Truelight cube Cinespace cube ASC CDL Imageworks spi3d ICC Profile Provider Academy / ASC Discreet Adobe Blackmagic Filmlight Rising Sun ASC Imageworks ICC Maintained public documentation \u2705 \u274c \u2705 \u2705 \u2705 \u274c \u2705 \u274c \u2705 Implementation guide \u2705 \u274c \u274c \u274c \u274c \u274c \u2705 \u274c \u2705 Allows shaper LUT \u2705 \u274c \u274c \u2705 \u2705 \u2705 \u274c \u274c \u2705 Is not limited to log or video data on input \u2705 \u274c \u274c \u2705 \u2705 \u2705 \u274c \u274c \u274c Unconstrained ordering of processing elements \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u274c Floating-point table values \u2705 \u274c \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 Rich metadata \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u2705 Test suite provided \u2705 \u274c \u274c \u274c \u274c \u274c \u2705 \u274c \u2705 Text-based \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u274c Can define operations in linear floating-point space \u2705 \u274c \u274c \u274c \u274c \u274c \u2705 \u274c \u2705 GUID support \u2705 \u274c \u274c \u274c \u274c \u274c \u2705 \u274c \u2705 Supports mathematical operators \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u274c","title":"Format Comparison Table"},{"location":"guides/clf/#target-audience","text":"This document is primarily intended for application developers who want to add CLF support to their product. It defines requirements, tests, and provides recommendations that, if followed, will lead to robust support for CLF . Implementers who follow the guidance in this document can have confidence that their product is implementing the specification correctly. The document may also be of interest to those using CLF to author transforms and who want to understand how the CLFs will be used by applications. This guide should be read in conjunction with the CLF Specification (v 3.0) . Note The specification was previously referred to by its document number - \"S-2014-006\". Although the spec had \"2014\" in the name, the document has been updated more recently than that. Version 3 of CLF was introduced with the release of ACES 1.2 in 2020 and the most recent editorial updates were in 2021. The current version of the specification now lives at the above link.","title":"Target Audience"},{"location":"guides/clf/#a-quick-introduction-to-clf","text":"Below is a basic example of a simple CLF file. Despite the word ' LUT ' in the name of the format, these very simple examples do not contain any type of LUT whatsoever. Instead, the CLF is being used to communicate a set of ASC CDL adjustments ( Example 1 ), and encapsulate a YCbCr to RGB conversion ( Example 2 ). There are a few key points that these examples demonstrate: CLF is an XML document and therefore conforms to the requirements of any XML document. There is one ProcessList , which can contain any number of ProcessNodes . (A ProcessNode is an operator such as a Matrix or LUT3D .) A CLF may or may not contain \u201c LUTs \u201d (despite the name). Some parts are optional and others are required. CLF provides a richer metadata model than other LUT formats - it\u2019s not just numbers. Good metadata is highly encouraged and helps make the CLF file self-documenting. Every CLF must have a unique id attribute. The bit-depth attributes control formatting but not precision. Color coding for the following two examples: red is required blue is optional green are comments","title":"A Quick Introduction to CLF"},{"location":"guides/clf/#open-source-example-implemention","text":"As you explore CLF and work to implement it into your product(s), it may be helpful to refer to some existing tools that already provide full CLF functionality. The tools described here are included in the open source project OpenColorIO ( OCIO ) v2. More details and the full installation process for OCIO can be found at https://www.opencolorio.org .","title":"Open Source Example Implemention"},{"location":"guides/clf/#ociochecklut","text":"The command-line utility ociochecklut can be used to load a CLF file and process an RGB triplet through the CLF file. It will report any errors that are encountered in parsing the file. If no RGB triplet is provided to process through the CLF file, then a list of the ProcessNodes contained in the LUT are returned. This tool is installed as part of OCIO v2. Here is sample output using the CLF in the example section (assuming it is saved as a file called 709_ycbcr-to-rgb.clf ): Summarizing the contents of the CLF : $ ociochecklut 709_ycbcr-to-rgb.clf Transform operators: <MatrixTransform direction=forward, fileindepth=32f, fileoutdepth=32f, matrix=1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1, offset=-0.0625 -0.5 -0.5 0> <MatrixTransform direction=forward, fileindepth=32f, fileoutdepth=32f, matrix=1.16893193493151 0 1.79974396623884 0 1.16893193493151 -0.214081616673236 -0.534991005624129 0 1.16893193493151 2.12065335518973 -0 0 0 0 0 1, offset=0 0 0 0> Evaluating the RGB value [0.5, 0.4, 0.3]: $ ociochecklut 709_ycbcr-to-rgb.clf 0.5 0.4 0.3 0.1514589 0.6398141 0.2993424","title":"ociochecklut"},{"location":"guides/clf/#ocioconvert","text":"The command-line utility ocioconvert can be used to apply a CLF file to an image. To apply a CLF file, use the --lut option. A variety of image file formats are supported. This tool is installed as a part of OCIO v2, although it first requires installation of OpenImageIO. Processing the input image syntheticChart.01.exr to the output image output_image.exr through the CLF from the previous example: $ ocioconvert --lut 709_ycbcr-to-rgb.clf syntheticChart.01.exr output_image.exr","title":"ocioconvert"},{"location":"guides/clf/#ociomakeclf","text":"The command-line utility ociomakeclf will convert any LUT format supported by OpenColorIO into CLF format. The --csc option may be used to create an ACES Look Transform that is compatible with the ACES Metadata File ( AMF ). This tool is installed as a part of OCIO v2. Convert the LUT oldLUT.3dl to CLF format: $ ociomakeclf oldLUT.3dl oldLUT.clf Convert the look LUT acescctLUT.3dl that expects and produces ACEScct values to an ACES Look Transform in CLF format that expects and produces ACES2065-1 values: $ ociomakeclf acescctLUT.3dl LMT.clf --csc ACEScct","title":"ociomakeclf"},{"location":"guides/clf/#minimum-requirements","text":"","title":"Minimum Requirements"},{"location":"guides/clf/#introduction_1","text":"The products anticipated to implement CLF can be categorized into two broad categories: one for final production-level finished images and one for preview/proxy images. Due to the fundamental differences in the products, different requirements are provided for the two categories.","title":"Introduction"},{"location":"guides/clf/#finishing-tier","text":"The primary category of products, dubbed the Finishing Tier , includes software implementations that have the logic and processing power available to parse and apply ProcessNode operations using floating-point calculations and in sequential order. Finishing Tier products provide the highest quality image processing and have the tightest tolerances, prioritizing accuracy in computation results. Finishing Tier products should be used to create images when the highest image fidelity is required in pipelines utilizing CLF files.","title":"Finishing Tier"},{"location":"guides/clf/#preview-tier","text":"The second category of implementations are described as Preview Tier devices. These are products that, due to limited processing power or technical constraints, cannot implement a CLF ProcessList exactly and instead require that CLF files be \u201dbaked\u201d or collapsed into a simpler representation (for example, a single 3D- LUT ). Hardware devices such as on-set LUT boxes would be an example of devices that might fall into this category. As the name implies, Preview Tier products are suitable for creating images such as for on-set viewing, where the requirements for accuracy and/or flexibility are lower than for the Finishing Tier. CLF is designed as a modern LUT format that can handle floating-point input and output pixels. However, the current ecosystem of devices still includes many products that work primarily on integer-encoded signals (e.g. HD-SDI and HDMI video) and do not support floating-point image data, including scene-linear encodings such as ACES2065-1. These types of devices would fall in the Preview Tier and CLF may be used to encapsulate any of the LUTs that are currently used in such devices. But there is no expectation that these devices will be able to accurately process other CLFs that contain transforms expecting scene-linear inputs or outputs. Note that although the processing requirements are lower for the Preview Tier, the read requirements are not. In other words, even Preview Tier devices must be able to read all of the files in the test suite. But as described in the section \" Applying CLFs \", if a Preview Tier device detects ProcessNodes that it does not support, there are two options: Inform the user of this situation and do not attempt to process the file. Attempt to bake the CLF down into a representation supported by the device. The user should be given some indication that they are seeing an approximation of the original CLF .","title":"Preview Tier"},{"location":"guides/clf/#reading-clfs","text":"This section describes the general requirements for parsing CLF files, the provided test suite, and the steps for validating an implementation using the test suite.","title":"Reading CLFs"},{"location":"guides/clf/#general-parsing-requirements","text":"","title":"General Parsing Requirements"},{"location":"guides/clf/#clf-file-test-suite","text":"A number of test files are provided for implementers to test their system and demonstrate that their implementation can robustly handle all features of CLF v3. The tests provided in the OpenColorIO repository on Github include both legal and illegal test files. The file name and description in each file identifies what the file is testing. The test files confirm that each ProcessNode is functioning per the CLF specification. For ProcessNodes that allow for different styles or parameters, either separate test files or single test files with multiple ProcessNode variations are provided to check that all styles and parameters are functional. Standard files are expected to be processed without error. A number of \"illegal\" test files with various syntax errors are also provided to test the error handling capability of implementations. Illegal files should not be processed and the system should generate an appropriate error message.","title":"CLF File Test Suite"},{"location":"guides/clf/#test-procedure","text":"Download the OpenColorIO repository from GitHub at the URL: https://github.com/AcademySoftwareFoundation/OpenColorIO If you are not familiar with Git, that\u2019s fine. Simply click on the green button that says Code and select \u201cDownload ZIP\u201d. Unzip this file on your computer and you will have all of the test files. The test files are in the directory: OpenColorIO/tests/data/files/clf You may refer to a description of each test file in Annex B . For each legal test file: Read the file into your product and verify that it loads successfully. For each illegal test file (these are the files in the clf/illegal subdirectory): Read the file into your product and ensure that the user is notified that it is not a legal CLF file. Ideally, the nature of the problem should be communicated to the user. Verify that none of these files load successfully. They should not result in a processed image. If an implementation needs to pass through the unprocessed image, it should communicate clearly to the user in some other way that there was an error.","title":"Test Procedure"},{"location":"guides/clf/#applying","text":"","title":"Applying CLFs"},{"location":"guides/clf/#general","text":"For CLF to be useful, it is important that different products output the same results when applying the same CLF to the same input. This section describes the different expectations for Finishing Tier and Preview Tier products. Each category has their own metric and defined tolerances.","title":"General"},{"location":"guides/clf/#finishing-tier_1","text":"","title":"Finishing Tier"},{"location":"guides/clf/#preview-tier_1","text":"","title":"Preview Tier"},{"location":"guides/clf/#writing","text":"Not all products must support writing CLFs, depending on the way they are used. If your product supports the writing of CLF files, it must adhere to the CLF specification. Some important highlights and recommendations for implementation default behavior, or for users authoring CLFs by hand, are described in the following sections.","title":"Writing CLFs"},{"location":"guides/clf/#file-extension","text":"The extension used for CLF files should be a .clf at the end of the file name.","title":"File Extension"},{"location":"guides/clf/#indentation","text":"CLF files may be opened and read by users during troubleshooting, so readability is desirable. In particular, the following formatting is recommended for indentation: Use 2-4 spaces to indent relative to a parent item. A new indented line should be used after the starting element tag for complex XML types. For compactness, simple XML types may be placed on a single line. Arrays (contained in Matrix , LUT1D , LUT3D ) should use line breaks to present data visually (e.g., by aligning columns of R, G, B). Large blocks of lines of numbers do not need to be indented since they are already visually distinct and there is no point adding spaces in front of thousands of lines (e.g., in the case of large LUTs ). Long text strings (e.g. in a Description tag) should not contain embedded wrapping and indentation. It is better to let the application software determine where to wrap long lines of text in order to present them best in its own user interface.","title":"Indentation"},{"location":"guides/clf/#use-of-xml-comments","text":"CLF authors should avoid using XML comments to encapsulate metadata or important information. Most parsers ignore comments, so if a CLF gets read and rewritten, comments that were previously there may go missing. Any important information should be enclosed in provided metadata XML elements and attributes (e.g., the ProcessList's Info element).","title":"Use of XML Comments"},{"location":"guides/clf/#discrete-operations","text":"Finishing Tier products should, whenever possible, encapsulate discrete math operations with one or more ProcessNodes in a ProcessList rather than simply exporting a 1D- and/or 3D- LUT . For example, a common color space conversion should use discrete Log and Matrix nodes, where appropriate, rather than a single LUT3D .","title":"Discrete Operations"},{"location":"guides/clf/#precision-and-range-of-numeric-values","text":"Ensure your implementation writes a sufficient number of digits. Even though image processing will typically be done at 32-bit floating-point precision, intermediate calculations (for example, combining matrices) may be done at higher precision. Also, take note that the bit-depth attributes do not impose range or quantization limits. Hence you should not impose these limits unnecessarily. For example, for a LUT1D with an outBitDepth of 10i , the normal range would be expected to be 0 to 1023. However, it is legal to exceed this range and also to use fractional values. Thus, values such as [-10.5, 0.01, 1055.2] could be legal values. Please refer to the Implementation Notes on Bit Depth section of the CLF specification for more detail.","title":"Precision and Range of Numeric Values"},{"location":"guides/clf/#the-id-attribute","text":"Every CLF is required to have an id attribute at the ProcessList level. The specification does not impose any restrictions on the formatting of this attribute. However, it should be noted that an ACES Metadata File that references a CLF file prefers that the id attribute contains a UUID object according to RFC 4122. Therefore, it is recommended that implementations use a UUID to fill the id attribute when writing new CLF files. Note that the id attribute is optional at the ProcessNode level.","title":"The id Attribute"},{"location":"guides/clf/#storage-of-proprietary-metadata","text":"If an application wants to store \"dark metadata\" that is meaningful only for a special purpose within proprietary products or workflows, this is easily accomplished. Indeed this is one of the frequently cited benefits of the XML encoding. However, it is important that CLF writers are respectful of certain guidelines to ensure the CLF file remains usable by other readers. If you need to add proprietary metadata, please respect the following: Check the CLF spec to see if there is already an element whose purpose matches what you are trying to store. If not, you may create a custom XML element to store your metadata. As described in the spec, this should typically be placed within the Info block. You may add additional custom elements and attributes under your main element as needed in order to easily represent your information. Avoid using the standard existing elements such as Description in a way that is inconsistent with their purpose. Avoid placing custom elements at the ProcessNode level since that would make it an illegal file that most parsers will reject.","title":"Storage of Proprietary Metadata"},{"location":"guides/clf/#other-metadata-considerations","text":"Inaccurate metadata is worse than no metadata. Implementers should make it as regular and easy as possible for the user to set required CLF metadata when writing a file. Accurate metadata is critical for other users to be able to understand the intended usage of the CLF file, especially the Description , InputDescriptor , and OutputDescriptor tags. If known by the application, the application should fill in the InputDescriptor and OutputDescriptor tags automatically. At this time, no standard list of values (i.e., text strings) for color spaces or other common settings is defined. When writing a CLF to represent an ACES Look Transform, the CLF should adhere to the structure and metadata described in Annex F . If translating an ACES CTL (Color Transformation Language) file into CLF , set the ACESTransformID and ACESUserName (under the Info block of metadata) using the corresponding strings from the CTL header. [Examples 13] and [14] in [section 6] of the specification show CLFs using this feature.","title":"Other Metadata Considerations"},{"location":"guides/clf/#helpful-hints-for-a-successful-implementation","text":"","title":"Helpful Hints for a Successful Implementation"},{"location":"guides/clf/#matrix-order","text":"Take note that the order of coefficients in the Matrix ProcessNode follows the usual convention in color science but that this is the transposition of both the order sometimes used in computer graphics and the order used in CTL . The Matrix section of the CLF Specification clearly documents the ordering of matrix coefficients that must be used. Also, note that the 3x4 matrix includes an offset value after each of the three matrix values.","title":"Matrix Order"},{"location":"guides/clf/#lut3d-serialization-order","text":"As described in the LUT3D section of the CLF Specification , take note that the LUT3D ProcessNode serializes the LUT entries in blue-fastest order. This is a commonly used ordering (for example it is used by the common .3dl format) but some other formats use red-fastest ordering (e.g., .cube format).","title":"LUT3D Serialization Order"},{"location":"guides/clf/#gamma-polarity","text":"As described in the Exponent section of the CLF Specification , take note that the Exponent ProcessNode uses the specified parameter directly in the power function for the forward direction. This is the same usage as in an ASC CDL power. But take care since often \"gamma\" operators in color processing software apply the inverse of the power for the forward direction.","title":"Gamma Polarity"},{"location":"guides/clf/#bit-depth-attributes-dont-affect-processing-precision","text":"As called out in the CLF specification, the inBitDepth and outBitDepth attributes of ProcessNodes are not intended to control the processing precision, which should normally be 32-bit floating-point. Rather, these attributes simply determine the scaling of various parameter values such as matrix and LUT entries. Please refer to the Bit Depth section of the CLF Specification for the details.","title":"Bit-Depth Attributes Don't Affect Processing Precision"},{"location":"guides/clf/#conversion-between-bit-depths","text":"When interpreting the inBitDepth and outBitDepth attributes, conversions happen using \"power of two minus 1\" scaling rather than \"power of 2\" scaling. Please refer to the section on conversion between bit depths in the CLF Specification for the details.","title":"Conversion Between Bit-Depths"},{"location":"guides/clf/#appendices","text":"","title":"Appendices"},{"location":"guides/clf/#annexA","text":"A 16-bit OpenEXR test image was designed with many ramps and other values which should be useful for testing any CLF and/or CLF implementation. The image includes: 33x33 cube spanning -1.0 to 1.0 33x33 cube spanning -65504 to 65504 an ACES2065-1 ColorChecker chart 0-1 grayscale ramps ColorChecker values and primaries/secondaries ramped in \u00bd stop increments a set of ramps designed to generate a spiderweb when viewed on a vectorscope extents lattice ramps designed to produce a bounding box around all possible normal positive and negative values when viewed in 3D Specific details for each of the image subsections can be found in the README at https://github.com/alexfry/CLFTestImage The test image (named CLF_Finishing_SourceImage_v008.exr ) is included along with the processed reference images in the download referenced in Annex C and D .","title":"Annex A: Test Image"},{"location":"guides/clf/#annexB","text":"These test files may be found in the OpenColorIO repository on GitHub: https://github.com/AcademySoftwareFoundation/OpenColorIO The files are in the sub-directory: OpenColorIO/tests/data/files/clf Note: Some of the test files intentionally use unusual or difficult syntax to give a thorough test for parsers. They are not all intended as \"best practice\" examples.","title":"Annex B: CLF Test Suite Listing"},{"location":"guides/clf/#annexC","text":"The list of CLF files for the Finishing Tier apply test is the complete list of legal files in Annex B . Processed reference images may be downloaded from here: CLF Apply Test Images","title":"Annex C: Finishing Tier Apply Test CLF List"},{"location":"guides/clf/#annexD","text":"The CLF file for the Preview Tier apply test is simply: lut3d_preview_tier_test.clf Processed reference images may be downloaded from here: CLF Apply Test Images","title":"Annex D: Preview Tier Apply Test CLF List"},{"location":"guides/clf/#annexE","text":"Because CLF allows a fairly powerful set of processing operators that may be assembled into pipelines of any ordering and any length, it will not be possible to exactly evaluate all CLFs on hardware or software that has a fixed processing pipeline. (In other words, the implementation must allow the CLF file itself to specify the pipeline of operators for a given color transform.) Converting color transforms into a simpler structure to make them simpler to evaluate is known as baking . This is often done to meet the needs of a particular hardware implementation. There are a number of factors that make the process of accurately baking color transforms a difficult and complicated subject: CLF is intended to support the needs of floating-point scene-linear color spaces and therefore the range of possible input and output values extends from very small to very large numbers (both positive and negative). A given CLF may expect virtually any color space (scene-linear, camera log, video, etc.) on input and another completely different space on output. The flexible nature of CLF and the way a chain of operators is built up makes it fairly easy for the function to have abrupt changes in slope. For example, at the edge of a gamut boundary, or due to a conversion into an internal working space for a look transform. These slope changes are usually not captured accurately when the transform is baked. The human visual system is often able to detect fairly small errors in color reproduction, particularly in dark colors. All of that said, there are many successful products that have used a baking process. For example, this technique is often used in products designed for on-set production monitoring involving look transforms. So it is highly likely that baking of CLFs could be a successful strategy for Preview Tier products. The key will be to clearly document the types of color transforms that may be successfully baked and those that the user should avoid. Integer-based implementations in the Preview Tier will typically be processing video or logarithmic color space encodings. So for example, if the documentation suggests avoiding use of CLFs expecting scene-linear color spaces on input, that is probably fine since (hopefully!) no one will be trying to send raw scene-linear values through an integer connection such as SDI video. The accuracy of the baking process may be judged by sending images through both the original CLF and the baked CLF and comparing them. OpenColorIO or any product that passes the Finishing Tier tests could be used for this type of comparison. But keep in mind that the result will depend on many factors, including the input and output color spaces and the internal structure of the original CLF . So even though one CLF may bake accurately through a given baking process, it certainly does not mean that all of them will. Testing with a range of user transforms is essential. OpenColorIO may be used to experiment with baking CLFs using the command-line tool ociobakelut . For example, here is a command that takes an original CLF named complicated.clf and bakes it into a single LUT3D with a cube dimension of 33x33x33 called simple.clf : $ ociobakelut --lut complicated.clf --cubesize 33 --format \"Academy/ASC Common LUT Format\" --v simple.clf You may edit the resulting CLF XML file in a text editor to add the interpolation=\"tetrahedral\" attribute to the LUT3D and any desired metadata. For CLFs that convert from one perceptually uniform color space to another (i.e., between most logarithmic and video color spaces), this will often be reasonably accurate for Preview Tier devices. Increasing the cube size will improve accuracy (the default cubesize is 64x64x64). However, this would not work well for baking a CLF that expects a scene-linear color space on input. In those situations, the usual technique is to add some kind of a \"shaper\" LUT1D or other non-linear transform in front of the LUT3D that will convert the linear values into something more perceptually uniform. A more modern and compact technique that takes advantage of the CLF capabilities would be to insert a Log ProcessNode rather than a LUT1D , but the most appropriate technique would be based on the needs of the given implementation. The ociobakelut tool is able to bake with shaper LUTs , but it requires an OCIO config file to define the input, output, and shaper spaces. But for the use-case here, the input is just a single CLF file, so there is no OCIO config file to use. OpenColorIO could still be used to do these more advanced types of baking, but it would require some scripting. One approach would be to create a config file that references the original CLF as a file transform and includes an appropriate shaper space. Another approach would be to just use the OCIO API directly to write your own baking tool, using the ociobakelut code for inspiration. (And if so, we encourage you to contribute it back to the OCIO project!) The ociobakelut command supports many arguments; use the -h argument for a summary. For example, note that you may supply many --lut arguments on the command line and they will all be baked together into the result. You may also consult the Baking LUT \u2019s section of the OCIO documentation for a tutorial on using ociobakelut .","title":"Annex E: Baking a CLF for Preview Tier Implementation"},{"location":"guides/clf/#annexF","text":"Historically, look workflows have been based on applying a look in some kind of logarithmic color space, for example, a camera log space. This is partly because the existing infrastructure was built for integer pixel formats and did not support floating-point pixel formats. (The Preview Tier described above is an attempt to define requirements for these integer-based devices.) And until CLF , previous LUT formats did not support scene-linear color spaces well. However, the input values and output values of ACES Look Transforms (also known as \"LMTs\") must be ACES2065-1. This is to maintain universality of Look Transforms and not link them to project-specific working spaces. Look Transforms may then convert ACES2065-1 to some other working space internally (e.g., a camera log space) for look application. This is the vision for the future and the ACES Metadata File ( AMF ) format expects implementations to work this way. As an aside, it is recommended that the InputDescriptor and OutputDescriptor be set to ACES2065-1 when authoring Look Transforms as CLFs so it is always clear what the expected input and output color spaces are. The Description tag and other metadata may also be used to provide a more complete description of the look. When look operations are to be performed in a working space other than ACES2065-1, then appropriate conversions to and from the required working space can be prepended and appended within a CLF to communicate the transform. For accuracy, whenever possible, these conversions should be implemented using discrete operations such as Log and Matrix ProcessNodes rather than LUT1D or LUT3D . By using ProcessNodes such as Log and Matrix , a CLF author makes it easier for an implementation to detect and remove any unnecessary conversions when applying the CLF . For example, OpenColorIO will do this when optimizing transform chains. The OCIO tool ociomakeclf can create an ACES Look Transform by prepending and appending the appropriate color space conversions to an existing look LUT file. For example, if an existing look LUT expects ACEScct input and outputs ACEScct, the --csc ACEScct option will add appropriate conversions from ACES2065-1 to ACEScct at the beginning and from ACEScct back to ACES2065-1 at the end. Example: Convert the look CDL cdl_test2.cc that expects and produces ACEScct values to an ACES Look Transform in CLF format that expects and produces ACES2065-1 values: $ ociomakeclf OpenColorIO/tests/data/files/cdl_test2.cc LMT.clf --csc ACEScct This generates the following CLF : <?xml version=\"1.0\" encoding=\"UTF-8\"?> <ProcessList compCLFversion= \"3\" id= \"669980ac1ecd97ab18c1707250a13d20\" > <!-- Header metadata --> <Description> ACES LMT transform built from a look LUT expecting color space: ACEScct </Description> <Description> Original LUT name: OpenColorIO/tests/data/files/cdl_test2.cc </Description> <InputDescriptor> ACES2065-1 </InputDescriptor> <OutputDescriptor> ACES2065-1 </OutputDescriptor> <!-- Convert from ACES2065-1 to ACEScct --> <Matrix inBitDepth= \"32f\" outBitDepth= \"32f\" > <Array dim= \"3 3\" > 1.45143931614567 -0.23651074689374 -0.214928569251925 -0.0765537733960206 1.17622969983357 -0.0996759264375522 0.00831614842569772 -0.00603244979102103 0.997716301365323 </Array> </Matrix> <Log inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"cameraLinToLog\" > <LogParams base= \"2\" linSideSlope= \"1\" linSideOffset= \"0\" logSideSlope= \"0.0570776255707763\" logSideOffset= \"0.554794520547945\" linSideBreak= \"0.0078125\" /> </Log> <!-- Apply the user's CDL look in the ACEScct working space --> <ASC_CDL id= \"cc0001\" inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"FwdNoClamp\" > <SOPNode> <Slope> 1.0 1.0 0.9 </Slope> <Offset> -0.03 -0.02 0.0 </Offset> <Power> 1.25 1.0 1.0 </Power> </SOPNode> <SatNode> <Saturation> 1.7 </Saturation> </SatNode> </ASC_CDL> <!-- Convert from ACEScct back to ACES2065-1 --> <Log inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"cameraLogToLin\" > <LogParams base= \"2\" linSideSlope= \"1\" linSideOffset= \"0\" logSideSlope= \"0.0570776255707763\" logSideOffset= \"0.554794520547945\" linSideBreak= \"0.0078125\" /> </Log> <Matrix inBitDepth= \"32f\" outBitDepth= \"32f\" > <Array dim= \"3 3\" > 0.695452241357452 0.140678696470294 0.163869062172254 0.0447945633720377 0.859671118456422 0.0955343181715404 -0.00552588255811354 0.00402521030597866 1.00150067225213 </Array> </Matrix> </ProcessList> Note that an ACES Look Transform is usually just one component in a larger pipeline of transforms. For example, Preview Tier implementations involving on-set LUT boxes will typically incorporate the Look Transform into a chain of transforms that expect a camera log color space on input and produce a video color space on output. As noted above, the use of explicit Log and Matrix ProcessNodes in a CLF transform allows an implementation to detect unnecessary operations. For example, if an ACES Input Transform were added in front of an ACES Look Transform that begins with the inverse of that Input Transform, the redundant operations could be optimized out for efficiency. Though in some implementations, this will all be baked into a single LUT3D , making such optimizations less necessary.","title":"Annex F: Using CLF to represent ACES Look Transforms"},{"location":"guides/clf/#annexG","text":"The ACES Metadata File ( AMF ) is a \"sidecar\" XML file designed to encapsulate the metadata required to recreate ACES viewing pipelines. An AMF can carry references to one or more CLF files as external ACES Look Transform files. When using a CLF file for ACES applications and especially when in conjunction with AMF , it is recommended that the CLF id attribute of the ProcessList be populated with a uuid . Multiple CLFs can be included by using multiple lookTransform elements in the AMF file. The CLFs are applied in the order in which they appear in the AMF . See the AMF Handbook for more details.","title":"Annex G: Using CLF with AMF"},{"location":"guides/clf/#annexH","text":"To avoid doubt in cases where CLF files are exchanged as \u201csidecar\u201d files to batches of media, it may be desirable to use a standard CLF form even when no transform or color modification has been assigned to certain media clips / files. In these cases it may be useful that a \u201cNo-Op\u201d CLF file be included as the associated sidecar file to communicate to downstream users that no transform is assigned. This may be preferred to not providing a sidecar CLF file, as the absence of CLF files for a subset of a larger media batch often raises questions in certain workflows about whether an expected file is missing. For this situation, implementers may generate a minimal CLF file like that shown below, where the ProcessList has a single ProcessNode of the Matrix type with a 3x3 identity matrix. (Implementers do not need to copy this exactly, for example there are other operators that also give an identity and details like the id string will differ.) <?xml version=\"1.0\" encoding=\"UTF-8\"?> <ProcessList id= \"37efa85b-5bc8-40dc-8ffe-b488a3c013ea\" name= \"No-Op\" compCLFversion= \"3.0\" > <Description> No-Op CLF </Description> <Matrix name= \"identity matrix\" inBitDepth= \"32f\" outBitDepth= \"32f\" > <Array dim= \"3 3\" > 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 </Array> </Matrix> </ProcessList>","title":"Annex H: Identity (no-op) CLF example"},{"location":"guides/clf/#annexI","text":"The CLFs used for the apply tests were specially chosen to avoid floating-point overflows that could turn pixels in the test target image into infinity or NaN. However, with other CLFs, the comparison script described in the other sections may fail if the resulting images have infinity or NaN pixels. The handling of infinity and NaN is challenging in a number of regards. For example: There is not always consensus on what the ideal behavior is. For example, should overflows be clamped to a large finite value or allowed to produce an infinity. There are sometimes performance penalties to be extra rigorous about the handling which are not always warranted. The handling on GPUs tends to vary a lot and often does not match the CPU (where there are clearer specs for what is supposed to happen). Once these values get into a chain of color processing, there can be somewhat unexpected results. For example, (Inf \u2013 Inf) is NaN, likewise, (0 x Inf) is NaN, so quite often an infinity going into a matrix or other operator that mixes the channels results in NaNs coming out. Due to issues such as these, neither the Academy reference CTL for ACES transforms nor OpenColorIO have ideal behavior with respect to the handling of floating-point infinity and NaN. We expect this is true of most other practical implementations and so this initial version of the Implementation Guide does not attempt to validate handling of these values.","title":"Annex I: Infinity and NaN handling"},{"location":"guides/clf/#annexJ","text":"Here is some Python code that uses OCIO to create the test LUT for the Preview Tier. # This script builds the file for the Preview Tier test from the CLF test suite. import PyOpenColorIO as ocio import numpy as np v = np . linspace ( 0 , 1 , 33 ) # v = # array([ 0. , 0.03125, 0.0625 , 0.09375, 0.125 , 0.15625, # 0.1875 , 0.21875, 0.25 , 0.28125, 0.3125 , 0.34375, # 0.375 , 0.40625, 0.4375 , 0.46875, 0.5 , 0.53125, # 0.5625 , 0.59375, 0.625 , 0.65625, 0.6875 , 0.71875, # 0.75 , 0.78125, 0.8125 , 0.84375, 0.875 , 0.90625, # 0.9375 , 0.96875, 1. ]) # Convert the vector into the values for a Lut3D. Uses blue-fastest order. a1 , a2 , a3 = np . meshgrid ( v , v , v ) gr = np . column_stack (( a2 . ravel (), a1 . ravel (), a3 . ravel ())) # At this point, gr is a 35937 x 3 array with min=0 and max=1. # Build transforms to convert from ACEScct to Rec.709 using an ACES Output Transform. bt1 = ocio . BuiltinTransform ( style = 'ACEScct_to_ACES2065-1' ) bt2 = ocio . BuiltinTransform ( style = 'ACES-OUTPUT - ACES2065-1_to_CIE-XYZ-D65 - SDR-VIDEO_1.0' ) bt3 = ocio . BuiltinTransform ( style = 'DISPLAY - CIE-XYZ-D65_to_REC.1886-REC.709' ) dvt = ocio . GroupTransform ( [ bt1 , bt2 , bt3 ] ) # Set up an OCIO Processor and process the values. config = ocio . Config . CreateRaw () proc = config . getProcessor ( dvt ) cpu = proc . getDefaultCPUProcessor () tmp = gr . astype ( np . float32 ) cpu . applyRGB ( tmp ) # replaces tmp with output # For this example, the goal was to quantize to 10-bits and clamp to [4,1019] # since hardware involving SDI video may not be able to process these values. vals = np . round ( tmp * 1023 ) # vals[0:10,:] = # array([[ 0., 0., 0.], # [ 0., 0., 0.], # [ 0., 0., 0.], # [ 0., 0., 0.], # [ 0., 0., 35.], # [ 0., 0., 52.], # [ 0., 0., 68.], # [ 0., 0., 88.], # [ 0., 0., 114.], # [ 0., 0., 148.]], dtype=float32) vals2 = vals . clip ( 4 , 1019 ) # Now renormalize to [0,1], vectorize, and set the data into a Lut3D. vals2 = vals2 / 1023. lut = ocio . Lut3DTransform () lut . setData ( vals2 . ravel ()) # Set some LUT attributes. lut . setFileOutputBitDepth ( ocio . BIT_DEPTH_UINT10 ) lut . setInterpolation ( ocio . INTERP_TETRAHEDRAL ) fmd = lut . getFormatMetadata () fmd . addChildElement ( 'Description' , 'This LUT is an ACEScct to Rec.709 Output Transform, clamped to [4,1019]' ) # print(lut) # <Lut3DTransform direction=forward, fileoutdepth=10ui, interpolation=tetrahedral, # gridSize=33, minrgb=[0.00391007 0.00391007 0.00391007], maxrgb=[0.99609 0.99609 # 0.99609]> # Add the LUT to a GroupTransform, set the metadata and write. grp = ocio . GroupTransform () grp . appendTransform ( lut ) fmdg = grp . getFormatMetadata () fmdg . setID ( '00001' ) fmdg . setName ( 'Preview-tier Lut3D test' ) fmdg . addChildElement ( 'Description' , 'Test LUT for Preview-tier CLF validation test suite' ) fmdg . addChildElement ( 'InputDescriptor' , 'ACEScct' ) fmdg . addChildElement ( 'OutputDescriptor' , 'Rec.1886 / Rec.709 video' ) # print(grp) # <GroupTransform direction=forward, transforms= # <Lut3DTransform direction=forward, fileoutdepth=10ui, interpolation=tetrahedral, # gridSize=33, minrgb=[0.00391007 0.00391007 0.00391007], # maxrgb=[0.99609 0.99609 0.99609]>> grp . write ( formatName = 'Academy/ASC Common LUT Format' , config = config , fileName = '/tmp/lut3d_preview_tier_test.clf' )","title":"Annex J: Python code for creating the Preview Tier test LUT"},{"location":"guides/clf/#annexK","text":"The processed reference images may be downloaded from the URL provided in Annex C and D above. This section documents how those images were generated.","title":"Annex K: Generation of the reference images"},{"location":"guides/rgc-implementation/","text":"ACES Reference Gamut Compression Implementation Guide \u00b6 Scope \u00b6 The purpose of this document is to detail and define standards for user interface and experience, workflow, tolerances, and tracking of the ACES Reference Gamut Compression ( RGC ) published in ACES 1.3 . For detailed technical specifications, please refer to the ACES Gamut Mapping Architecture VWG - Technical Documentation . References \u00b6 The following standards, specifications, articles, presentations, and texts are referenced in this text: ACES Gamut Mapping Architecture VWG - Technical Documentation Deliverable Introduction \u00b6 The ACES Reference Gamut Compression was introduced to help solve ACES user issues with out of gamut (negative) pixels introduced either in the conversion from camera raw RGB via an Input Transform ( IDT ) into ACES AP0 or in the conversion from ACES AP0 into ACES AP1 (ACEScg and ACEScct). These out of gamut pixel values are problematic when their negative components cause issues in compositing, and may also produce visual artifacts when viewed through an ACES Output Transform. User Testing Footage Examples Target Audience \u00b6 This document is targeted at software developers and product managers looking to integrate the Reference Gamut Compression into their software package or library. It will focus on the \u201chow\u201d as opposed to the \u201cwhy\u201d, which is covered in the architecture documentation above. Workflow Recommendations \u00b6 Workflow As visualized in the flowchart above, it is recommended (in the current absence of AMF for tracking) that most productions utilize the gamut compression in every area - from on set all the way to finishing. This means that at this time, the RGC is \u201calways on\u201d by default in any viewing pipeline. Following the general ACES workflow philosophy, the RGC is only baked into image data at the appropriate stage in the pipeline - which varies based on the needs of the production, as outlined in the flow chart above. For further workflow specifications, please refer to the User Guide . Reference Implementation Specifications \u00b6 Versioning and Naming \u00b6 The Reference Gamut Compression published in ACES 1.3 uses the following ACES Transform ID and ACES User Name in the CTL : <ACEStransformID>urn:ampas:aces:transformId:v1.5:LMT.Academy.ReferenceGamutCompress.a1.v1.0</ACEStransformID> <ACESuserName>ACES 1.3 Look - Reference Gamut Compress</ACESuserName> Implementers should only make the RGC available in the UI when their application has the ACES version set to 1.3 or higher. Project and Clip Level Setting \u00b6 When an application has the ACES version set to 1.3 or higher, a simple check-box (defaulting to on ) should be exposed in the project settings which applies the RGC to all clips in the project. DaVinci Resolve project level RGC setting An override should be provided at the clip level, so that the user can control the RGC setting for individual clips, if required. DaVinci Resolve clip level RGC setting Implementers may also choose to offer a parametric variation of the RGC (see Section 9 ). Export Settings \u00b6 The user should be able to easily control whether rendered media will have the RGC \u201cbaked in\u201d. Options should be available so that exports can either follow the global project setting, individual clip settings, or be forced to either on or off for all clips. If an application offers export templates, then templates should be provided which force the RGC off when rendering EXRs (following the recommended workflow for VFX pulls) and follow the clip settings when rendering deliverables with an Output Transform baked in. Test Images and Tolerances \u00b6 Test image (without RGC) with sRGB Output Transform applied To aid with validation of implementations, a test image has been created which covers a wide dynamic range (including negatives) and contains values which exceed the AP1 gamut in every direction. It also includes ColorCheckers at varying exposures, to confirm that the gamut compression does not alter colors within the \u201czone of trust\u201d. The Python code to create the test image can be found in this Google Colab . The resulting test file can be downloaded from here , and the test image processed through the CTL implementation of the RGC can be downloaded from here (Note: ctlrender adds an alpha channel to the result, which can be ignored.) For comparison of an implementation with the reference, a relative error metric has been defined (see Appendix A ). The command-line application oiiotool , which is installed as a component of OpenImageIO , can be used to compare pixels between two images and evaluate the metric specified above, using the following command line (with test_target.exr replaced with the name of the file under test): oiiotool gc_test_image_v007_gamut_compressed_ctlrender.exr --dup test_target.exr --absdiff --swap --abs --maxc 0.1 --div --rangecheck 0,0,0 .002,.002,.002 -o /tmp/tmp.exr A match within tolerances will produce the following output: 0 < 0,0,0 0 > .002,.002,.002 2073600 within range Implementers are of course free to use their own code to perform validation, as long as it applies the same metric. Tracking via ACES Metadata File ( AMF ) \u00b6 The Reference Gamut Compression is trackable via a lookTransform element in an AMF file. If the RCG is used in the viewing pipeline, the lookTransform will be listed in the associated AMF . If the AMF is accompanying rendered media, use the applied flag to track whether or not the RGC has been \u201cbaked in\u201d. See below for an example AMF : <aces:inputTransform applied=\"true\"> \u2026 </aces:inputTransform> <aces:lookTransform applied=\"true\"> <aces:description>ACES 1.3 Look - Reference Gamut Compress</aces:description> <aces:transformId>urn:ampas:aces:transformId:v1.5:LMT.Academy. ReferenceGamutCompress.a1.v1.0</aces:transformId> </aces:lookTransform> If using the RGC in a viewing pipeline, this lookTransform should appear directly after the IDT , first in the list of any LMTs, to make sure other operations benefit from the gamut compression. The Transform ID outlined in the specification section should be included in any exported AMFs, with the applied flag set as appropriate, and the description set to the ACESuserName to enable proper tracking. Currently, only the Reference (i.e. static) Gamut Compression is trackable via AMF . Parametric Version Implementation Specifications \u00b6 An implementation of the gamut compression transform which exposes the parameters to the user should be treated differently than the ACES RGC and grouped with other, creative color correction operators instead. As a creative color correction tool, the parametric gamut compression transform is expected to be used as part of a color correction operator stack. This parametric transform can be useful to achieve a desired \u201clook\u201d or manage out-of-gamut artifacts created earlier in the process chain that were not, or could not, be addressed by the RGC . The parametric version should not be used as a replacement for the RGC since it cannot be tracked by AMF . While such an operator is not explicitly endorsed, the following recommendations are made to facilitate a common user experience across implementations: Parameters UI Label Components Slider Range Default Value(s) / Slider Detents Distance Limit Limit 3 (Cyan, Magenta, Yellow) 1.001 - 2.000 C:1.147, M:1.264, Y:1.312 Compression Threshold Threshold 3 (Cyan, Magenta, Yellow) 0.000 - 1.000 C:0.815, M:0.803, Y:0.880 Power Curve Exponent Roll-off 1 0.500 - 2.000 1.200 These default values will exactly match a parametric implementation to the RGC . DaVinci Resolve Parametric Gamut Compress Settings Appendices \u00b6 Appendix A: Relative metric detail \u00b6 Where video and logarithmic encodings are typically sufficiently perceptually uniform that a simple absolute error metric such as (actual - aim) may be used, scene-linear encodings require a tolerance that is tighter for dark colors and looser for bright colors. This is due to the approximately logarithmic nature of human color perception (although the metric is actually computed per channel). When comparing an aim and actual value, a basic relative error metric has the form: \\[\\frac{(actual - aim)}{aim}\\] However this can become overly sensitive when the values being compared become very small. In the limit, when the aim value is zero, the result is either infinity or NaN . Therefore it is useful to use a \u201csafe-guarded relative error metric\u201d that places a lower bound on the denominator: \\[\\frac{(actual - aim)}{max(aim, lower\\_bound)}\\] This effectively transitions the error metric from being a relative error metric for bright and normal colors to an absolute error metric when approaching a certain noise floor determined by the lower_bound constant. A reasonable lower_bound constant for images in ACES2065-1 color space would be 0.1. It is also necessary to handle the case where the aim value may be negative, in which case the final error metric becomes: \\[\\frac{abs(actual - aim)}{max(abs(aim), 0.1)} <= 0.002\\] This is essentially a relative tolerance of +/\u2013 one part in 500 above 0.1 and an absolute tolerance of +/\u2013 0.0002 below 0.1. @import \"../../stylesheets/sections.css\"","title":"Index"},{"location":"guides/rgc-implementation/#aces-reference-gamut-compression-implementation-guide","text":"","title":"ACES Reference Gamut Compression Implementation Guide"},{"location":"guides/rgc-implementation/#scope","text":"The purpose of this document is to detail and define standards for user interface and experience, workflow, tolerances, and tracking of the ACES Reference Gamut Compression ( RGC ) published in ACES 1.3 . For detailed technical specifications, please refer to the ACES Gamut Mapping Architecture VWG - Technical Documentation .","title":"Scope"},{"location":"guides/rgc-implementation/#references","text":"The following standards, specifications, articles, presentations, and texts are referenced in this text: ACES Gamut Mapping Architecture VWG - Technical Documentation Deliverable","title":"References"},{"location":"guides/rgc-implementation/#introduction","text":"The ACES Reference Gamut Compression was introduced to help solve ACES user issues with out of gamut (negative) pixels introduced either in the conversion from camera raw RGB via an Input Transform ( IDT ) into ACES AP0 or in the conversion from ACES AP0 into ACES AP1 (ACEScg and ACEScct). These out of gamut pixel values are problematic when their negative components cause issues in compositing, and may also produce visual artifacts when viewed through an ACES Output Transform. User Testing Footage Examples","title":"Introduction"},{"location":"guides/rgc-implementation/#target-audience","text":"This document is targeted at software developers and product managers looking to integrate the Reference Gamut Compression into their software package or library. It will focus on the \u201chow\u201d as opposed to the \u201cwhy\u201d, which is covered in the architecture documentation above.","title":"Target Audience"},{"location":"guides/rgc-implementation/#workflow-recommendations","text":"Workflow As visualized in the flowchart above, it is recommended (in the current absence of AMF for tracking) that most productions utilize the gamut compression in every area - from on set all the way to finishing. This means that at this time, the RGC is \u201calways on\u201d by default in any viewing pipeline. Following the general ACES workflow philosophy, the RGC is only baked into image data at the appropriate stage in the pipeline - which varies based on the needs of the production, as outlined in the flow chart above. For further workflow specifications, please refer to the User Guide .","title":"Workflow Recommendations"},{"location":"guides/rgc-implementation/#reference-implementation-specifications","text":"","title":"Reference Implementation Specifications"},{"location":"guides/rgc-implementation/#versioning-and-naming","text":"The Reference Gamut Compression published in ACES 1.3 uses the following ACES Transform ID and ACES User Name in the CTL : <ACEStransformID>urn:ampas:aces:transformId:v1.5:LMT.Academy.ReferenceGamutCompress.a1.v1.0</ACEStransformID> <ACESuserName>ACES 1.3 Look - Reference Gamut Compress</ACESuserName> Implementers should only make the RGC available in the UI when their application has the ACES version set to 1.3 or higher.","title":"Versioning and Naming"},{"location":"guides/rgc-implementation/#project-and-clip-level-setting","text":"When an application has the ACES version set to 1.3 or higher, a simple check-box (defaulting to on ) should be exposed in the project settings which applies the RGC to all clips in the project. DaVinci Resolve project level RGC setting An override should be provided at the clip level, so that the user can control the RGC setting for individual clips, if required. DaVinci Resolve clip level RGC setting Implementers may also choose to offer a parametric variation of the RGC (see Section 9 ).","title":"Project and Clip Level Setting"},{"location":"guides/rgc-implementation/#export-settings","text":"The user should be able to easily control whether rendered media will have the RGC \u201cbaked in\u201d. Options should be available so that exports can either follow the global project setting, individual clip settings, or be forced to either on or off for all clips. If an application offers export templates, then templates should be provided which force the RGC off when rendering EXRs (following the recommended workflow for VFX pulls) and follow the clip settings when rendering deliverables with an Output Transform baked in.","title":"Export Settings"},{"location":"guides/rgc-implementation/#test-images-and-tolerances","text":"Test image (without RGC) with sRGB Output Transform applied To aid with validation of implementations, a test image has been created which covers a wide dynamic range (including negatives) and contains values which exceed the AP1 gamut in every direction. It also includes ColorCheckers at varying exposures, to confirm that the gamut compression does not alter colors within the \u201czone of trust\u201d. The Python code to create the test image can be found in this Google Colab . The resulting test file can be downloaded from here , and the test image processed through the CTL implementation of the RGC can be downloaded from here (Note: ctlrender adds an alpha channel to the result, which can be ignored.) For comparison of an implementation with the reference, a relative error metric has been defined (see Appendix A ). The command-line application oiiotool , which is installed as a component of OpenImageIO , can be used to compare pixels between two images and evaluate the metric specified above, using the following command line (with test_target.exr replaced with the name of the file under test): oiiotool gc_test_image_v007_gamut_compressed_ctlrender.exr --dup test_target.exr --absdiff --swap --abs --maxc 0.1 --div --rangecheck 0,0,0 .002,.002,.002 -o /tmp/tmp.exr A match within tolerances will produce the following output: 0 < 0,0,0 0 > .002,.002,.002 2073600 within range Implementers are of course free to use their own code to perform validation, as long as it applies the same metric.","title":"Test Images and Tolerances"},{"location":"guides/rgc-implementation/#tracking-via-aces-metadata-file-amf","text":"The Reference Gamut Compression is trackable via a lookTransform element in an AMF file. If the RCG is used in the viewing pipeline, the lookTransform will be listed in the associated AMF . If the AMF is accompanying rendered media, use the applied flag to track whether or not the RGC has been \u201cbaked in\u201d. See below for an example AMF : <aces:inputTransform applied=\"true\"> \u2026 </aces:inputTransform> <aces:lookTransform applied=\"true\"> <aces:description>ACES 1.3 Look - Reference Gamut Compress</aces:description> <aces:transformId>urn:ampas:aces:transformId:v1.5:LMT.Academy. ReferenceGamutCompress.a1.v1.0</aces:transformId> </aces:lookTransform> If using the RGC in a viewing pipeline, this lookTransform should appear directly after the IDT , first in the list of any LMTs, to make sure other operations benefit from the gamut compression. The Transform ID outlined in the specification section should be included in any exported AMFs, with the applied flag set as appropriate, and the description set to the ACESuserName to enable proper tracking. Currently, only the Reference (i.e. static) Gamut Compression is trackable via AMF .","title":"Tracking via ACES Metadata File (AMF)"},{"location":"guides/rgc-implementation/#parametric-version-implementation-specifications","text":"An implementation of the gamut compression transform which exposes the parameters to the user should be treated differently than the ACES RGC and grouped with other, creative color correction operators instead. As a creative color correction tool, the parametric gamut compression transform is expected to be used as part of a color correction operator stack. This parametric transform can be useful to achieve a desired \u201clook\u201d or manage out-of-gamut artifacts created earlier in the process chain that were not, or could not, be addressed by the RGC . The parametric version should not be used as a replacement for the RGC since it cannot be tracked by AMF . While such an operator is not explicitly endorsed, the following recommendations are made to facilitate a common user experience across implementations: Parameters UI Label Components Slider Range Default Value(s) / Slider Detents Distance Limit Limit 3 (Cyan, Magenta, Yellow) 1.001 - 2.000 C:1.147, M:1.264, Y:1.312 Compression Threshold Threshold 3 (Cyan, Magenta, Yellow) 0.000 - 1.000 C:0.815, M:0.803, Y:0.880 Power Curve Exponent Roll-off 1 0.500 - 2.000 1.200 These default values will exactly match a parametric implementation to the RGC . DaVinci Resolve Parametric Gamut Compress Settings","title":"Parametric Version Implementation Specifications"},{"location":"guides/rgc-implementation/#appendices","text":"","title":"Appendices"},{"location":"guides/rgc-implementation/#appendix-a-relative-metric-detail","text":"Where video and logarithmic encodings are typically sufficiently perceptually uniform that a simple absolute error metric such as (actual - aim) may be used, scene-linear encodings require a tolerance that is tighter for dark colors and looser for bright colors. This is due to the approximately logarithmic nature of human color perception (although the metric is actually computed per channel). When comparing an aim and actual value, a basic relative error metric has the form: \\[\\frac{(actual - aim)}{aim}\\] However this can become overly sensitive when the values being compared become very small. In the limit, when the aim value is zero, the result is either infinity or NaN . Therefore it is useful to use a \u201csafe-guarded relative error metric\u201d that places a lower bound on the denominator: \\[\\frac{(actual - aim)}{max(aim, lower\\_bound)}\\] This effectively transitions the error metric from being a relative error metric for bright and normal colors to an absolute error metric when approaching a certain noise floor determined by the lower_bound constant. A reasonable lower_bound constant for images in ACES2065-1 color space would be 0.1. It is also necessary to handle the case where the aim value may be negative, in which case the final error metric becomes: \\[\\frac{abs(actual - aim)}{max(abs(aim), 0.1)} <= 0.002\\] This is essentially a relative tolerance of +/\u2013 one part in 500 above 0.1 and an absolute tolerance of +/\u2013 0.0002 below 0.1. @import \"../../stylesheets/sections.css\"","title":"Appendix A: Relative metric detail"},{"location":"guides/rgc-user/","text":"ACES Reference Gamut Compression User Guide \u00b6 Scope \u00b6 The purpose of this document is to elaborate on suggested user workflows for on set, dailies, visual effects, and finishing using the ACES Reference Gamut Compression ( RGC ). For detailed technical specifications, please refer to the ACES Gamut Mapping Architecture VWG - Technical Documentation. References \u00b6 The following standards, specifications, articles, presentations, and texts are referenced in this text: ACES Gamut Mapping Architecture VWG - Technical Documentation Deliverable Introduction \u00b6 A common complaint from users of ACES has been the artifacts resulting from out of gamut values in source images. These artifacts are most known for appearing in highly saturated, bright LED light sources such as police car lights, stoplights, etc - but also show up frequently in LED sources used to light scenes. In an ACES workflow, these artifacts appear at two stages - first in the conversion from camera raw RGB via an Input Transform ( IDT ) into ACES AP0 - and second in the conversion from ACES AP0 into ACES AP1 (ACEScg and ACEScct). These out of gamut pixel values are problematic when their negative components cause issues in compositing, and may also produce visual artifacts when viewed through an ACES Output Transform. A Look Modification Transform ( LMT ) referred to as the blue light artifact fix was created as a temporary solution, but this solution affected all pixels in the image, rather than just the problem areas. A new solution was needed which preserved colors within a \u201czone of trust\u201d, only altering the most saturated values. The Reference Gamut Compression algorithm published in ACES 1.3 is intended to replace and deprecate the Blue Light Artifact LMT . Various options were investigated, and the working group finally settled on a simple RGB ratio based algorithm which compresses values based on their distance from the neutral axis. This makes no attempt to ascertain the \u201ccorrect\u201d value for a pixel, since the nature of the problem means that these pixels may have no correct color. The algorithm is intended as a technical correction rather than an aesthetic look. It \u201cheals\u201d the problem pixels, to produce new RGB values which are less problematic when used in subsequent compositing or grading operations. Creative modifications are left for the user to apply as necessary downstream of the RGC . The ACES Reference Gamut Compression uses fixed values 1 for the thresholds where compression begins, and for the amount of compression. These values have been calculated such that the colors of the ColorChecker 24 will remain unchanged, and that any colors that are within the encoding gamuts of all the commonly used digital cinema cameras (those with official ACES IDTs) will be brought within AP1, thus ensuring positive ACEScg values. In most workflows, these constants will be invisible to the user, as demonstrated in the screenshots from Resolve 17.4 below - the user has the option to apply the RGC at a project or a clip level. Reference Gamut Compression enabled via Project Settings in DaVinci Resolve 17.4 Reference Gamut Compression individual clip settings in DaVinci Resolve 17.4 In the example below, artifacts such as the magenta solarization seen on the nose of the Okja toy are greatly reduced by application of the RGC . Without the RGC With the RGC applied Though the algorithm itself and application to an image is relatively simple, there are many considerations to discuss for overall workflows for an ACES project, from on set through to finishing. General Workflow \u00b6 As visualized in the flowchart above, it is recommended (in the current absence of AMF for tracking) that most productions utilize the gamut compression in every area - from on set all the way to finishing. This means that at this time, for simplicity, the the RGC is \u201calways on\u201d by default in any viewing pipeline. Following the general ACES workflow philosophy, the RGC is only baked in to image data at the appropriate stage in the pipeline - which varies based on the needs of your production, as outlined in the flow chart and explained below. On Set \u00b6 Live Grading \u00b6 If your production is utilizing an on set grading software, such as Pomfort Livegrade, use it to apply the Reference Gamut Compression. This will embed the RGC in the 3D LUT which is passed to the LUT box for viewing on a monitor. In-Camera \u00b6 The production can create a 3D LUT of the appropriate size (normally 33x33x33 max) with the Reference Gamut Compression added to the existing viewing pipeline to load into the camera. Dailies \u00b6 Use a dailies generation software, such as Colorfront or Resolve, to import the original camera footage, and apply the Reference Gamut Compression as a part of your viewing pipeline for export to desired media. Editorial \u00b6 Use media supplied from dailies, and back from VFX , to verify media as work progresses. As editorial is largely offline and based on proxy media, the RGC , as viewed on set, should be baked into the files sent to editorial. VFX \u00b6 Frame pulls for VFX should NOT have the Reference Gamut Compression baked in. The files should be debayered to AP0. VFX will have the flexibility to apply the RGC wherever is best for their compositing chain. This will often be the first node in the tree, but sometimes operations such as a despill on a bluescreen will need to be performed pre-gamut compression. Sending pulls to VFX in AP0 gives compositors the flexibility to fine tune and control their work. Once applied, the Reference Gamut compression should NOT be inverted before delivery. It is important that the RGC get applied to all WIP QT renders for review and editorial, so as to match dailies. Finishing \u00b6 Finishing software should have the ability to apply the RGC at a project, timeline, or clip level. This should give the colorist flexibility to choose what works best for the project. The RGC should be applied directly after the IDT , ideally before any scaling, grading, or other finishing work. In a pre-conformed timeline, apply the RGC as early as possible. If frames are coming back from VFX , it will be important to track those vs. non- VFX shots, so that the gamut compression is not applied twice. Production Realities \u00b6 Order of Operations \u00b6 The order in which the various operations are applied to an image has a significant impact on the end result. In particular, any scaling will produce a different result depending on whether it is done before or after the RGC , since its removal of negative values can reduce some scaling artifacts. Some applications may give the user detailed control over order of operations, but in others the underlying processes are hidden. This is an important consideration when planning workflows. In compositing in particular, there may be operations (edge despill in keying has been noted) where using the unmodified pixel values gives a preferable result. In these cases it may be necessary for the compositor to have access to both the original and gamut compressed image data in their node tree, choosing between them as necessary. For consistency, the RGC should still be applied at some other suitable point in the composite, such that the final renders delivered to DI still have the gamut compression applied as expected. Since normal practice in VFX is to return images with any pixel not touched by the compositing process unmodified from the original pulls, one might think that the RGC should be inverted for deliverables, as is done with CDL corrections, for example. However, it is better to think of the RGC more like a spill suppression, which is part of the composite, and would not be inverted out at the end. Inverting creates the possibility that elements added during compositing (CGI originally created in ACEScg, for example) which have not had the RGC applied may produce extreme values on inversion. An inverse mode is included in the algorithm, but is provided only for edge cases where it proves unavoidable. Some education of the various stakeholders may be required to establish why inverting is not preferable. Tracking \u00b6 In the long term, the expectation is that application of the RGC will be tracked using AMF (the ACES Metadata File). This will enable selective use of the algorithm, rather than the currently recommended default of \u201calways on\u201d. Since AMF is currently in development by the various software vendors, this will not be practical until AMF is widely implemented. Unless AMF can be relied upon to be correctly read and updated at every stage of the process, it will be of little use \u2013 incorrect metadata is worse that no metadata. The RGC is classed as an LMT (Look Modification Transform). But unlike most LMTs, it is applied first, immediately after the IDT , rather than last, just before the Output Transform. AMF can list multiple LMTs in its specification of the viewing pipeline for a shot, so will include one for the RGC as well as optionally one for a scene/show look. Compositing and grading work will be done between these two LMTs. LMT elements in an AMF include an applied attribute, so a shot which was previously viewed (e.g. on set) with the RGC enabled will include an LMT for the RGC , with the applied attribute set to false . If the shot is then passed through VFX , and the RGC is then baked in, the applied attribute should be set to true in the AMF returned with the shot to finishing. This will enable the finishing system to automatically apply the RGC to original footage, but disable it for shots from VFX . In the short term, manual tracking will be needed. This is the reason for the recommendation to have the RGC always enabled in the viewing pipeline (and therefore baked into any media which includes the Output Transform). A slight complexity is introduced by the requirement to apply the RGC before compositing work, and therefore bake it into any VFX renders. This means it is necessary for anybody working with a shot which has passed through VFX (including both colorists and VFX artists adding a secondary compositing pass) to take account of the fact that the RGC is already baked in, and not apply it a second time. Until AMF automates this process, careful communication, and agreement upon standard practices will be required. Please note that the workflows outlined in this guide are recommendations, but the needs may vary by facility and production. 3D LUT Implementation \u00b6 While it is generally recommended to use full precision CPU/GPU implementations of the ACES RGC transform some use cases may still require a 3D LUT based implementation instead. Examples for this include (but are not limited to): On-set monitoring of live camera feeds Implementations using legacy versions of OpenColorIO (v2.0 or earlier) Other DCC applications that do not yet support ACES v1.3 The two main considerations for a 3D LUT implementation of the ACES RGC are the LUT input color space and the transform precision. LUT Input Color Space: \u00b6 3D LUT input domains are usually in a 0.0 to 1.0 range (or equivalent integer ranges). Since out-of-gamut color samples have component values below zero an appropriate LUT input color space must be used in which all expected color samples map into the 0.0 to 1.0 range. For on-set monitoring, where the input gamut is known and fixed, such an input color space could be the camera\u2019s specific log-encoding (e.g. LogC3/ARRIWideGamut, Log3G10/REDWideGamutRGB). These encodings are optimized for the particular camera model and are expected to map all color samples into the 0.0\u21921.0 domain. Please note that ACEScct does not fulfill this requirement, even if it is available as a camera RAW development target, and is therefore not recommended to be used as an input encoding for a 3D LUT implementation of the RGC . So for visual effects, review or mastering applications that have to account for multiple input gamuts and are not able to rely on a specific camera vendor encoding an analytic implementation is required. LUT Precision: \u00b6 To achieve a reasonable approximation of the ACES RGC transform a 3D LUT implementation should use the highest practical resolution (e.g. 65x65x65) as well as tetrahedral interpolation. However, even with high resolution LUTs , the residual interpolation errors are significant enough to prevent accurate inversion of the transform, especially at the gamut boundaries. Therefore 3D LUT implementations of the RGC should be considered non-invertible. Implementation Guide \u00b6 If you are a software developer or engineer looking for technical implementation guidelines for integrating the ACES Reference Gamut Compression in software, please see our Implementation Guide . Appendix \u00b6 Before and after images, viewed through the Rec. 709 Output Transform @import \"../../stylesheets/sections.css\" Some implementations may also include a parametric version of the ACES gamut compression. If you choose to use this, it falls outside the scope of published ACES workflows, and therefore will need to be tracked manually. At that point it is simply another creative tool in the colorist\u2019s arsenal. \u21a9","title":"Index"},{"location":"guides/rgc-user/#aces-reference-gamut-compression-user-guide","text":"","title":"ACES Reference Gamut Compression User Guide"},{"location":"guides/rgc-user/#scope","text":"The purpose of this document is to elaborate on suggested user workflows for on set, dailies, visual effects, and finishing using the ACES Reference Gamut Compression ( RGC ). For detailed technical specifications, please refer to the ACES Gamut Mapping Architecture VWG - Technical Documentation.","title":"Scope"},{"location":"guides/rgc-user/#references","text":"The following standards, specifications, articles, presentations, and texts are referenced in this text: ACES Gamut Mapping Architecture VWG - Technical Documentation Deliverable","title":"References"},{"location":"guides/rgc-user/#introduction","text":"A common complaint from users of ACES has been the artifacts resulting from out of gamut values in source images. These artifacts are most known for appearing in highly saturated, bright LED light sources such as police car lights, stoplights, etc - but also show up frequently in LED sources used to light scenes. In an ACES workflow, these artifacts appear at two stages - first in the conversion from camera raw RGB via an Input Transform ( IDT ) into ACES AP0 - and second in the conversion from ACES AP0 into ACES AP1 (ACEScg and ACEScct). These out of gamut pixel values are problematic when their negative components cause issues in compositing, and may also produce visual artifacts when viewed through an ACES Output Transform. A Look Modification Transform ( LMT ) referred to as the blue light artifact fix was created as a temporary solution, but this solution affected all pixels in the image, rather than just the problem areas. A new solution was needed which preserved colors within a \u201czone of trust\u201d, only altering the most saturated values. The Reference Gamut Compression algorithm published in ACES 1.3 is intended to replace and deprecate the Blue Light Artifact LMT . Various options were investigated, and the working group finally settled on a simple RGB ratio based algorithm which compresses values based on their distance from the neutral axis. This makes no attempt to ascertain the \u201ccorrect\u201d value for a pixel, since the nature of the problem means that these pixels may have no correct color. The algorithm is intended as a technical correction rather than an aesthetic look. It \u201cheals\u201d the problem pixels, to produce new RGB values which are less problematic when used in subsequent compositing or grading operations. Creative modifications are left for the user to apply as necessary downstream of the RGC . The ACES Reference Gamut Compression uses fixed values 1 for the thresholds where compression begins, and for the amount of compression. These values have been calculated such that the colors of the ColorChecker 24 will remain unchanged, and that any colors that are within the encoding gamuts of all the commonly used digital cinema cameras (those with official ACES IDTs) will be brought within AP1, thus ensuring positive ACEScg values. In most workflows, these constants will be invisible to the user, as demonstrated in the screenshots from Resolve 17.4 below - the user has the option to apply the RGC at a project or a clip level. Reference Gamut Compression enabled via Project Settings in DaVinci Resolve 17.4 Reference Gamut Compression individual clip settings in DaVinci Resolve 17.4 In the example below, artifacts such as the magenta solarization seen on the nose of the Okja toy are greatly reduced by application of the RGC . Without the RGC With the RGC applied Though the algorithm itself and application to an image is relatively simple, there are many considerations to discuss for overall workflows for an ACES project, from on set through to finishing.","title":"Introduction"},{"location":"guides/rgc-user/#general-workflow","text":"As visualized in the flowchart above, it is recommended (in the current absence of AMF for tracking) that most productions utilize the gamut compression in every area - from on set all the way to finishing. This means that at this time, for simplicity, the the RGC is \u201calways on\u201d by default in any viewing pipeline. Following the general ACES workflow philosophy, the RGC is only baked in to image data at the appropriate stage in the pipeline - which varies based on the needs of your production, as outlined in the flow chart and explained below.","title":"General Workflow"},{"location":"guides/rgc-user/#on-set","text":"","title":"On Set"},{"location":"guides/rgc-user/#dailies","text":"Use a dailies generation software, such as Colorfront or Resolve, to import the original camera footage, and apply the Reference Gamut Compression as a part of your viewing pipeline for export to desired media.","title":"Dailies"},{"location":"guides/rgc-user/#editorial","text":"Use media supplied from dailies, and back from VFX , to verify media as work progresses. As editorial is largely offline and based on proxy media, the RGC , as viewed on set, should be baked into the files sent to editorial.","title":"Editorial"},{"location":"guides/rgc-user/#vfx","text":"Frame pulls for VFX should NOT have the Reference Gamut Compression baked in. The files should be debayered to AP0. VFX will have the flexibility to apply the RGC wherever is best for their compositing chain. This will often be the first node in the tree, but sometimes operations such as a despill on a bluescreen will need to be performed pre-gamut compression. Sending pulls to VFX in AP0 gives compositors the flexibility to fine tune and control their work. Once applied, the Reference Gamut compression should NOT be inverted before delivery. It is important that the RGC get applied to all WIP QT renders for review and editorial, so as to match dailies.","title":"VFX"},{"location":"guides/rgc-user/#finishing","text":"Finishing software should have the ability to apply the RGC at a project, timeline, or clip level. This should give the colorist flexibility to choose what works best for the project. The RGC should be applied directly after the IDT , ideally before any scaling, grading, or other finishing work. In a pre-conformed timeline, apply the RGC as early as possible. If frames are coming back from VFX , it will be important to track those vs. non- VFX shots, so that the gamut compression is not applied twice.","title":"Finishing"},{"location":"guides/rgc-user/#production-realities","text":"","title":"Production Realities"},{"location":"guides/rgc-user/#order-of-operations","text":"The order in which the various operations are applied to an image has a significant impact on the end result. In particular, any scaling will produce a different result depending on whether it is done before or after the RGC , since its removal of negative values can reduce some scaling artifacts. Some applications may give the user detailed control over order of operations, but in others the underlying processes are hidden. This is an important consideration when planning workflows. In compositing in particular, there may be operations (edge despill in keying has been noted) where using the unmodified pixel values gives a preferable result. In these cases it may be necessary for the compositor to have access to both the original and gamut compressed image data in their node tree, choosing between them as necessary. For consistency, the RGC should still be applied at some other suitable point in the composite, such that the final renders delivered to DI still have the gamut compression applied as expected. Since normal practice in VFX is to return images with any pixel not touched by the compositing process unmodified from the original pulls, one might think that the RGC should be inverted for deliverables, as is done with CDL corrections, for example. However, it is better to think of the RGC more like a spill suppression, which is part of the composite, and would not be inverted out at the end. Inverting creates the possibility that elements added during compositing (CGI originally created in ACEScg, for example) which have not had the RGC applied may produce extreme values on inversion. An inverse mode is included in the algorithm, but is provided only for edge cases where it proves unavoidable. Some education of the various stakeholders may be required to establish why inverting is not preferable.","title":"Order of Operations"},{"location":"guides/rgc-user/#tracking","text":"In the long term, the expectation is that application of the RGC will be tracked using AMF (the ACES Metadata File). This will enable selective use of the algorithm, rather than the currently recommended default of \u201calways on\u201d. Since AMF is currently in development by the various software vendors, this will not be practical until AMF is widely implemented. Unless AMF can be relied upon to be correctly read and updated at every stage of the process, it will be of little use \u2013 incorrect metadata is worse that no metadata. The RGC is classed as an LMT (Look Modification Transform). But unlike most LMTs, it is applied first, immediately after the IDT , rather than last, just before the Output Transform. AMF can list multiple LMTs in its specification of the viewing pipeline for a shot, so will include one for the RGC as well as optionally one for a scene/show look. Compositing and grading work will be done between these two LMTs. LMT elements in an AMF include an applied attribute, so a shot which was previously viewed (e.g. on set) with the RGC enabled will include an LMT for the RGC , with the applied attribute set to false . If the shot is then passed through VFX , and the RGC is then baked in, the applied attribute should be set to true in the AMF returned with the shot to finishing. This will enable the finishing system to automatically apply the RGC to original footage, but disable it for shots from VFX . In the short term, manual tracking will be needed. This is the reason for the recommendation to have the RGC always enabled in the viewing pipeline (and therefore baked into any media which includes the Output Transform). A slight complexity is introduced by the requirement to apply the RGC before compositing work, and therefore bake it into any VFX renders. This means it is necessary for anybody working with a shot which has passed through VFX (including both colorists and VFX artists adding a secondary compositing pass) to take account of the fact that the RGC is already baked in, and not apply it a second time. Until AMF automates this process, careful communication, and agreement upon standard practices will be required. Please note that the workflows outlined in this guide are recommendations, but the needs may vary by facility and production.","title":"Tracking"},{"location":"guides/rgc-user/#3d-lut-implementation","text":"While it is generally recommended to use full precision CPU/GPU implementations of the ACES RGC transform some use cases may still require a 3D LUT based implementation instead. Examples for this include (but are not limited to): On-set monitoring of live camera feeds Implementations using legacy versions of OpenColorIO (v2.0 or earlier) Other DCC applications that do not yet support ACES v1.3 The two main considerations for a 3D LUT implementation of the ACES RGC are the LUT input color space and the transform precision.","title":"3D LUT Implementation"},{"location":"guides/rgc-user/#implementation-guide","text":"If you are a software developer or engineer looking for technical implementation guidelines for integrating the ACES Reference Gamut Compression in software, please see our Implementation Guide .","title":"Implementation Guide"},{"location":"guides/rgc-user/#appendix","text":"Before and after images, viewed through the Rec. 709 Output Transform @import \"../../stylesheets/sections.css\" Some implementations may also include a parametric version of the ACES gamut compression. If you choose to use this, it falls outside the scope of published ACES workflows, and therefore will need to be tracked manually. At that point it is simply another creative tool in the colorist\u2019s arsenal. \u21a9","title":"Appendix"},{"location":"specifications/acescct/","text":"@import \"../../stylesheets/sections.css\" ACEScct \u2013 A Quasi-Logarithmic Encoding of ACES Data for use within Color Grading Systems \u00b6 Introduction \u00b6 The Academy Color Encoding Specification ( ACES ) defines a common color encoding method using half- precision floating point values corresponding to linear exposure values encoded relative to a fixed set of extended-gamut RGB primaries. Many digital-intermediate color grading systems have been engineered assuming image data with primaries similar to the grading display and a logarithmic relationship between relative scene exposures and image code values. This document describes a 32-bit single precision floating-point logarithm encoding of ACES known as ACEScct. ACEScct uses values above 1.0 and below 0.0 to encode the entire range of ACES values. ACEScct values should not be clamped except as part of color correction needed to produce a desired artistic intent. There is no image file container format specified for use with ACEScct as the encoding is intended to be transient and internal to software or hardware systems, and is specifically not intended for interchange or archiving. For ACES values greater than 0.0078125, the ACEScct encoding function is identical to the pure-log encoding function of ACEScc. Below this point, the addition of a \u201dtoe\u201d results in a more distinct \u201dmilking\u201d or \u201dfogging\u201d of shadows when a lift operation is applied when compared to the same operation applied in ACEScc. This difference in grading behavior is provided in response to colorist requests for behavior more similar to that of traditional legacy log film scan encodings. Scope \u00b6 This document describes a 32-bit floating point encoding of ACES for use within color grading systems. Equivalent functions may be used for implementation purposes as long as correspondence of grading param- eters to this form of log implementation is properly maintained. This document is intended as a guideline to aid developers who are integrating an ACES workflow into a color correction system. References \u00b6 The following standards, specifications, articles, presentations, and texts are referenced in this text: ST 2065-1:2021 - SMPTE Standard - Academy Color Encoding Specification ( ACES ) RP 177:1993 - SMPTE Recommended Practice - Derivation of Basic Television Color Equations Specification \u00b6 Naming conventions \u00b6 The quasi-logarithmic encoding of ACES specified below shall be known as ACEScct. Color component value encoding \u00b6 ACEScct values are encoded as 32-bit floating-point numbers. This floating-point encoding uses 32 bits per component as described in IEEE 754. Color space chromaticities \u00b6 ACEScct uses a different set of primaries than ACES RGB primaries defined in SMPTE ST 2065-1. The CIE 1931 colorimetry of the ACEScct RGB primaries and white are specified below. Color primaries \u00b6 The chromaticity values of the RGB primaries (known as AP1) shall be those found below: R G B CIE x CIE y Red 1.0 0.0 0.0 0.713 0.293 Green 0.0 1.0 0.0 0.165 0.830 Blue 0.0 0.0 1.0 0.128 0.044 ACEScct RGB primaries chromaticity values White point \u00b6 The white point shall be: R G B CIE x CIE y White 1.0 1.0 1.0 0.32168 0.33767 ACEScct RGB white point chromaticity values ACEScct \u00b6 The following functions shall be used to convert between ACES values, encoded according to SMPTE ST 2065-1, and ACEScct. Encoding Function \u00b6 ACES \\(R\\) , \\(G\\) , and \\(B\\) values shall be converted to \\(lin_{AP1}\\) \\(R\\) , \\(G\\) , and \\(B\\) values using the transformation matrix ( \\(TRA_1\\) ) calculated and applied using the methods provided in Section 4 of SMPTE RP 177:1993. \\(lin_{AP1}\\) \\(R\\) , \\(G\\) , and \\(B\\) values shall be converted to ACEScct values according to Equation 1 . \\[\\begin{equation} ACEScct = \\left\\{ \\begin{array}{l l } 10.5402377416545 \\times lin_{AP1} + 0.0729055341958355; & \\quad lin_{AP1} \\leq 0.0078125 \\\\[10pt] \\dfrac{\\log_{2}(lin_{AP1}) + 9.72}{17.52}; & \\quad lin_{AP1} > 0.0078125 \\\\ \\end{array} \\right. \\end{equation}\\] Equation 1: Linear AP1 to ACEScct Equation 2 shows the relationship between ACES \\(R\\) , \\(G\\) , and \\(B\\) values and \\(lin_{AP1}\\) \\(R\\) , \\(G\\) , and \\(B\\) values. \\(TRA_{1}\\) , rounded to 10 significant digits, is derived from the product of \\(NPM_{AP1}\\) inverse and \\(NPM_{AP0}\\) calculated using methods provided in Section 3.3 of SMPTE RP 177:1993. AP0 are the primaries of ACES specified in SMPTE ST 2065-1. AP1 are the primaries of ACEScct specified in Color space chromaticities . \\[\\begin{equation} \\begin{bmatrix} R_{lin_{AP1}}\\\\ G_{lin_{AP1}}\\\\ B_{lin_{AP1}} \\end{bmatrix} = TRA_{1} \\cdot \\begin{bmatrix} R_{ACES}\\\\ G_{ACES}\\\\ B_{ACES} \\end{bmatrix} \\\\ \\end{equation}\\] \\[\\begin{equation} TRA_{1} = \\begin{bmatrix} \\phantom{-}1.4514393161 & -0.2365107469 & -0.2149285693 \\\\ -0.0765537734 & \\phantom{-}1.1762296998 & -0.0996759264 \\\\ \\phantom{-}0.0083161484 & -0.0060324498 & \\phantom{-}0.9977163014 \\\\ \\end{bmatrix} \\\\ \\end{equation}\\] \\[\\begin{equation} TRA_{1} = NPM^{-1}_{AP1} \\cdot NPM_{AP0} \\end{equation}\\] Equation 2: ACES to linear AP1 Decoding Function \u00b6 ACEScct \\(R\\) , \\(G\\) , and \\(B\\) values shall be converted to \\(lin_{AP1}\\) values using Equation 3 . \\[\\begin{equation} lin_{AP1} = \\left\\{ \\begin{aligned} &\\dfrac{\\left(ACEScct-0.0729055341958355\\right)}{10.5402377416545};& ACEScct& \\leq 0.155251141552511 \\\\[10pt] &2^{(ACEScct \\times 17.52-9.72)}; &0.155251141552511 \\leq ACEScct& < \\dfrac{\\log_{2}(65504)+9.72}{17.52} \\\\[10pt] &65504; & ACEScct& \\geq \\dfrac{\\log_{2}(65504)+9.72}{17.52} \\\\ \\end{aligned} \\right. \\end{equation}\\] Equation 3: ACEScct to linear AP1 \\(lin_{AP1}\\) \\(R\\) , \\(G\\) , and \\(B\\) values shall be converted to ACES \\(R\\) , \\(G\\) , and \\(B\\) values using the transformation matrix ( \\(TRA_{2}\\) ) calculated and applied using the methods provided in Section 4 of SMPTE RP 177:1993. Equation 4 shows the relationship between ACES \\(R\\) , \\(G\\) , and \\(B\\) values and ACEScct \\(R\\) , \\(G\\) , and \\(B\\) values. \\(TRA_{2}\\) , rounded to 10 significant digits, is derived from the product of \\(NPM_{AP0}\\) inverse and \\(NPM_{AP1}\\) calculated using methods provided in Section 3.3 of SMPTE RP 177:1993. AP0 are the primaries of ACES specified in SMPTE ST 2065-1. AP1 are the primaries of ACEScct specified in Color space chromaticities . \\[\\begin{equation} \\begin{bmatrix} R_{ACES}\\\\ G_{ACES}\\\\ B_{ACES} \\end{bmatrix} = TRA_{2} \\cdot \\begin{bmatrix} R_{lin_{AP1}}\\\\ G_{lin_{AP1}}\\\\ B_{lin_{AP1}} \\end{bmatrix} \\end{equation}\\] \\[\\begin{equation} TRA_{2} = \\begin{bmatrix} \\phantom{-}0.6954522414 & 0.1406786965 & 0.1638690622 \\\\ \\phantom{-}0.0447945634 & 0.8596711185 & 0.0955343182 \\\\ -0.0055258826 & 0.0040252103 & 1.0015006723 \\\\ \\end{bmatrix} \\end{equation}\\] \\[\\begin{equation} TRA_{2} = NPM^{-1}_{AP1} \\cdot NPM_{AP0} \\end{equation}\\] Equation 4: Linear AP1 to ACES Appendices \u00b6 Appendix A: Application of ASC CDL parameters to ACEScct image data \u00b6 American Society of Cinematographers Color Decision List ( ASC CDL ) slope, offset, power, and saturation modifiers can be applied directly to ACEScct image data. To preserve the extended range of ACEScct values, no limiting function should be applied with ASC CDL parameters. The power function, however, should not be applied to any negative ACEScct values after slope and offset are applied. Slope, offset, and power are applied with the following function. Note ACEScct is not compatible with ASC CDL values generated on-set using the ACESproxy encoding. If there is a need to reproduce a look generated on-set where ACESproxy was used, ACEScc must be used in the dailies and/or DI environment to achieve a match. \\[\\begin{equation} ACEScct_{out} = \\left\\{ \\begin{array}{l r } ACEScct_{in} \\times slope + offset; & \\quad ACEScct_{slopeoffset} \\leq 0 \\\\ (ACEScct_{in} \\times slope + offset)^{power}; & \\quad ACEScct_{slopeoffset} > 0 \\\\ \\end{array} \\right. \\\\ \\end{equation}\\] \\[\\begin{equation} \\begin{array}{l} \\text{Where:}\\\\ ACEScct_{slopeoffset} = ACEScct_{in} \\times slope + offset \\end{array} \\end{equation}\\] ASC CDL Saturation is also applied with no limiting function: \\[\\begin{gather*} luma = 0.2126 \\times ACEScct_{red} + 0.7152 \\times ACEScct_{green} + 0.0722 \\times ACEScct_{blue} \\\\ \\begin{aligned} ACEScct_{red} &= luma + saturation \\times (ACEScct_{red} - luma) \\\\ ACEScct_{green} &= luma + saturation \\times (ACEScct_{green} - luma) \\\\ ACEScct_{blue} &= luma + saturation \\times (ACEScct_{blue} - luma) \\\\ \\end{aligned} \\end{gather*}\\] Appendix B: Reference ACES and ACEScct values \u00b6 The table below contains a series of reference ACES values and the corresponding ACEScct values for developers who wish to validate the accuracy of their implementation. Description ACES (R,G,B) ACEScct (R,G,B) ACES min non-zero ( \\(2^{-24}\\) ) 0.000000059605, 0.000000059605, 0.000000059605 0.072906162, 0.072906162, 0.072906162 ACES middle gray 18% 0.18, 0.18, 0.18 0.4135884, 0.4135884, 0.4135884 ACES max 65504, 65504, 65504 1.4679964, 1.4679964, 1.4679964 ColorChecker Blue 0.08731, 0.07443, 0.27274 0.30893773, 0.31394949, 0.44770345 ColorChecker Green 0.15366, 0.25692, 0.09071 0.39450300, 0.45037864, 0.35672542 ColorChecker Red 0.21743, 0.07070, 0.05130 0.45224438, 0.32502256, 0.31222500 ColorChecker Yellow 0.58921, 0.53944, 0.09157 0.52635207, 0.50997715, 0.35921441 ColorChecker Magenta 0.30904, 0.14818, 0.27426 0.46941309, 0.38243160, 0.44857958 ColorChecker Cyan 0.14900, 0.23377, 0.35939 0.35056940, 0.43296115, 0.47029844","title":"Index"},{"location":"specifications/acescct/#acescct-a-quasi-logarithmic-encoding-of-aces-data-for-use-within-color-grading-systems","text":"","title":"ACEScct \u2013 A Quasi-Logarithmic Encoding of ACES Data for use within Color Grading Systems"},{"location":"specifications/acescct/#introduction","text":"The Academy Color Encoding Specification ( ACES ) defines a common color encoding method using half- precision floating point values corresponding to linear exposure values encoded relative to a fixed set of extended-gamut RGB primaries. Many digital-intermediate color grading systems have been engineered assuming image data with primaries similar to the grading display and a logarithmic relationship between relative scene exposures and image code values. This document describes a 32-bit single precision floating-point logarithm encoding of ACES known as ACEScct. ACEScct uses values above 1.0 and below 0.0 to encode the entire range of ACES values. ACEScct values should not be clamped except as part of color correction needed to produce a desired artistic intent. There is no image file container format specified for use with ACEScct as the encoding is intended to be transient and internal to software or hardware systems, and is specifically not intended for interchange or archiving. For ACES values greater than 0.0078125, the ACEScct encoding function is identical to the pure-log encoding function of ACEScc. Below this point, the addition of a \u201dtoe\u201d results in a more distinct \u201dmilking\u201d or \u201dfogging\u201d of shadows when a lift operation is applied when compared to the same operation applied in ACEScc. This difference in grading behavior is provided in response to colorist requests for behavior more similar to that of traditional legacy log film scan encodings.","title":"Introduction"},{"location":"specifications/acescct/#scope","text":"This document describes a 32-bit floating point encoding of ACES for use within color grading systems. Equivalent functions may be used for implementation purposes as long as correspondence of grading param- eters to this form of log implementation is properly maintained. This document is intended as a guideline to aid developers who are integrating an ACES workflow into a color correction system.","title":"Scope"},{"location":"specifications/acescct/#references","text":"The following standards, specifications, articles, presentations, and texts are referenced in this text: ST 2065-1:2021 - SMPTE Standard - Academy Color Encoding Specification ( ACES ) RP 177:1993 - SMPTE Recommended Practice - Derivation of Basic Television Color Equations","title":"References"},{"location":"specifications/acescct/#specification","text":"","title":"Specification"},{"location":"specifications/acescct/#naming-conventions","text":"The quasi-logarithmic encoding of ACES specified below shall be known as ACEScct.","title":"Naming conventions"},{"location":"specifications/acescct/#color-component-value-encoding","text":"ACEScct values are encoded as 32-bit floating-point numbers. This floating-point encoding uses 32 bits per component as described in IEEE 754.","title":"Color component value encoding"},{"location":"specifications/acescct/#color-space","text":"ACEScct uses a different set of primaries than ACES RGB primaries defined in SMPTE ST 2065-1. The CIE 1931 colorimetry of the ACEScct RGB primaries and white are specified below.","title":"Color space chromaticities"},{"location":"specifications/acescct/#acescct","text":"The following functions shall be used to convert between ACES values, encoded according to SMPTE ST 2065-1, and ACEScct.","title":"ACEScct"},{"location":"specifications/acescct/#appendices","text":"","title":"Appendices"},{"location":"specifications/acescct/#appendix-a-application-of-asc-cdl-parameters-to-acescct-image-data","text":"American Society of Cinematographers Color Decision List ( ASC CDL ) slope, offset, power, and saturation modifiers can be applied directly to ACEScct image data. To preserve the extended range of ACEScct values, no limiting function should be applied with ASC CDL parameters. The power function, however, should not be applied to any negative ACEScct values after slope and offset are applied. Slope, offset, and power are applied with the following function. Note ACEScct is not compatible with ASC CDL values generated on-set using the ACESproxy encoding. If there is a need to reproduce a look generated on-set where ACESproxy was used, ACEScc must be used in the dailies and/or DI environment to achieve a match. \\[\\begin{equation} ACEScct_{out} = \\left\\{ \\begin{array}{l r } ACEScct_{in} \\times slope + offset; & \\quad ACEScct_{slopeoffset} \\leq 0 \\\\ (ACEScct_{in} \\times slope + offset)^{power}; & \\quad ACEScct_{slopeoffset} > 0 \\\\ \\end{array} \\right. \\\\ \\end{equation}\\] \\[\\begin{equation} \\begin{array}{l} \\text{Where:}\\\\ ACEScct_{slopeoffset} = ACEScct_{in} \\times slope + offset \\end{array} \\end{equation}\\] ASC CDL Saturation is also applied with no limiting function: \\[\\begin{gather*} luma = 0.2126 \\times ACEScct_{red} + 0.7152 \\times ACEScct_{green} + 0.0722 \\times ACEScct_{blue} \\\\ \\begin{aligned} ACEScct_{red} &= luma + saturation \\times (ACEScct_{red} - luma) \\\\ ACEScct_{green} &= luma + saturation \\times (ACEScct_{green} - luma) \\\\ ACEScct_{blue} &= luma + saturation \\times (ACEScct_{blue} - luma) \\\\ \\end{aligned} \\end{gather*}\\]","title":"Appendix A: Application of ASC CDL parameters to ACEScct image data"},{"location":"specifications/acescct/#appendix-b-reference-aces-and-acescct-values","text":"The table below contains a series of reference ACES values and the corresponding ACEScct values for developers who wish to validate the accuracy of their implementation. Description ACES (R,G,B) ACEScct (R,G,B) ACES min non-zero ( \\(2^{-24}\\) ) 0.000000059605, 0.000000059605, 0.000000059605 0.072906162, 0.072906162, 0.072906162 ACES middle gray 18% 0.18, 0.18, 0.18 0.4135884, 0.4135884, 0.4135884 ACES max 65504, 65504, 65504 1.4679964, 1.4679964, 1.4679964 ColorChecker Blue 0.08731, 0.07443, 0.27274 0.30893773, 0.31394949, 0.44770345 ColorChecker Green 0.15366, 0.25692, 0.09071 0.39450300, 0.45037864, 0.35672542 ColorChecker Red 0.21743, 0.07070, 0.05130 0.45224438, 0.32502256, 0.31222500 ColorChecker Yellow 0.58921, 0.53944, 0.09157 0.52635207, 0.50997715, 0.35921441 ColorChecker Magenta 0.30904, 0.14818, 0.27426 0.46941309, 0.38243160, 0.44857958 ColorChecker Cyan 0.14900, 0.23377, 0.35939 0.35056940, 0.43296115, 0.47029844","title":"Appendix B: Reference ACES and ACEScct values"},{"location":"specifications/clf/","text":"Common LUT Format ( CLF ) - A Common File Format for Look-Up Tables \u00b6 Introduction \u00b6 Look-Up Tables ( LUTs ) are a common implementation for transformations from one set of color values to another. With a large number of product developers providing software and hardware solutions for LUTs , there is an explosion of unique vendor-specific LUT file formats, which are often only trivially different from each other. This can create workflow problems when a LUT being used on a production is not supported by one or more of the applications being used. Furthermore, many LUT formats are designed for a particular use case only and lack the quality, flexibility, and metadata needed to meet modern requirements. The Common LUT Format ( CLF ) can communicate an arbitrary chain of color operators (also called processing nodes) which are sequentially processed to achieve an end result. The set of available operator types includes matrices, 1D LUTs , 3D LUTs , ASC - CDL , log and exponential shaper functions, and more. Even when 1D or 3D LUTs are not present, CLF can be used to encapsulate any supported color transforms as a text file conforming to the XML schema. Scope \u00b6 This document introduces a human-readable text file format for the interchange of color transformations using an XML schema. The XML format supports Look-Up Tables of several types: 1D LUTs , 3D LUTs , and 3\u00d71D LUTs , as well as additional transformation needs such as matrices, range rescaling, and \u201cshaper LUTs .\u201d The document defines what is a valid CLF file. Though it is not intended as a tutorial for users to create their own files, LUT creators will find it useful to understand the elements and attributes available for use in a CLF file. The document is also not intended to provide guidance to implementors on how to optimize their implementations, but does provide a few notes on the subject. This document assumes the reader has knowledge of basic color transformation operators and XML . References \u00b6 The following standards, specifications, articles, presentations, and texts are referenced in this text: IETF RFC 3066: IETF (Internet Engineering Task Force). RFC 3066: Tags for the Identification of Lan- guages, ed. H. Alvestrand. 2001 IEEE DRAFT Standard P123 Academy S-2014-002, Academy Color Encoding System \u2013 Versioning System Academy TB-2014-002, Academy Color Encoding System Version 1.0 User Experience Guidelines ASC Color Decision List ( ASC CDL ) Transfer Functions and Interchange Syntax. ASC - CDL Release1.2. Joshua Pines and David Reisner. 2009-05-04. Specification \u00b6 General \u00b6 A Common LUT Format ( CLF ) file shall be written using Extensible Markup Language ( XML ) and adhere to a defined XML structure. A CLF file shall have the file extension ' .clf '. The top level element in a CLF file defines a ProcessList which represents a sequential set of color transformations. The result of each individual color transformation feeds into the next transform in the list to create a daisy chain of transforms. An application reads a CLF file and initializes a transform engine to perform the operations in the list. The transform engine reads as input a stream of code values of pixels, performs the calculations and/or interpolations, and writes an output stream representing a new set of code values for the pixels. In the sequence of transformations described by a ProcessList , each ProcessNode performs a transform on a stream of pixel data, and only one input line (input pixel values) may enter a node and only one output line (output pixel values) may exit a node. A ProcessList may be defined to work on either 1- component or 3-component pixel data, however all transforms in the list must be appropriate, especially in the 1-component case (black-and-white) where only 1D LUT operations are allowed. Implementation may process 1-component transforms by applying the same processing to R, G, and B. Figure 1. Example of a ProcessList containing a sequence of multiple ProcessNodes The file format does not provide a mechanism to assign color transforms to either image sequences or image regions. However, the XML structure defining the LUT transform, a ProcessList, may be encapsulated in a larger XML structure potentially providing that mechanism. This mechanism is beyond the scope of this document. Each CLF file shall be completely self-contained requiring no external information or metadata. The full content of a color transform must be included in each file and a color transform may not be incorporated by reference to another CLF file. This restriction ensures that each CLF file can be an independent archival element. Each ProcessList shall be given a unique ID for reference. The data for LUTs shall be an ordered array that is either all floats or all integers. When three RGB color components are present, it is assumed that these are red, green, and blue in that order. There is only one order for how the data array elements are specified in a LUT , which is in general from black to white (from the minimum input value position to the maximum input value position). Arbitrary ordering of list elements is not supported in the format (see XML Elements for details). Note For 3D LUTs , the indexes to the cube are assumed to have regular spacing across the range of input values. To accommodate irregular spacing, a \" halfDomain \" 1D LUT or Log node should be used as a shaper function prior to the 3D LUT . XML Structure \u00b6 General \u00b6 A CLF file shall contain a single occurrence of the XML root element known as the ProcessList. The ProcessList element shall contain one or more elements known as ProcessNodes. The order and number of process nodes is determined by the designer of the CLF file. An example of the overall structure of a simple CLF file is thus: <ProcessList id= \"123\" > <Matrix id= \"1\" > data & metadata </Matrix> <LUT1D id= \"2\" > data & metadata </LUT1D> <Matrix id= \"3\" > data & metadata </Matrix> </ProcessList> XML Version and Encoding \u00b6 A CLF file shall include a starting line that declares XML version number and character encoding. This line is mandatory once in a file and looks like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> Comments \u00b6 The file may also contain XML comments that may be used to describe the structure of the file or save information that would not normally be exposed to a database or to a user. XML comments are enclosed in brackets like so: <!-- This is a comment --> Language \u00b6 It is often useful to identify the natural or formal language in which text strings of XML documents are written. The special attribute named xml:lang may be inserted in XML documents to specify the language used in the contents and attribute values of any element in an XML document. The values of the attribute are language identifiers as defined by IETF RFC 3066. In addition, the empty string may be specified. The language specified by xml:lang applies to the element where it is specified (including the values of its attributes), and to all elements in its content unless overridden with another instance of xml:lang. In particular, the empty value of xml:lang can be used to override a specification of xml:lang on an enclosing element, without specifying another language. White Space \u00b6 Particularly when creating CLF files containing certain elements (such as Array , LUT1D , or LUT3D ) it is desirable that single lines per entry are maintained so that file contents can be scanned more easily by a human reader. There exist some difficulties with maintaining this behavior as XML has some non-specific methods for handling white-space. Especially if files are re-written from an XML parser, white space will not necessarily be maintained. To maintain line layout, XML style sheets may be used for reviewing and checking the CLF file\u2019s entries. Newline Control Characters \u00b6 Different end of line conventions, including <CR> , <LF> , and <CRLF> , are utilized between Mac, Unix, and Windows systems. Different newline characters may result in the collapse of values into one long line of text. To maintain intended linebreaks, CLF specifies that the \u2018newline\u2019 string (i.e. the byte(s) to be interpreted as ending each line of text) shall be the single code value \\(10_{10} = 0\\textrm{A}_{16}\\) (ASCII \u2018Line Feed\u2019 character), also indicated <LF> . Note Parsers of CLF files may choose to interpret Microsoft\u2019s <CR><LF> or older-MacOS\u2019 <CR> newline conventions, but CLF files should only be generated with the <LF> encoding. Note <LF> is the newline convention native to all *nix operating systems (including Linux and modern macOS). XML Elements \u00b6 Figure 2. Object Model of XML Elements ProcessList \u00b6 Description: The ProcessList is the root element for any CLF file and is composed of one or more ProcessNodes. A ProcessList is required even if only one ProcessNode will be present. Note The last node of the ProcessList is expected to be the final output of the LUT . A LUT designer can allow floating-point values to be interpreted by applications and thus delay control of the final encoding through user selections. Note If needed, a Range node can be placed at the end of a ProcessList to control minimum and maximum output values and clamping. Attributes: id (required) a string to serve as a unique identifier of the ProcessList compCLFversion (required) a string indicating the minimum compatible CLF specification version required to read this file The compCLFversion corresponding to this version of the specification is be \"3.0\" . name (optional) a concise string used as a text name of the ProcessList for display or selection from an application\u2019s user interface inverseOf (optional) a string for linking to another ProcessList id (unique) which is the inverse of this one Elements: Description (optional) a string for comments describing the function, usage, or any notes about the ProcessList . A ProcessList can contain zero or more Description elements. InputDescriptor (optional) an arbitrary string used to describe the intended source code values of the ProcessList OutputDescriptor (optional) an arbitrary string used to describe the intended output target of the ProcessList (e.g. target display) ProcessNode (required) a generic XML element that in practice is substituted with a particular color operator. The ProcessList must contain at least one ProcessNode . The ProcessNode is described in ProcessNode . Info (optional) optional element for including additional custom metadata not needed to interpret the transforms. The Info element includes: AppRelease (optional) a string used for indicating application software release level Copyright (optional) a string containing a copyright notice for authorship of the CLF file Revision (optional) a string used to track the version of the LUT itself (e.g. an increased resolution from a previous version of the LUT ) ACEStransformID (optional) a string containing an ACES transform identifier as described in Academy S-2014-002. If the transform described by the ProcessList is the concatenation of several ACES transforms, this element may contain several ACES Transform IDs, separated by white space or line separators. This element is mandatory for ACES transforms and may be referenced from ACES Metadata Files. ACESuserName (optional) a string containing the user-friendly name recommended for use in product user interfaces as described in Academy TB-2014-002 CalibrationInfo (optional) container element for calibration metadata used when making a LUT for a specific device. CalibrationInfo can contain the following child elements: DisplayDeviceSerialNum DisplayDeviceHostName OperatorName CalibrationDateTime MeasurementProbe CalibrationSoftwareName CalibrationSoftwareVersion ProcessNode \u00b6 Description: A ProcessNode element represents an operation to be applied to the image data. At least one ProcessNode element must be included in a ProcessList . The generic ProcessNode element contains attributes and elements that are common to and inherited by the specific sub-types of the ProcessNode element that can substitute for ProcessNode . All ProcessNode substitutes shall inherit the following attributes. Attributes: id (optional) a unique identifier for the ProcessNode name (optional) a concise string defining a name for the ProcessNode that can be used by an application for display in a user interface inBitDepth (required) a string that is used by some ProcessNodes to indicate how array or parameter values have been scaled outBitDepth (required) a string that is used by some ProcessNodes to indicate how array or parameter values have been scaled The supported values for both inBitDepth and outBitDepth are the same: \"8i\" : 8-bit unsigned integer \"10i\" : 10-bit unsigned integer \"12i\" : 12-bit unsigned integer \"16i\" : 16-bit unsigned integer \"16f\" : 16-bit floating point (half-float) \"32f\" : 32-bit floating point (single precision) Elements: Description (optional) an arbitrary string for describing the function, usage, or notes about the ProcessNode. A ProcessNode can contain one or more Descriptions. Array \u00b6 Description: The Array element contains a table of entries with a single line for each grouping of values. This element is used in the LUT1D , LUT3D , and Matrix ProcessNodes. The dim attribute specifies the dimensions of the array and, depending on context, defines the size of a matrix or the length of a LUT table. The specific formatting of the dim attribute must match with the type of node in which it is being used. The usages are summarized below but specific requirements for each application of Array are described when it appears as a child element for a particular ProcessNode . Attributes: dim (required) Specifies the dimension of the LUT or the matrix and the number of color components. The dim attribute provides the dimensionality of the indexes, where: 4 entries represent the dimensions of a 3D cube and the number of components per entry. e.g. dim = 17 17 17 3 indicates a 17-cubed 3D LUT with 3 color components 2 entries represent the dimensions of a matrix. e.g. dim = 3 3 indicates a 3\u00d73 matrix e.g. dim = 3 4 indicates a 3\u00d74 matrix 2 entries represent the length of the LUT and the component value (1 or 3). e.g. dim = 256 3 indicates a 256 element 1D LUT with 3 components (a 3\u00d71D LUT ) e.g. dim = 256 1 indicates a 256 element 1D LUT with 1 component (1D LUT ) Substititues for ProcessNode \u00b6 General \u00b6 The attributes and elements defined for ProcessNode are inherited by the substitutes for ProcessNode . This section defines the available substitutes for the generalized ProcessNode element. The inBitDepth of a ProcessNode must match the outBitDepth of the preceding ProcessNode (if any). LUT1D \u00b6 Description: A 1D LUT transform uses an input pixel value, finds the two nearest index positions in the LUT , and then interpolates the output value using the entries associated with those positions. This node shall contain either a 1D LUT or a 3x1D LUT in the form of an Array . If the input to a LUT1D is an RGB value, the same LUT shall be applied to all three color components. A 3x1D LUT transform looks up each color component in a separate LUT1D of the same length. In a 3x1D LUT , by convention, the LUT1D for the first component goes in the first column of Array . The scaling of the array values is based on the outBitDepth (the inBitDepth is not considered). The length of a 1D LUT should be limited to at most 65536 entries, and implementations are not required to support LUT1D s longer than 65536 entries. Linear interpolation shall be used for LUT1D . More information about linear interpolation can be found in Appendix A . Elements: Array (required) an array of numeric values that are the output values of the 1D LUT . Array shall contain the table entries of a LUT in order from minimum value to maximum value. For a 1D LUT , one value per entry is used for all color channels. For a 3x1D LUT , each line should contain 3 values, creating a table where each column defines a 1D LUT for each color component. For RGB , the first column shall correspond to R\u2019s 1D LUT , the second column shall correspond to G\u2019s 1D LUT , and the third column shall correspond to B\u2019s 1D LUT . Attributes: dim (required) two integers that represent the dimensions of the array. The first value defines the length of the array and shall equal the number of entries (lines) in the LUT . The second value indicates the number of components per entry and shall equal 1 for a 1D LUT or 3 for a 3x1D LUT . Example dim = \"1024 3\" indicates a 1024 element 1D LUT with 3 component color (a 3x1D LUT ) Example dim = \"256 1\" indicates a 256 element 1D LUT with 1 component color (a 1D LUT ) Note Array is formatted differently when it is contained in a LUT3D or Matrix element (see Array ). Attributes: interpolation (optional) a string indicating the preferred algorithm used to interpolate values in the 1DLUT . This attribute is optional but, if present, shall be set to \"linear\" . Note Previous versions of this specification allowed for implementations to utilize different types of interpolation but did not define what those interpolation types were or how they should be labeled. For simplicity and to ensure similarity across implementations, 1D LUT interpolation has been limited to \"linear\" in this version of the specification. Support for additional interpolation types could be added in future version. halfDomain (optional) If this attribute is present, its value must equal \u201ctrue\u201d . When true, the input domain to the node is considered to be all possible 16-bit floating-point values, and there must be exactly 65536 entries in the Array element. Note For example, the unsigned integer 15360 has the same bit-pattern (0011110000000000) as the half-float value 1.0, so the 15360th entry (zero-indexed) in the Array element is the output value corresponding to an input value of 1.0. rawHalfs (optional) If this attribute is present, its value must equal \u201ctrue\u201d . When true, the rawHalfs attribute indicates that the output array values in the form of unsigned 16-bit integers are interpreted as the equivalent bit pattern, half floating-point values. Note For example, to represent the value 1.0, one would use the integer 15360 in the Array element because it has the same bit-pattern. This allows the specification of exact half-float values without relying on conversion from decimal text strings. Examples: <LUT1D id= \"lut-23\" name= \"4 Value Lut\" inBitDepth= \"12i\" outBitDepth= \"12i\" > <Description> 1D LUT - Turn 4 grey levels into 4 inverted codes </Description> <Array dim= \"4 1\" > 3 2 1 0 </Array> </LUT1D> Example 1. Example of a very simple LUT1D LUT3D \u00b6 Description: This node shall contain a 3D LUT in the form of an Array. In a LUT3D, the 3 color components of the input value are used to find the nearest indexed values along each axis of the 3D cube. The 3-component output value is calculated by interpolating within the volume defined by the nearest corresponding positions in the LUT . LUT3Ds have the same dimension on all axes (i.e. Array dimensions are of the form \u201cn n n 3\u201d). A LUT3D with axial dimensions greater than 128x128x128 should be avoided. The scaling of the array values is based on the outBitDepth (the inBitDepth is not considered). Attributes: interpolation (optional) a string indicating the preferred algorithm used to interpolate values in the 3DLUT. This attribute is optional with a default of \"trilinear\" if the attribute is not present. Supported values are: \"trilinear\" : perform trilinear interpolation \"tetrahedral\" : perform tetrahedral interpolation Note Interpolation methods are specified in Appendix A . Elements: Array (required) an array of numeric values that are the output values of the 3D LUT . The Array shall contain the table entries for the LUT3D from the minimum to the maximum input values, with the third component index changing fastest. Attributes: dim (required) four integers that reperesent the dimensions of the 3D LUT and the number of color com- ponents. The first three values define the dimensions of the LUT and if multiplied shall equal the number of entries actually present in the array. The fourth value indicates the number of components per entry. 4 entries have the dimensions of a 3D cube plus the number of components per entry. Example dim = \"17 17 17 3\" indicates a 17-cubed 3D lookup table with 3 component color Note Array is formatted differently when it is contained in a LUT1D or Matrix element (see Array ). Examples: <LUT3D id= \"lut-24\" name= \"green look\" interpolation= \"trilinear\" inBitDepth= \"12i\" outBitDepth= \"16f\" > <Description> 3D LUT </Description> <Array dim= \"2 2 2 3\" > 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 1.0 1.0 </Array> </LUT3D> Example 2. Example of a simple LUT3D Matrix \u00b6 Description: This node specifies a matrix transformation to be applied to the input values. The input and output of a Matrix are always 3-component values. All matrix calculations should be performed in floating point, and input bit depths of integer type should be treated as scaled floats. If the input bit depth and output bit depth do not match, the coefficients in the matrix must incorporate the results of the \u2018scale\u2019 factor that will convert the input bit depth to the output bit depth (e.g. input of 10i with an output of 12i requires the matrix coefficients already have a factor of \\(4095/1023\\) applied). Changing the input or output bit depth requires creation of a new set of coefficients for the matrix. The output values are calculated using row-order convention: \\[ \\begin{bmatrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\\\ a_{31} & a_{32} & a_{33} \\\\ \\end{bmatrix} \\begin{bmatrix} r_1\\\\ g_1\\\\ b_1 \\end{bmatrix} = \\begin{bmatrix} r_2\\\\ g_2\\\\ b_2 \\end{bmatrix} \\] which is equivalent in functionality to the following: \\[ \\begin{aligned} r_2 = (r_1 \\cdot a_{11}) + (g_1 \\cdot a_{12}) + (b_1 \\cdot a_{13}) \\\\ g_2 = (r_1 \\cdot a_{21}) + (g_1 \\cdot a_{22}) + (b_1 \\cdot a_{23}) \\\\ b_2 = (r_1 \\cdot a_{31}) + (g_1 \\cdot a_{32}) + (b_1 \\cdot a_{33}) \\end{aligned} \\] Matrices using an offset calculation will have one more column than rows. An offset matrix may be defined using a 3x4 Array , wherein the fourth column is used to specify offset terms, \\(k_1\\) , \\(k_2\\) , \\(k_3\\) : \\[ \\begin{bmatrix} a_{11} & a_{12} & a_{13} & k_1\\\\ a_{21} & a_{22} & a_{23} & k_2\\\\ a_{31} & a_{32} & a_{33} & k_3\\\\ \\end{bmatrix} \\begin{bmatrix} r_1\\\\ g_1\\\\ b_1\\\\ 1.0 \\end{bmatrix} = \\begin{bmatrix} r_2\\\\ g_2\\\\ b_2 \\end{bmatrix} \\] Expanded out, this means that the offset terms \\(k_1\\) , \\(k_2\\) , and \\(k_3\\) are added to each of the normal matrix calculations: \\[ \\begin{aligned} r_2 = (r_1 \\cdot a_{11}) + (g_1 \\cdot a_{12}) + (b_1 \\cdot a_{13}) + k_1\\\\ g_2 = (r_1 \\cdot a_{21}) + (g_1 \\cdot a_{22}) + (b_1 \\cdot a_{23}) + k_2\\\\ b_2 = (r_1 \\cdot a_{31}) + (g_1 \\cdot a_{32}) + (b_1 \\cdot a_{33}) + k_3 \\end{aligned} \\] Elements: Array (required) a table that provides the coefficients of the transformation matrix. The matrix dimensions are either 3x3 or 3x4. The matrix is serialized row by row from top to bottom and from left to right, i.e., \" \\(a_{11}\\ a_{12}\\ a_{13}\\ a_{21}\\ a_{22}\\ a_{23}\\ \\ldots\\) \" for a 3x3 matrix. \\[ \\begin{bmatrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\\\ a_{31} & a_{32} & a_{33} \\\\ \\end{bmatrix} \\] Attributes: dim (required) two integers that describe the dimensions of the matrix array. The first value define the number of rows and the second is the number of columns. 2 entries have the dimensions of a matrix Example dim = \"3 3\" indicates a 3x3 matrix Example dim = \"3 4\" indicates a 3x4 matrix Note Previous versions of this specification used three integers for the dim attribute, rather than the current two. In order to facilitate backwards compatibility, implementations should allow a third value for the dim attribute and may simply ignore it. Note Array is formatted differently when nit is contained in a LUT1D or LUT3D element (see Array ) Examples: <Matrix id= \"lut-28\" name= \"AP0 to AP1\" inBitDepth= \"16f\" outBitDepth= \"16f\" > <Description> 3x3 color space conversion from AP0 to AP1 </Description> <Array dim= \"3 3\" > 1.45143931614567 -0.236510746893740 -0.214928569251925 -0.0765537733960204 1.17622969983357 -0.0996759264375522 0.00831614842569772 -0.00603244979102103 0.997716301365324 </Array> </Matrix> Example 3. Example of a Matrix node with dim=\"3 3 3\" <Matrix id= \"lut-25\" name= \"colorspace conversion\" inBitDepth= \"10i\" outBitDepth= \"10i\" > <Description> 3x4 Matrix , 4th column is offset </Description> <Array dim= \"3 4\" > 1.2 0.0 0.0 0.002 0.0 1.03 0.001 -0.005 0.004 -0.007 1.004 0.0 </Array> </Matrix> Example 4. Example of a Matrix node Range \u00b6 Description: This node maps the input domain to the output range by scaling and offsetting values. The Range element can also be used to clamp values. Unless otherwise specified, the node\u2019s default behavior is to scale and offset with clamping. If clamping is not desired, the style attribute can be set to \"noClamp\" . To achieve scale and/or offset of values, all of minInValue , minOutValue , maxInValue , and maxOutValue must be present. In this explicit case, the formula for Range shall be: \\[ out = in \\times scale + \\texttt{minOutValue} - \\texttt{minInValue} \\times scale \\] where: \\(scale = \\dfrac{(\\texttt{maxOutValue} - \\texttt{minOutValue})}{(\\texttt{maxInValue} - \\texttt{minInValue})}\\) The scaling of minInValue and maxInValue depends on the input bit-depth, and the scaling of minOutValue and maxOutValue depends on the output bit-depth. If style=\"Clamp\" , the output value of \\(out\\) from the above equation is furthur modified as follows: \\[ out_{clamped} = \\mathrm{MIN}(\\texttt{maxOutValue}, \\mathrm{MAX}( \\texttt{minOutValue}, out)) \\] where: \\(\\mathrm{MAX}(a,b)\\) returns \\(a\\) if \\(a > b\\) and \\(b\\) if \\(b \\geq a\\) \\(\\mathrm{MIN}(a,b)\\) returns \\(a\\) if \\(a < b\\) and \\(b\\) if \\(b \\leq a\\) The Range element can also be used to clamp values on only the top or bottom end. In such instances, no offset is applied, and the formula simplifies because only one pair of min or max values are required. (The style shall not be \"noClamp\" for this use-case.) If only the minimum value pair is provided, then the result shall be clamping at the low end, according to: \\[ out = \\mathrm{MAX}( \\texttt{minOutValue}, in \\times bitDepthScale) \\] If only the maximum values pairs are provided, the result shall be clamping at the high end, according to: \\[ out = \\mathrm{MIN}( \\texttt{maxOutValue}, in \\times bitDepthScale) \\] where: \\[ bitDepthScale = \\dfrac{\\mathrm{SIZE}(\\texttt{outBitDepth})}{\\mathrm{SIZE}(\\texttt{inBitDepth})} \\] \\[ \\mathrm{SIZE}(a) = \\begin{cases} 2^{bitDepth}-1 & \\text{when }a \\in \\{\\texttt{\"8i\"},\\texttt{\"10i\"},\\texttt{\"12i\"},\\texttt{\"16i\"}\\} \\\\ 1.0 & \\text{when }a \\in \\{\\texttt{\"16f\"},\\texttt{\"32f\"}\\} \\end{cases} \\] In both instances, values must be set such that \\(\\texttt{maxOutValue} = \\texttt{maxInValue} \\times bitDepthScale\\) . Note The bit depth scale factor intentionally uses \\(2^{bitDepth}\u22121\\) and not \\(2^{bitDepth}\\) . This means that the scale factor created for scaling between different bit depths is \"non-integer\" and is slightly different depending on the bit depths being scaled between. While instinct might be that this scale should be a clean bit-shift factor (i.e. \\(2\\times\\) or \\(4\\times\\) scale), testing with a few example values plugged into the formula will show that the resulting non-integer scale is the correct and intended behavior. At least one pair of either minimum or maximum values, or all four values, must be provided. Elements: minInValue (optional) The minimum input value. Required if minOutValue is present. maxInValue (optional) The maximum input value. Required if maxOutValue is present. The maxInValue shall be greater than the minInValue . minOutValue (optional) The minimum output value. Required if minInValue is present. maxOutValue (optional) :The maximum output value. Required if maxInValue is present. The maxOutValue shall be greater than or equal to the minOutValue . Attributes: style (optional) Describes the preferred handling of the scaling calculation of the Range node. If the style attribute is not present, clamping is performed. The options for style are: \"noClamp\" If present, scale and offset is applied without clamping (i.e. values below minOutValue or above maxOutValue are preserved) \"Clamp\" If present, clamping is applied upon the result of the scale and offset expressed by the result of the non-clamping Range equation Examples: <Range inBitDepth= \"10i\" outBitDepth= \"10i\" > <Description> 10-bit full range to SMPTE range </Description> <minInValue> 0 </minInValue> <maxInValue> 1023 </minInValue> <minOutValue> 64 </minInValue> <maxOutValue> 940 </minInValue> </Range> Example 5. Using \"Range\" for scaling 10-bit full range to 10-bit SMPTE (legal) range. Log \u00b6 Description: This node contains parameters for processing pixels through a logarithmic or anti-logarithmic function. A couple of main formulations are supported. The most basic formula follows a pure logarithm or anti-logarithm of either base 2 or base 10. Another supported formula allows for a logarithmic function with a gain factor and offset. This formulation can be used to convert from linear to Cineon. Another style of log formula follows a piece-wise function consisting of a logarithmic function with a gain factor, an offset, and a linear segment. This style can be used to implement many common \u201ccamera-log\u201d encodings. Note The equations for the Log node assume integer data is normalized to floating-point scaling. LogParams do not change based on the input and output bit-depths. Note On occasion it may be necessary to transform a logarithmic function specified in terms of traditional Cineon-style parameters to the parameters used by CLF . Guidance on how to do this is provided in Appendix B . Attributes: style (required specifies the form of the of log function to be applied Supported values for \u201dstyle\u201d are: \"log10\" \"antiLog10\" \"log2\" \"antiLog2\" \"linToLog\" \"logToLin\" \"cameraLinToLog\" \"cameraLogToLin\" The formula to be applied for each style is described by the equations below, for all of which: \\[ \\texttt{FLT_MIN} = 1.175494e\u221238 \\] \\(\\textrm{MAX}(a, b)\\) returns \\(a\\) if \\(a \\gt b\\) and \\(b\\) if \\(b \\geq a\\) \"log10\" : applies a base 10 logarithm according to \\[ y = log_{10}(\\textrm{MAX}(x,\\texttt{FLT_MIN})) \\] \"antiLog10\" : applies a base 10 anti-logarithm according to \\[ x = 10^{y} \\] \"log2\" : applies a base 2 logarithm according to \\[ y = log_{2}(\\textrm{MAX}(x,\\texttt{FLT_MIN})) \\] \"antiLog2\" : applies a base 2 anti-logarithm according to \\[ x = 2^{y} \\] \"linToLog\" : applies a logarithm according to \\[ y = \\text{logSideSlope} \\times \\text{log}_\\text{base}(\\textrm{MAX}(\\text{linSideSlope} \\times x + \\text{linSideOffset}, \\texttt{FLT_MIN}))+\\text{logSideOffset} \\] \"logToLin\" : applies an anti-logarithm according to \\[ x = \\frac{\\left(\\text{base}^{\\frac{y-\\text{logSideOffset}}{\\text{logSideSlope}}} - \\text{linSideOffset}\\right)}{\\text{linSideSlope}} \\] \"cameraLinToLog\" : applies a piecewise function with logarithmic and linear segments on linear values, converting them to non-linear values \\[ y = \\begin{cases} \\text{linearSlope} \\times x + \\text{linearOffset} & \\text{if } x \\leq \\text{linSideBreak}\\\\ \\text{logSideSlope} \\times \\text{log}_{\\text{base}}(\\mathrm{MAX}(\\text{linSideSlope} \\times x + \\text{linSideOffset},\\texttt{FLT_MIN})) + \\text{logSideOffset} & \\text{otherwise} \\\\ \\end{cases} \\\\ \\] Note The calculation of \\(\\text{linearSlope}\\) , and \\(\\text{linearOffset}\\) is described in Solving for LogParams \"cameraLogToLin\" : applies a piecewise function with logarithmic and linear segments on non-linear values, converting them to linear values \\[ x = \\begin{cases} \\frac{(y - \\text{linearOffset})}{\\text{linearSlope}} & \\text{if } y \\leq \\text{logSideBreak} \\\\ \\frac{\\left(\\text{base}^{\\frac{y-\\text{logSideOffset}}{\\text{logSideSlope}}} - \\text{linSideOffset}\\right)}{\\text{linSideSlope}} & \\text{otherwise} \\end{cases} \\] Note The calculation of \\(\\text{logSideBreak}\\) , \\(\\text{linearSlope}\\) , and \\(\\text{linearOffset}\\) is described in Solving for LogParams Elements: LogParams (required - if \"style\" is not a basic logarithm) contains the attributes that control the \"linToLog\" , \"logToLin\" , \"cameraLinToLog\" , or \"cameraLogToLin\" functions This element is required if style is of type \"linToLog\" , \"logToLin\" , \"cameraLinToLog\" , or \"cameraLogToLin\" . Attributes: \"base\" (optional) the base of the logarithmic function Default is 2. \"logSideOffset\" (optional) offset applied to the log side of the logarithmic segment. Default is 0. \"linSideSlope\" (optional) slope of the linear side of the logarithmic segment. Default is 1. \"linSideOffset\" (optional) offset applied to the linear side of the logarithmic segment. Default is 0. \"linSideBreak\" (optional) the break-point, defined in linear space, at which the piece-wise function transitions between the logarithmic and linear segments. This is required if style=\"cameraLinToLog\" or \"cameraLogToLin\" \"linearSlope\" (optional) the slope of the linear segment of the piecewise function. This attribute does not need to be provided unless the formula being implemented requires it. The default is to calculate using linSideBreak such that the linear portion is continuous in value with the logarithmic portion of the curve, by using the value of the logarithmic portion of the curve at the break-point. This is described in the following note below. \"channel\" (optional) the color channel to which the exponential function is applied. Possible values are \"R\" , \"G\" , \"B\" . If this attribute is utilized to target different adjustments per channel, then up to three LogParams elements may be used, provided that \"channel\" is set differently in each. However, the same value of base must be used for all channels. If this attribute is not otherwise specified, the logarithmic function is applied identically to all three color channels. Solving for LogParams \\(\\text{linearOffset}\\) is the offset of the linear segment of the piecewise function. This value is calculated using the position of the break-point and the linear slope in order to ensure continuity of the two segments. The following steps describe how to calculate \\(\\text{linearOffset}\\) . First, the value of the break-point on the log-axis is calculated using the value of \\(\\text{linSideBreak}\\) as input to the logarithmic segment of the piecewise function , as below: \\[ logSideBreak = logSideSlope \u00d7 logbase(linSideSlope \u00d7 linSideBreak + linSideOffset) + logSideOffset \\] Then, if \\(\\text{linearSlope}\\) was not provided, the value of \\(\\text{linSideBreak}\\) is used again to solve for the derivative of the logarithmic function. The value of \\(\\text{linearSlope}\\) is set to equal the instantaneous slope at the break-point, or derivative, as shown below: \\[ \\text{linearSlope} = \\text{logSideSlope} \\times \\left(\\frac{\\text{linSideSlope}}{(\\text{linSideSlope} \\times \\textbf{linSideBreak} + \\text{linSideOffset}) \\times \\text{ln}(\\text{base})}\\right) \\] Finally, the value of \\(\\text{linearOffset}\\) can be solved for by rearranging the linear segment of of the piecewise function and using the values of \\(\\text{logSideBreak|\\) and \\(\\text{linearSlope}\\) \\[ \\text{linearOffset} = \\textbf{logSideBreak} - \\textbf{ linearSlope} \\times \\text{linSideBreak} \\] Examples: <Log inBitDepth= \"16f\" outBitDepth= \"16f\" style= \"log10\" > <Description> Base 10 Logarithm </Description> </Log> Example 6. Log node applying a base 10 logarithm. <Log inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"cameraLinToLog\" > <Description> Linear to DJI D-Log </Description> <LogParams base= \"10\" logSideSlope= \"0.256663\" logSideOffset= \"0.584555\" linSideSlope= \"0.9892\" linSideOffset= \"0.0108\" linSideBreak= \"0.0078\" linearSlope= \"6.025\" /> </Log> Example 7. Log node applying the DJI D-Log formula. Exponent \u00b6 Description: This node contains parameters for processing pixels through a power law function. Two main formulations are supported. The first follows a pure power law. The second is a piecewise function that follows a power function for larger values and has a linear segment that is followed for small and negative values. The latter formulation can be used to represent the Rec. 709, sRGB, and CIE L* equations. Attributes: style (required) specifies the form of the exponential function to be applied. Supported values are: \"basicFwd\" \"basicRev\" \"basicMirrorFwd\" \"basicMirrorRev\" \"basicPassThruFwd\" \"basicPassThruRev\" \"monCurveFwd\" \"monCurveRev\" \"monCurveMirrorFwd\" \"monCurveMirrorRev\" Each of these supported styles are described in detail below, and for all of which the following definitions apply: \\(g =\\) exponent \\(k =\\) offset \\(\\textrm{MAX}(a, b)\\) returns \\(a\\) if \\(a \\gt b\\) and \\(b\\) if \\(b \\geq a\\) \"basicFwd\" applies a power law using the exponent value specified in the ExponentParams element. Values less than zero are clamped. \\[ \\text{basicFwd}(x) = [\\textrm{MAX}(0,x)]^g \\] \"basicRev\" applies power law using the exponent value specified in the ExponentParams element. Values less than zero are clamped. \\[ \\text{basicRev}(y) = [\\textrm{MAX}(0,y)]^{1/g} \\] \"basicMirrorFwd\" applies a basic power law using the exponent value specified in the ExponentParams element for values greater than or equal to zero and mirrors the function for values less than zero (i.e. rotationally symmetric around the origin): \\[ \\text{basicMirrorFwd}(x) = \\begin{cases} x^{g} & \\text{if } x \\geq 0 \\\\ [6pt] -\\Big[(-x)^{g}\\Big] & \\text{otherwise} \\end{cases} \\] \"basicMirrorRev\" applies a basic power law using the exponent value specified in the ExponentParams element for values greater than or equal to zero and mirrors the function for values less than zero (i.e. rotationally symmetric around the origin): \\[ \\text{basicMirrorRev}(y) = \\begin{cases} y^{1/g} & \\text{if } y \\geq 0 \\\\[6pt] -\\Big[(-y)^{1/g}\\Big] & \\text{otherwise} \\end{cases} \\] \"basicPassThruFwd\" applies a basic power law using the exponent value specified in the ExponentParams element for values greater than or equal to zero and passes values less than zero unchanged: \\[ \\text{basicPassThruFwd}(x) = \\begin{cases} x^{g} & \\text{if } x \\geq 0 \\\\[6pt] x & \\text{otherwise} \\end{cases} \\] \"basicPassThruRev\" applies a basic power law using the exponent value specified in the ExponentParams element for values greater than or equal to zero and and passes values less than zero un- changed: \\[ \\text{basicPassThruRev}(y) = \\begin{cases} y^{1/g} & \\text{if } y \\geq 0 \\\\[6pt] y & \\text{otherwise} \\end{cases} \\] \"monCurveFwd\" applies a power law function with a linear segment near the origin \\[ \\text{monCurveFwd}(x) = \\begin{cases} \\left( \\frac{x\\:+\\:k}{1\\:+\\:k} \\right)^{g} & \\text{if } x \\geq xBreak \\\\[8pt] x\\:s & \\text{otherwise} \\end{cases} \\] where: \\(xBreak = \\dfrac{k}{g-1}\\) and, for the \\(\\text{monCurveFwd}\\) ( above ) and \\(\\text{monCurveRev}\\) ( below ) equations: \\(s = \\left(\\dfrac{g-1}{k}\\right) \\left(\\dfrac{k g}{(g-1)(1+k)}\\right)^{g}\\) \"monCurveRev\" applies a power law function with a linear segment near the origin \\[ \\text{monCurveRev}(y) = \\begin{cases} (1 + k)\\:y^{(1/g)} - k & \\text{if } y \\geq yBreak \\\\[8pt] \\dfrac{y}{s} & \\text{otherwise} \\end{cases} \\] where: \\(yBreak = \\left(\\dfrac{k g}{(g-1)(1+k)}\\right)^g\\) \"monCurveMirrorFwd\" applies a power law function with a linear segment near the origin and mirrors the function for values less than zero (i.e. rotationally symmetric around the origin): \\[ \\text{monCurveMirrorFwd}(x) = \\begin{cases} \\text{monCurveFwd}(x) & \\text{if } x \\geq 0 \\\\[8pt] -[\\text{monCurveFwd}(-x)] & \\text{otherwise} \\end{cases} \\] \"monCurveMirrorRev\" applies a power law function with a linear segment near the origin and mirrors the function for values less than zero (i.e. rotationally symmetric around the origin): \\[ \\text{monCurveMirrorRev}(y) = \\begin{cases} \\text{monCurveRev}(y) & \\text{if } y \\geq 0 \\\\[8pt] -[\\text{monCurveRev}(-y)] & \\text{otherwise} \\end{cases} \\] Note The above equations assume that the input and output bit-depths are floating-point. Integer values are normalized to the range \\([0.0, 1.0]\\) . Elements: Description (optional) See ProcessNode ExponentParams (required) contains one or more attributes that provide the values to be used by the enclosing Exponent element. If style is any of the \u201cbasic\u201d types, then only exponent is required. If style is any of the \u201cmonCurve\u201d types, then exponent and offset are required. Attributes: \"exponent\" (required) the power to which the value is to be raised If style is any of the \u201cmonCurve\u201d types, the valid range is \\([1.0, 10.0]\\) . The nominal value is 1.0. Note When using a \u201cmonCurve\u201d style, a value of 1.0 assigned to exponent could result in a divide-by-zero error. Implementors should protect against this case. \"offset\" (optional) the offset value to use If offset is used, the enclosing Exponent element\u2019s style attribute must be set to one of the \u201cmonCurve\u201d types. Offset is not allowed when style is any of the \u201cbasic\u201d types. The valid range is \\([0.0, 0.9]\\) . The nominal value is 0.0. Note If zero is provided as a value for offset , the calculation of \\(xBreak\\) or \\(yBreak\\) could result in a divide-by-zero error. Implementors should protect against this case. \"channel\" (optional) the color channel to which the exponential function is applied. Possible values are \"R\" , \"G\" , \"B\" . If this attribute is utilized to target different adjustments per channel, up to three ExponentParams elements may be used, provided that \"channel\" is set differently in each. If this attribute is not otherwise specified, the exponential function is applied identically to all three color channels. Examples: <Exponent inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"basicFwd\" > <Description> Basic 2.2 Gamma </Description> <ExponentParams exponent= \"2.2\" /> </Exponent> Example 8. Using Exponent node for applying a 2.2 gamma. <Exponent inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"monCurveFwd\" > <Description> EOTF (sRGB) </Description> <ExponentParams exponent= \"2.4\" offset= \"0.055\" /> </Exponent> Example 9. Using Exponent node for applying the intended EOTF found in IEC 61966-2-1:1999 (sRGB). <Exponent inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"monCurveRev\" > <Description> CIE L* </Description> <ExponentParams exponent= \"3.0\" offset= \"0.16\" /> </Exponent> Example 10. Using Exponent node to apply CIE L* formula. <Exponent inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"monCurveRev\" > <Description> Rec. 709 OETF </Description> <ExponentParams exponent= \"2.2222222222222222\" offset= \"0.099\" /> </Exponent> Example 11. Using Exponent node to apply Rec. 709 OETF. ASC_CDL \u00b6 Description: This node processes values according to the American Society of Cinematographers\u2019 Color Decision List ( ASC CDL ) equations. Color correction using ASC CDL is an industry-wide method of recording and exchanging basic color correction adjustments via parameters that set particular color processing equations. The ASC CDL equations are designed to work on an input domain of floating-point values of [0 to 1.0] although values greater than 1.0 can be present. The output data may or may not be clamped depending on the processing style used. Note Equations 4.31-4.34 assume that \\(in\\) and \\(out\\) are scaled to normalized floating-point range. If the ASC_CDL node has inBitDepth or outBitDepth that are integer types, then the input or output values must be normalized to or from 0-1 scaling. In other words, the slope, offset, power, and saturation values stored in the ProcessNode do not depend on inBitDepth and outBitDepth ; they are always interpreted as if the bit depths were float. Attributes: id (optional) This should match the id attribute of the ColorCorrection element in the ASC CDL XML format. style (required) Determines the formula applied by the operator. The valid options are: \"Fwd\" implementation of v1.2 ASC CDL equation \"Rev\" inverse equation \"FwdNoClamp\" similar to the Fwd equation, but without clamping \"RevNoClamp\" inverse equation, without clamping The first two implement the math provided in version 1.2 of the ASC CDL specification. The second two omit the clamping step and are intended to provide compatibility with the many applications that take that alternative approach. Elements: SOPNode (optional) The SOPNode is optional, and if present, must contain each of the following sub-elements: Slope three decimal values representing the R, G, and B slope values, which is similar to gain, but changes the slope of the transfer function without shifting the black level established by offset Valid values for slope must be greater than or equal to zero ( \\(\\geq\\) 0). The nominal value is 1.0 for all channels. Offset three decimal values representing the R, G, and B offset values, which raise or lower overall brightness of a color component by shifting the transfer function up or down while holding the slope constant The nominal value is 0.0 for all channels. Power three decimal values representing the R, G, and B power values, which change the intermediate shape of the transfer function Valid values for power must be greater than zero ( \\(\\gt\\) 0). The nominal value is 1.0 for all channels. SatNode (optional) The SatNode is optional, but if present, must contain one of the following sub-element: Saturation a single decimal value applied to all color channels Valid values for saturation must be greater than or equal to zero ( \\(\\geq\\) 0). The nominal value is 1.0. Note If either element is not specified, values should default to the nominal values for each element. If using the \"noClamp\" style, the result of the defaulting to the nominal values is a no-op. Note The structure of this ProcessNode matches the structure of the XML format described in the v1.2 ASC CDL specification. However, unlike the ASC CDL XML format, there are no alternate spellings allowed for these elements. The math for style=\"Fwd\" is: \\[ out_{\\textrm{SOP}} = \\textrm{CLAMP}(in \\times \\textrm{slope} + \\textrm{offset})^{\\textrm{power}} \\] \\[ \\begin{aligned} luma &= 0.2126 \\times out_{\\textrm{SOP,R}} + 0.7152 \\times out_{\\textrm{SOP,G}} + 0.0722 \\times out_{\\textrm{SOP,B}} \\\\ out &= \\textrm{CLAMP}\\Big[luma + \\textrm{saturation} \\times (out_{\\textrm{SOP}} \u2212 luma)\\Big] \\end{aligned} \\] Where: \\(\\textrm{CLAMP()}\\) clamps the argument to \\([0,1]\\) The math for style=\"FwdNoClamp\" is the same as for \"Fwd\" but the two clamp() functions are omitted. Also, if \\((in \\times \\textrm{slope} + \\textrm{offset}) < 0\\) , then no power function is applied. The math for style=\"Rev\" is: \\[ \\begin{aligned} in_{\\textrm{clamp}} &= \\mathrm{CLAMP}(in) \\\\ luma &= 0.2126 \\times in_{\\textrm{clamp,R}} + 0.7152 \\times in_{\\textrm{clamp,G}} + 0.0722 \\times in_{\\textrm{clamp,B}} \\\\ out_{\\textrm{SAT}} &= luma + \\frac{(in_{\\textrm{clamp}} - luma)}{\\textrm{saturation}} \\end{aligned} \\] \\[ out = \\mathrm{CLAMP}\\left(\\frac{\\mathrm{CLAMP}(out_{\\textrm{SAT}})^{\\frac{1}{\\textrm{power}}} - \\textrm{offset}}{\\textrm{slope}}\\right) \\\\ \\] Where: \\(\\textrm{CLAMP()}\\) clamps the argument to \\([0,1]\\) The math for style=\"RevNoClamp\" is the same as for \"Rev\" but the \\(\\textrm{CLAMP}()\\) functions are omitted. Also, if \\(out_{\\textrm{SAT}} \\lt 0\\) , then no power function is applied. Examples: <ASC_CDL id= \"cc01234\" inBitDepth= \"16f\" outBitDepth= \"16f\" style= \"Fwd\" > <Description> scene 1 exterior look </Description> <SOPNode> <Slope> 1.000000 1.000000 0.900000 </Slope> <Offset> -0.030000 -0.020000 0.000000 </Offset> <Power> 1.2500000 1.000000 1.000000 </Power> </SOPNode> <SatNode> <Saturation> 1.700000 </Saturation> </SatNode> </ASC_CDL> Example 12. Example of an ASC_CDL node. Implementation Notes \u00b6 Bit Depth \u00b6 Processing Precision \u00b6 All processing shall be performed using 32-bit floating-point values. The values of the inBitDepth and outBitDepth attributes shall not affect the quantization of color values. Note For some hardware devices, 32-bit float processing might not be possible. In such instances, processing should be performed at the highest precision available. Because CLF permits complex series of discrete operations, CLF LUT files are unlikely to run on hardware devices without some form of pre-processing. Any pre-processing to prepare a CLF for more limited hardware applications should adhere to the processing precision requirements. Input To and Output From a ProcessList \u00b6 Applications often support multiple pixel formats (e.g. 8i, 10i, 16f, 32f, etc.). Often the actual pixel format to be processed may not agree with the inBitDepth of the first ProcessNode or the outBitDepth of the last ProcessNode. (Note that the ProcessList element itself does not contain global inBitDepth or outBitDepth attributes.) Therefore, in some cases an application may need to rescale a given ProcessNode to be appropriate for the actual image data being processed. For example, if the last ProcessNode in a ProcessList is a LUT1D with an outBitDepth of 12i, it indicates that the LUT Array values are scaled relative to 4095. If the application wants to produce floating-point pixel values, it should therefore divide the LUT Array values by 4095 before processing the pixels (according to Conversion ). Likewise, if the outBitDepth was instead 32f and the application wants to produce 12i pixel values, it should multiply the LUT Array values by 4095. (Note that in this case, since the result of the computations may exceed 4095 and the application wants to produce 12-bit integer output, the application would want to clamp, round, and quantize the value.) Input To and Output From a ProcessNode \u00b6 In order to ensure the scaling of parameter values of all ProcessNodes in a ProcessList are consistent, the inBitDepth of each ProcessNode must match the outBitDepth of the previous ProcessNode (if any). Please note that an integer inBitDepth or outBitDepth of a ProcessNode does not indicate that any clamping or quantization should be done. These attributes are strictly used to indicate the scaling of parameter and array values. As discussed above , processing precision shall be floating-point. Furthermore, because the processing precision is intended to be floating-point, the inBitDepth and outBitDepth only control the scaling of parameter and array values and do not impose range limits. For example, even if the outBitDepth of a LUT Array is 12i, it does not mean that the Array values must be limited to \\([0,4095]\\) or that they must be integer values. It simply means that in order to rescale to 32f that a scale factor of 1/4095 should be used (as per Conversion ). Because processing within a ProcessList should be done at floating-point precision, applications may optionally want to rescale the interfaces all ProcessNodes \u201cinterior\u201d to a ProcessList to be 32f according to Conversion . As discussed in Input To and Output From a ProcessList , applications may want to rescale the \u201cexterior\u201d interfaces of the ProcessList based on the type of pixel data being processed. For some applications, it may be easiest to simply rescale all ProcessNodes to 32f input and output bit-depth when parsing the file. That way, the ProcessList may be considered a purely 32f set of operations and the implementation therefore does not need to track or deal with bit-depth differences at the ProcessNode level. Conversion Between Integer and Normalized Float Scaling \u00b6 As discussed above, the inBitDepth or outBitDepth of a ProcessNode may need to be rescaled in order to accommodate the pixel data type being processed by the application. The scale factor associated with the bit-depths 8i, 10i, 12i, and 16i is \\(2^n \u2212 1\\) , where \\(n\\) is the bit-depth. The scale factor associated with the bit-depths 16f and 32f is 1.0. To rescale Matrix, LUT1D, or LUT3D Array values when the outBitDepth changes, the scale factor is equal to \\(\\frac{\\textrm{newScale}}{\\textrm{oldScale}}\\) . For example, to convert from 12i to 10i, multiply array values by \\(1023/4095\\) . To rescale Matrix Array values when the inBitDepth changes, the scale factor is equal to \\(\\frac{\\textrm{oldScale}}{\\textrm{newScale}}\\) . For example, to convert from 32f to 10i, multiply array values by \\(1/1023\\) . To rescale Range parameters when the inBitDepth changes, the scale factor for minInValue and maxInValue is \\(\\frac{\\textrm{newScale}}{\\textrm{oldScale}}\\) . To rescale Range parameters when the outBitDepth changes, the scale factor for minOutValue and maxOutValue is \\(\\frac{\\textrm{newScale}}{\\textrm{oldScale}}\\) . Please note that in all cases, the conversion shall be only a scale factor. In none of the above cases should clamping or quantization be applied. Aside from the specific cases listed above, changes to inBitDepth and outBitDepth do not affect the parameter or array values of a given ProcessNode. If an application needs to convert between different integer pixel formats or between integer and float (or vice versa) on the way into or out of a ProcessList, the same scale factors should be used. Note that when converting from floating-point to integer at the application level that values should be clamped, rounded, and quantized. Required vs Optional \u00b6 The required or optional indicated in parentheses throughout this specification indicate the requirement for an element or attribute to be present for a valid CLF file. In the spirit of a LUT format to be used commonly across different software and hardware, none of the elements or attributes should be considered optional for implementors to support. All elements and attributes, if present, should be recognized and supported by an implementation. If, due to hardware or software limitations, a particular element or attribute is not able to be supported, a warning should be issued to the user of a LUT that contains one of the offending elements. The focus shall be on the user and maintaining utmost compatibility with the specification so that LUTs can be interchanged seamlessly. Efficient Processing \u00b6 The transform engine may merge some ProcessNodes in order to obtain better performance. For example, adjacent Matrix operators may be combined into a single matrix. However, in general, combining operators in a way that preserves accuracy is difficult and should be avoided. Hardware implementations may need to convert all ProcessNodes into some other form that is consistent with what the hardware supports. For example, all ProcessNodes might need to be combined into a single 3D LUT . Using a grid size of 64 or larger is recommended to preserve as much accuracy as possible. Implementors should be aware that the success of such approximations varies greatly with the nature of the input and output color spaces. For example, if the input color space is scene-linear in nature, it may be necessary to use a \u201cshaper LUT \u201d or similar non-linearity before the 3D LUT in order to convert values into a more perceptually uniform representation. Extensions \u00b6 It is recommended that implementors of CLF file readers protect against unrecognized elements or attributes that are not defined in this specification. Unrecognized elements that are not children of the Info element should either raise an error or at least provide a warning message to the user to indicate that there is an operator present that is not recognized by the reader. Applications that need to add custom metadata should place it under the Info element rather than at the top level of the ProcessList. One or more Description elements in the ProcessList can and should be used for metadata that does not fit into a provided field in the Info element and/or is unlikely to be recognized by other applications. Examples \u00b6 <?xml version=\"1.0\" encoding=\"UTF-8\"?> <ProcessList id= \"ACEScsc.ACES_to_ACEScg.a1.0.3\" name= \"ACES2065-1 to ACEScg\" compCLFversion= \"3.0\" > <Info> <ACEStransformID> ACEScsc.ACES_to_ACEScg.a1.0.3 </ACEStransformID> <ACESuserName> ACES2065-1 to ACEScg </ACESuserName> </Info> <Description> ACES2065-1 to ACEScg </Description> <InputDescriptor> ACES2065-1 </InputDescriptor> <OutputDescriptor> ACEScg </OutputDescriptor> <Matrix inBitDepth= \"16f\" outBitDepth= \"16f\" > <Array dim= \"3 3\" > 1.451439316146 -0.236510746894 -0.214928569252 -0.076553773396 1.176229699834 -0.099675926438 0.008316148426 -0.006032449791 0.997716301365 </Array> </Matrix> </ProcessList> Example 13. ACES2065-1 to ACEScg <?xml version=\"1.0\" encoding=\"UTF-8\"?> <ProcessList id= \"ACEScsc.ACES_to_ACEScct.a1.0.3\" name= \"ACES2065-1 to ACEScct\" compCLFversion= \"3.0\" > <Description> ACES2065-1 to ACEScct Log working space </Description> <InputDescriptor> Academy Color Encoding Specification (ACES2065-1) </InputDescriptor> <OutputDescriptor> ACEScct Log working space </OutputDescriptor> <Info> <ACEStransformID> ACEScsc.ACES_to_ACEScct.a1.0.3 </ACEStransformID> <ACESuserName> ACES2065-1 to ACEScct </ACESuserName> </Info> <Matrix inBitDepth= \"16f\" outBitDepth= \"16f\" > <Array dim= \"3 3\" > 1.451439316146 -0.236510746894 -0.214928569252 -0.076553773396 1.176229699834 -0.099675926438 0.008316148426 -0.006032449791 0.997716301365 </Array> </Matrix> <Log inBitDepth= \"16f\" outBitDepth= \"16f\" style= \"cameraLinToLog\" > <LogParams base= \"2\" logSideSlope= \"0.05707762557\" logSideOffset= \"0.5547945205\" linSideBreak= \"0.0078125\" /> </Log> </ProcessList> Example 14. ACES2065-1 to ACEScct <?xml version=\"1.0\" encoding=\"UTF-8\"?> <ProcessList id= \"5ac02dc7-1e02-4f87-af46-fa5a83d5232d\" compCLFversion= \"3.0\" > <Description> CIE-XYZ D65 to CIELAB L*, a*, b* (scaled by 1/100, neutrals at 0.0 chroma) </Description> <InputDescriptor> CIE-XYZ, D65 white (scaled [0,1]) </InputDescriptor> <OutputDescriptor> CIELAB L*, a*, b* (scaled by 1/100, neutrals at 0.0 chroma) </OutputDescriptor> <Matrix inBitDepth= \"16f\" outBitDepth= \"16f\" > <Array dim= \"3 3\" > 1.052126639 0.000000000 0.000000000 0.000000000 1.000000000 0.000000000 0.000000000 0.000000000 0.918224951 </Array> </Matrix> <Exponent inBitDepth= \"16f\" outBitDepth= \"16f\" style= \"monCurveRev\" > <ExponentParams exponent= \"3.0\" offset= \"0.16\" /> </Exponent> <Matrix inBitDepth= \"16f\" outBitDepth= \"16f\" > <Array dim= \"3 3\" > 0.00000000 1.00000000 0.00000000 4.31034483 -4.31034483 0.00000000 0.00000000 1.72413793 -1.72413793 </Array> </Matrix> </ProcessList> Example 15. CIE XYZ to CIELAB Appendices \u00b6 Appendix A: Interpolation \u00b6 When an input value falls between sampled positions in a LUT , the output value must be calculated as a proportion of the distance along some function that connects the nearest surrounding values in the LUT . There are many different types of interpolation possible, but only three types of interpolation are currently specified for use with the Common LUT Format ( CLF ). The first interpolation type, linear , is specified for use with a LUT1D node. The other two, trilinear and tetrahedral interpolation, are specified for use with a LUT3D node. Linear Interpolation \u00b6 With a table of the sampled input values in \\(inValue[i]\\) where \\(i\\) ranges from \\(0\\) to \\((n-1)\\) , and a table of the corresponding output values in \\(outValue[j]\\) where \\(j\\) is equal to \\(i\\) , index \\(i\\) inValue index \\(j\\) outValue 0 0 0 0 \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) \\(n - 1\\) 1 \\(n - 1\\) 1000 the \\(output\\) resulting from \\(input\\) can be calculated after finding the nearest \\(inValue[i] < input\\) . When \\(inValue[i] = input\\) , the result is evaluated directly. \\[ output = \\dfrac{input-inValue[i]}{inValue[i+1]-inValue[i]} \\times (outValue[j+1]-outValue[j])+outValue[j] \\] Trilinear Interpolation \u00b6 Trilinear interpolation implements linear interpolation in three-dimensions by successively interpolating each direction. Figure 3 - Illustration of a sampled point located within a basic 3D LUT mesh grid (left) and the same point but with only the vertices surrounding the sampled point (right). Figure 4 - Labeling the mesh points surrounding the sampled point (r,g,b). Note The convention used for notation is uppercase variables for mesh points and lowercase variables for points on the grid. Consider a sampled point as depicted in Figure 4. Let \\(V(r,g,b)\\) represent the value at the point with coordinate \\((r,g,b)\\) . The distance between each node per color coordinate shows the proportion of each mesh point's color coordinate values that contribute to the sampled point. \\[ \\Delta_r = \\frac{r - R_0}{R_1 - R_0} \\hspace{0.25in} \\Delta_g = \\frac{g - G_0}{G_1 - G_0} \\hspace{0.25in} \\Delta_b = \\frac{b - B_0}{B_1 - B_0} \\] The general expression for trilinear interpolation can be expressed as: \\[ V(r,g,b) = c_0 + c_1\\Delta_b + c_2\\Delta_r + c_3\\Delta_g + c_4\\Delta_b\\Delta_r + c_5\\Delta_r\\Delta_g + c_6\\Delta_g\\Delta_b + c_7\\Delta_r\\Delta_g\\Delta_b \\] where: \\[ \\begin{aligned} c_0 &= V(R_0, G_0, B_0) \\\\ c_1 &= V(R_0, G_0, B_1) - V(R_0, G_0, B_0) \\\\ c_2 &= V(1_0, G_0, B_0) - V(R_0, G_0, B_0) \\\\ c_3 &= V(R_0, G_1, B_0) - V(R_0, G_0, B_0) \\\\ c_4 &= V(R_1, G_1, B_1) - V(R_1, G_0, B_0) - V(R_0, G_0, B_1) + V(R_0, G_0, B_0) \\\\ c_5 &= V(R_1, G_1, B_0) - V(R_0, G_1, B_0) - V(R_1, G_0, B_0) + V(R_0, G_0, B_0) \\\\ c_6 &= V(R_0, G_1, B_1) - V(R_1, G_1, B_0) - V(R_0, G_0, B_1) + V(R_0, G_0, B_0) \\\\ c_7 &= V(R_1, G_1, B_1) - V(R_1, G_1, B_0) - V(R_0, G_1, B_1) - V(R_1, G_0, B_1) \\\\ &+ V(R_0, G_0, B_1) + V(R_0, G_1, B_0) + V(R_1, G_0, B_0) - V(R_0, G_0, B_0) \\end{aligned} \\] Expressed in matrix form: \\[ \\begin{gather} \\mathbf{C} = [c_0 \\enspace c_1 \\enspace c_2 \\enspace c_3 \\enspace c_4 \\enspace c_5 \\enspace c_6 \\enspace c_7]^T \\\\ \\mathbf{\\Delta} = [1 \\quad \\Delta_b \\quad \\Delta_r \\quad \\Delta_g \\quad \\Delta_b\\Delta_r \\quad \\Delta_r\\Delta_g \\quad \\Delta_g\\Delta_b \\quad \\Delta_r\\Delta_g\\Delta_b]^T \\\\ V(r,g,b) = \\mathbf{C}^T \\mathbf{\\Delta} \\end{gather} \\] \\[ \\begin{bmatrix} c_0 \\\\ c_1 \\\\ c_2 \\\\ c_3 \\\\ c_4 \\\\ c_5 \\\\ c_6 \\\\ c_7 \\end{bmatrix} = \\begin{bmatrix} 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ -1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\ -1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\ -1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 1 & 0 & -1 & 0 & -1 & 0 & 1 & 0 \\\\ 1 & -1 & -1 & 1 & 0 & 0 & 0 & 0 \\\\ 1 & -1 & 0 & 0 & -1 & 1 & 0 & 0 \\\\ -1 & 1 & 1 & -1 & 1 & -1 & -1 & 1 \\end{bmatrix} \\begin{bmatrix} V(R_0, G_0, B_0) \\\\ V(R_0, G_1, B_0) \\\\ V(R_1, G_0, B_0) \\\\ V(R_1, G_1, B_0) \\\\ V(R_0, G_0, B_1) \\\\ V(R_0, G_1, B_1) \\\\ V(R_1, G_0, B_1) \\\\ V(R_1, G_1, B_1) \\end{bmatrix} \\] The expression in above can be written as: \\(\\mathbf{C} = \\mathbf{A}\\mathbf{V}\\) . Trilinear interpolation shall be done according to \\(V(r,g,b) = \\mathbf{C}^T \\mathbf{\\Delta} = \\mathbf{V}^T \\mathbf{A}^T \\mathbf{\\Delta}\\) . Note The term \\(\\mathbf{V}^T \\mathbf{A}^T\\) does not depend on the variable \\((r,g,b)\\) and thus can be computed in advance for optimization. Each sub-cube can have the values of the vector \\(\\mathbf{C}\\) already stored in memory. Therefore the algorithm can be summarized as: Find the sub-cube containing the point \\((r,g,b)\\) Select the vector \\(\\mathbf{C}\\) corresponding to that sub-cube Compute \\(\\Delta_r\\) , \\(\\Delta_g\\) , \\(\\Delta_b\\) Return \\(V(r,g,b) = \\mathbf{C}^T \\mathbf{\\Delta}\\) Tetrahedral Interpolation} \u00b6 Tetrahedral interpolation subdivides the cubelet defined by the vertices surrounding a sampled point into six tetrahedra by segmenting along the main (and usually neutral) diagonal (Figure 5). Figure 5 - Illustration of the six subdivided tetrahedra. To find the tetrahedron containing the point \\((r,g,b)\\) : if \\(\\Delta_b > \\Delta_r > \\Delta_g\\) , then use the first tetrahedron, \\(t1\\) if \\(\\Delta_b > \\Delta_g > \\Delta_r\\) , then use the first tetrahedron, \\(t2\\) if \\(\\Delta_g > \\Delta_b > \\Delta_r\\) , then use the first tetrahedron, \\(t3\\) if \\(\\Delta_r > \\Delta_b > \\Delta_g\\) , then use the first tetrahedron, \\(t4\\) if \\(\\Delta_r > \\Delta_g > \\Delta_b\\) , then use the first tetrahedron, \\(t5\\) else, use the sixth tetrahedron, \\(t6\\) The matrix notation is: \\[ \\mathbf{V} = \\begin{bmatrix} V(R_0, G_0, B_0) \\\\ V(R_0, G_1, B_0) \\\\ V(R_1, G_0, B_0) \\\\ V(R_1, G_1, B_0) \\\\ V(R_0, G_0, B_1) \\\\ V(R_0, G_1, B_1) \\\\ V(R_1, G_0, B_1) \\\\ V(R_1, G_1, B_1) \\end{bmatrix}\\\\ \\\\ \\] \\[ \\mathbf{\\Delta_t} = [1 \\enspace \\Delta_b \\enspace \\Delta_r \\enspace \\Delta_g]^T \\] \\[ \\begin{aligned} \\mathbf{T}_1 = \\begin{bmatrix} 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ -1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & -1 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & -1 & 1 \\end{bmatrix} \\hspace{0.5in} \\mathbf{T}_2 = \\begin{bmatrix} 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ -1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & -1 & 0 & 1 \\\\ 0 & 0 & 0 & 0 & -1 & 1 & 0 & 0 \\end{bmatrix} \\\\ \\mathbf{T}_3 = \\begin{bmatrix} 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & -1 & 0 & 0 & 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & -1 & 0 & 1 \\\\ -1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\end{bmatrix} \\hspace{0.5in} \\mathbf{T}_4 = \\begin{bmatrix} 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & -1 & 0 & 0 & 0 & 1 & 0 \\\\ -1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & -1 & 1 \\end{bmatrix} \\\\ \\mathbf{T}_5 = \\begin{bmatrix} 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & -1 & 0 & 0 & 0 & 1 \\\\ -1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & -1 & 1 & 0 & 0 & 0 & 0 \\end{bmatrix} \\hspace{0.5in} \\mathbf{T}_6 = \\begin{bmatrix} 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & -1 & 0 & 0 & 0 & 1 \\\\ 0 & -1 & 0 & 1 & 0 & 0 & 0 & 0 \\\\ -1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\end{bmatrix} \\end{aligned} \\] Trilinear interpolation shall be done according to: \\[ \\begin{gather} V(r,g,b)_{t1} = \\mathbf{\\Delta}^T_t \\mathbf{T}_1 \\mathbf{V}\\\\ V(r,g,b)_{t2} = \\mathbf{\\Delta}^T_t \\mathbf{T}_2 \\mathbf{V}\\\\ V(r,g,b)_{t3} = \\mathbf{\\Delta}^T_t \\mathbf{T}_3 \\mathbf{V}\\\\ V(r,g,b)_{t4} = \\mathbf{\\Delta}^T_t \\mathbf{T}_4 \\mathbf{V}\\\\ V(r,g,b)_{t5} = \\mathbf{\\Delta}^T_t \\mathbf{T}_5 \\mathbf{V}\\\\ V(r,g,b)_{t6} = \\mathbf{\\Delta}^T_t \\mathbf{T}_6 \\mathbf{V} \\end{gather} \\] Note The vectors \\(\\mathbf{T}_i \\mathbf{V}\\) for \\(i = 1,2,3,4,5,6\\) does not depend on the variable \\((r,g,b)\\) and thus can be computed in advance for optimization. Appendix B: Cineon-style Log Parameters \u00b6 When using a Log node, it might be desirable to conform an existing logarithmic function that uses Cineon style parameters to the parameters used by CLF . A translation from Cineon-style parameters to those used by CLF 's LogParams element is quite straightforward using the following steps. Traditionally, \\(\\textrm{refWhite}\\) and \\(\\textrm{refBlack}\\) are provided as 10-bit quantities, and if they indeed are, first normalize them to floating point by dividing by 1023: \\[ \\begin{align} \\textrm{refWhite} = \\frac{\\textrm{refWhite}_{10i}}{1023.0} \\\\[12pt] \\textrm{refBlack} = \\frac{\\textrm{refBlack}_{10i}}{1023.0} \\end{align} \\] where subscript 10 \\(i\\) indicates a 10-bit quantity. The density range is assumed to be: \\[ \\textrm{range} = 0.002 \\times 1023.0 \\] Then solve the following quantities: \\[ \\begin{align} \\textrm{multFactor} =& \\frac{\\textrm{range}}{\\textrm{gamma}} \\\\ \\textrm{gain} =& \\frac{\\textrm{highlight} - \\textrm{shadow}}{1.0 - 10^{( MIN( \\textrm{multFactor} \\times (\\textrm{refBlack}-\\textrm{refWhite}), -0.0001)}} \\\\[6pt] \\textrm{offset} =& \\ \\textrm{gain} - (\\textrm{highlight} - \\textrm{shadow}) \\\\ \\end{align} \\] Where \\(MIN(x,y)\\) returns \\(x\\) if \\(x<y\\) , otherwise returns \\(y\\) The parameters for the LogParams element are then: \\[\\begin{align} \\texttt{base} =& \\ 10.0 \\\\[6pt] \\texttt{logSlope} =& \\ \\frac{1}{\\textrm{multFactor}} \\\\[6pt] \\texttt{logOffset} =& \\ \\textrm{refWhite} \\\\[6pt] \\texttt{linSlope} =& \\ \\frac{1}{\\textrm{gain}} \\\\[6pt] \\texttt{linOffset} =& \\ \\frac{\\textrm{offset}-\\textrm{shadow}}{\\textrm{gain}} \\end{align}\\] Appendix C: Changes between v2.0 and v3.0 \u00b6 Add Log ProcessNode Add Exponent ProcessNode Revise formulas for defining use of Range ProcessNode to clamp at the low or high end. IndexMaps removed. Use a halfDomain LUT to achieve reshaping of input to a LUT . Move ACEStransform elements to Info element of ProcessList in main spec Changed syntax for dim attribute of Array when contained in a Matrix . Two integers are now used to define the dimensions of the matrix instead of the previous three values which defined the dimensions of the matrix and the number of color components. @import \"../../stylesheets/sections.css\"","title":"Index"},{"location":"specifications/clf/#common-lut-format-clf-a-common-file-format-for-look-up-tables","text":"","title":"Common LUT Format (CLF) - A Common File Format for Look-Up Tables"},{"location":"specifications/clf/#introduction","text":"Look-Up Tables ( LUTs ) are a common implementation for transformations from one set of color values to another. With a large number of product developers providing software and hardware solutions for LUTs , there is an explosion of unique vendor-specific LUT file formats, which are often only trivially different from each other. This can create workflow problems when a LUT being used on a production is not supported by one or more of the applications being used. Furthermore, many LUT formats are designed for a particular use case only and lack the quality, flexibility, and metadata needed to meet modern requirements. The Common LUT Format ( CLF ) can communicate an arbitrary chain of color operators (also called processing nodes) which are sequentially processed to achieve an end result. The set of available operator types includes matrices, 1D LUTs , 3D LUTs , ASC - CDL , log and exponential shaper functions, and more. Even when 1D or 3D LUTs are not present, CLF can be used to encapsulate any supported color transforms as a text file conforming to the XML schema.","title":"Introduction"},{"location":"specifications/clf/#scope","text":"This document introduces a human-readable text file format for the interchange of color transformations using an XML schema. The XML format supports Look-Up Tables of several types: 1D LUTs , 3D LUTs , and 3\u00d71D LUTs , as well as additional transformation needs such as matrices, range rescaling, and \u201cshaper LUTs .\u201d The document defines what is a valid CLF file. Though it is not intended as a tutorial for users to create their own files, LUT creators will find it useful to understand the elements and attributes available for use in a CLF file. The document is also not intended to provide guidance to implementors on how to optimize their implementations, but does provide a few notes on the subject. This document assumes the reader has knowledge of basic color transformation operators and XML .","title":"Scope"},{"location":"specifications/clf/#references","text":"The following standards, specifications, articles, presentations, and texts are referenced in this text: IETF RFC 3066: IETF (Internet Engineering Task Force). RFC 3066: Tags for the Identification of Lan- guages, ed. H. Alvestrand. 2001 IEEE DRAFT Standard P123 Academy S-2014-002, Academy Color Encoding System \u2013 Versioning System Academy TB-2014-002, Academy Color Encoding System Version 1.0 User Experience Guidelines ASC Color Decision List ( ASC CDL ) Transfer Functions and Interchange Syntax. ASC - CDL Release1.2. Joshua Pines and David Reisner. 2009-05-04.","title":"References"},{"location":"specifications/clf/#specification","text":"","title":"Specification"},{"location":"specifications/clf/#general","text":"A Common LUT Format ( CLF ) file shall be written using Extensible Markup Language ( XML ) and adhere to a defined XML structure. A CLF file shall have the file extension ' .clf '. The top level element in a CLF file defines a ProcessList which represents a sequential set of color transformations. The result of each individual color transformation feeds into the next transform in the list to create a daisy chain of transforms. An application reads a CLF file and initializes a transform engine to perform the operations in the list. The transform engine reads as input a stream of code values of pixels, performs the calculations and/or interpolations, and writes an output stream representing a new set of code values for the pixels. In the sequence of transformations described by a ProcessList , each ProcessNode performs a transform on a stream of pixel data, and only one input line (input pixel values) may enter a node and only one output line (output pixel values) may exit a node. A ProcessList may be defined to work on either 1- component or 3-component pixel data, however all transforms in the list must be appropriate, especially in the 1-component case (black-and-white) where only 1D LUT operations are allowed. Implementation may process 1-component transforms by applying the same processing to R, G, and B. Figure 1. Example of a ProcessList containing a sequence of multiple ProcessNodes The file format does not provide a mechanism to assign color transforms to either image sequences or image regions. However, the XML structure defining the LUT transform, a ProcessList, may be encapsulated in a larger XML structure potentially providing that mechanism. This mechanism is beyond the scope of this document. Each CLF file shall be completely self-contained requiring no external information or metadata. The full content of a color transform must be included in each file and a color transform may not be incorporated by reference to another CLF file. This restriction ensures that each CLF file can be an independent archival element. Each ProcessList shall be given a unique ID for reference. The data for LUTs shall be an ordered array that is either all floats or all integers. When three RGB color components are present, it is assumed that these are red, green, and blue in that order. There is only one order for how the data array elements are specified in a LUT , which is in general from black to white (from the minimum input value position to the maximum input value position). Arbitrary ordering of list elements is not supported in the format (see XML Elements for details). Note For 3D LUTs , the indexes to the cube are assumed to have regular spacing across the range of input values. To accommodate irregular spacing, a \" halfDomain \" 1D LUT or Log node should be used as a shaper function prior to the 3D LUT .","title":"General"},{"location":"specifications/clf/#xml-structure","text":"","title":"XML Structure"},{"location":"specifications/clf/#xml-elements","text":"Figure 2. Object Model of XML Elements","title":"XML Elements"},{"location":"specifications/clf/#processlist","text":"Description: The ProcessList is the root element for any CLF file and is composed of one or more ProcessNodes. A ProcessList is required even if only one ProcessNode will be present. Note The last node of the ProcessList is expected to be the final output of the LUT . A LUT designer can allow floating-point values to be interpreted by applications and thus delay control of the final encoding through user selections. Note If needed, a Range node can be placed at the end of a ProcessList to control minimum and maximum output values and clamping. Attributes: id (required) a string to serve as a unique identifier of the ProcessList compCLFversion (required) a string indicating the minimum compatible CLF specification version required to read this file The compCLFversion corresponding to this version of the specification is be \"3.0\" . name (optional) a concise string used as a text name of the ProcessList for display or selection from an application\u2019s user interface inverseOf (optional) a string for linking to another ProcessList id (unique) which is the inverse of this one Elements: Description (optional) a string for comments describing the function, usage, or any notes about the ProcessList . A ProcessList can contain zero or more Description elements. InputDescriptor (optional) an arbitrary string used to describe the intended source code values of the ProcessList OutputDescriptor (optional) an arbitrary string used to describe the intended output target of the ProcessList (e.g. target display) ProcessNode (required) a generic XML element that in practice is substituted with a particular color operator. The ProcessList must contain at least one ProcessNode . The ProcessNode is described in ProcessNode . Info (optional) optional element for including additional custom metadata not needed to interpret the transforms. The Info element includes: AppRelease (optional) a string used for indicating application software release level Copyright (optional) a string containing a copyright notice for authorship of the CLF file Revision (optional) a string used to track the version of the LUT itself (e.g. an increased resolution from a previous version of the LUT ) ACEStransformID (optional) a string containing an ACES transform identifier as described in Academy S-2014-002. If the transform described by the ProcessList is the concatenation of several ACES transforms, this element may contain several ACES Transform IDs, separated by white space or line separators. This element is mandatory for ACES transforms and may be referenced from ACES Metadata Files. ACESuserName (optional) a string containing the user-friendly name recommended for use in product user interfaces as described in Academy TB-2014-002 CalibrationInfo (optional) container element for calibration metadata used when making a LUT for a specific device. CalibrationInfo can contain the following child elements: DisplayDeviceSerialNum DisplayDeviceHostName OperatorName CalibrationDateTime MeasurementProbe CalibrationSoftwareName CalibrationSoftwareVersion","title":"ProcessList"},{"location":"specifications/clf/#processNode","text":"Description: A ProcessNode element represents an operation to be applied to the image data. At least one ProcessNode element must be included in a ProcessList . The generic ProcessNode element contains attributes and elements that are common to and inherited by the specific sub-types of the ProcessNode element that can substitute for ProcessNode . All ProcessNode substitutes shall inherit the following attributes. Attributes: id (optional) a unique identifier for the ProcessNode name (optional) a concise string defining a name for the ProcessNode that can be used by an application for display in a user interface inBitDepth (required) a string that is used by some ProcessNodes to indicate how array or parameter values have been scaled outBitDepth (required) a string that is used by some ProcessNodes to indicate how array or parameter values have been scaled The supported values for both inBitDepth and outBitDepth are the same: \"8i\" : 8-bit unsigned integer \"10i\" : 10-bit unsigned integer \"12i\" : 12-bit unsigned integer \"16i\" : 16-bit unsigned integer \"16f\" : 16-bit floating point (half-float) \"32f\" : 32-bit floating point (single precision) Elements: Description (optional) an arbitrary string for describing the function, usage, or notes about the ProcessNode. A ProcessNode can contain one or more Descriptions.","title":"ProcessNode"},{"location":"specifications/clf/#array","text":"Description: The Array element contains a table of entries with a single line for each grouping of values. This element is used in the LUT1D , LUT3D , and Matrix ProcessNodes. The dim attribute specifies the dimensions of the array and, depending on context, defines the size of a matrix or the length of a LUT table. The specific formatting of the dim attribute must match with the type of node in which it is being used. The usages are summarized below but specific requirements for each application of Array are described when it appears as a child element for a particular ProcessNode . Attributes: dim (required) Specifies the dimension of the LUT or the matrix and the number of color components. The dim attribute provides the dimensionality of the indexes, where: 4 entries represent the dimensions of a 3D cube and the number of components per entry. e.g. dim = 17 17 17 3 indicates a 17-cubed 3D LUT with 3 color components 2 entries represent the dimensions of a matrix. e.g. dim = 3 3 indicates a 3\u00d73 matrix e.g. dim = 3 4 indicates a 3\u00d74 matrix 2 entries represent the length of the LUT and the component value (1 or 3). e.g. dim = 256 3 indicates a 256 element 1D LUT with 3 components (a 3\u00d71D LUT ) e.g. dim = 256 1 indicates a 256 element 1D LUT with 1 component (1D LUT )","title":"Array"},{"location":"specifications/clf/#substititues-for-processnode","text":"","title":"Substititues for ProcessNode"},{"location":"specifications/clf/#general_2","text":"The attributes and elements defined for ProcessNode are inherited by the substitutes for ProcessNode . This section defines the available substitutes for the generalized ProcessNode element. The inBitDepth of a ProcessNode must match the outBitDepth of the preceding ProcessNode (if any).","title":"General"},{"location":"specifications/clf/#lut1d","text":"Description: A 1D LUT transform uses an input pixel value, finds the two nearest index positions in the LUT , and then interpolates the output value using the entries associated with those positions. This node shall contain either a 1D LUT or a 3x1D LUT in the form of an Array . If the input to a LUT1D is an RGB value, the same LUT shall be applied to all three color components. A 3x1D LUT transform looks up each color component in a separate LUT1D of the same length. In a 3x1D LUT , by convention, the LUT1D for the first component goes in the first column of Array . The scaling of the array values is based on the outBitDepth (the inBitDepth is not considered). The length of a 1D LUT should be limited to at most 65536 entries, and implementations are not required to support LUT1D s longer than 65536 entries. Linear interpolation shall be used for LUT1D . More information about linear interpolation can be found in Appendix A . Elements: Array (required) an array of numeric values that are the output values of the 1D LUT . Array shall contain the table entries of a LUT in order from minimum value to maximum value. For a 1D LUT , one value per entry is used for all color channels. For a 3x1D LUT , each line should contain 3 values, creating a table where each column defines a 1D LUT for each color component. For RGB , the first column shall correspond to R\u2019s 1D LUT , the second column shall correspond to G\u2019s 1D LUT , and the third column shall correspond to B\u2019s 1D LUT . Attributes: dim (required) two integers that represent the dimensions of the array. The first value defines the length of the array and shall equal the number of entries (lines) in the LUT . The second value indicates the number of components per entry and shall equal 1 for a 1D LUT or 3 for a 3x1D LUT . Example dim = \"1024 3\" indicates a 1024 element 1D LUT with 3 component color (a 3x1D LUT ) Example dim = \"256 1\" indicates a 256 element 1D LUT with 1 component color (a 1D LUT ) Note Array is formatted differently when it is contained in a LUT3D or Matrix element (see Array ). Attributes: interpolation (optional) a string indicating the preferred algorithm used to interpolate values in the 1DLUT . This attribute is optional but, if present, shall be set to \"linear\" . Note Previous versions of this specification allowed for implementations to utilize different types of interpolation but did not define what those interpolation types were or how they should be labeled. For simplicity and to ensure similarity across implementations, 1D LUT interpolation has been limited to \"linear\" in this version of the specification. Support for additional interpolation types could be added in future version. halfDomain (optional) If this attribute is present, its value must equal \u201ctrue\u201d . When true, the input domain to the node is considered to be all possible 16-bit floating-point values, and there must be exactly 65536 entries in the Array element. Note For example, the unsigned integer 15360 has the same bit-pattern (0011110000000000) as the half-float value 1.0, so the 15360th entry (zero-indexed) in the Array element is the output value corresponding to an input value of 1.0. rawHalfs (optional) If this attribute is present, its value must equal \u201ctrue\u201d . When true, the rawHalfs attribute indicates that the output array values in the form of unsigned 16-bit integers are interpreted as the equivalent bit pattern, half floating-point values. Note For example, to represent the value 1.0, one would use the integer 15360 in the Array element because it has the same bit-pattern. This allows the specification of exact half-float values without relying on conversion from decimal text strings. Examples: <LUT1D id= \"lut-23\" name= \"4 Value Lut\" inBitDepth= \"12i\" outBitDepth= \"12i\" > <Description> 1D LUT - Turn 4 grey levels into 4 inverted codes </Description> <Array dim= \"4 1\" > 3 2 1 0 </Array> </LUT1D> Example 1. Example of a very simple LUT1D","title":"LUT1D"},{"location":"specifications/clf/#lut3d","text":"Description: This node shall contain a 3D LUT in the form of an Array. In a LUT3D, the 3 color components of the input value are used to find the nearest indexed values along each axis of the 3D cube. The 3-component output value is calculated by interpolating within the volume defined by the nearest corresponding positions in the LUT . LUT3Ds have the same dimension on all axes (i.e. Array dimensions are of the form \u201cn n n 3\u201d). A LUT3D with axial dimensions greater than 128x128x128 should be avoided. The scaling of the array values is based on the outBitDepth (the inBitDepth is not considered). Attributes: interpolation (optional) a string indicating the preferred algorithm used to interpolate values in the 3DLUT. This attribute is optional with a default of \"trilinear\" if the attribute is not present. Supported values are: \"trilinear\" : perform trilinear interpolation \"tetrahedral\" : perform tetrahedral interpolation Note Interpolation methods are specified in Appendix A . Elements: Array (required) an array of numeric values that are the output values of the 3D LUT . The Array shall contain the table entries for the LUT3D from the minimum to the maximum input values, with the third component index changing fastest. Attributes: dim (required) four integers that reperesent the dimensions of the 3D LUT and the number of color com- ponents. The first three values define the dimensions of the LUT and if multiplied shall equal the number of entries actually present in the array. The fourth value indicates the number of components per entry. 4 entries have the dimensions of a 3D cube plus the number of components per entry. Example dim = \"17 17 17 3\" indicates a 17-cubed 3D lookup table with 3 component color Note Array is formatted differently when it is contained in a LUT1D or Matrix element (see Array ). Examples: <LUT3D id= \"lut-24\" name= \"green look\" interpolation= \"trilinear\" inBitDepth= \"12i\" outBitDepth= \"16f\" > <Description> 3D LUT </Description> <Array dim= \"2 2 2 3\" > 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 0.0 0.0 1.0 0.0 1.0 1.0 1.0 0.0 1.0 1.0 1.0 </Array> </LUT3D> Example 2. Example of a simple LUT3D","title":"LUT3D"},{"location":"specifications/clf/#matrix","text":"Description: This node specifies a matrix transformation to be applied to the input values. The input and output of a Matrix are always 3-component values. All matrix calculations should be performed in floating point, and input bit depths of integer type should be treated as scaled floats. If the input bit depth and output bit depth do not match, the coefficients in the matrix must incorporate the results of the \u2018scale\u2019 factor that will convert the input bit depth to the output bit depth (e.g. input of 10i with an output of 12i requires the matrix coefficients already have a factor of \\(4095/1023\\) applied). Changing the input or output bit depth requires creation of a new set of coefficients for the matrix. The output values are calculated using row-order convention: \\[ \\begin{bmatrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\\\ a_{31} & a_{32} & a_{33} \\\\ \\end{bmatrix} \\begin{bmatrix} r_1\\\\ g_1\\\\ b_1 \\end{bmatrix} = \\begin{bmatrix} r_2\\\\ g_2\\\\ b_2 \\end{bmatrix} \\] which is equivalent in functionality to the following: \\[ \\begin{aligned} r_2 = (r_1 \\cdot a_{11}) + (g_1 \\cdot a_{12}) + (b_1 \\cdot a_{13}) \\\\ g_2 = (r_1 \\cdot a_{21}) + (g_1 \\cdot a_{22}) + (b_1 \\cdot a_{23}) \\\\ b_2 = (r_1 \\cdot a_{31}) + (g_1 \\cdot a_{32}) + (b_1 \\cdot a_{33}) \\end{aligned} \\] Matrices using an offset calculation will have one more column than rows. An offset matrix may be defined using a 3x4 Array , wherein the fourth column is used to specify offset terms, \\(k_1\\) , \\(k_2\\) , \\(k_3\\) : \\[ \\begin{bmatrix} a_{11} & a_{12} & a_{13} & k_1\\\\ a_{21} & a_{22} & a_{23} & k_2\\\\ a_{31} & a_{32} & a_{33} & k_3\\\\ \\end{bmatrix} \\begin{bmatrix} r_1\\\\ g_1\\\\ b_1\\\\ 1.0 \\end{bmatrix} = \\begin{bmatrix} r_2\\\\ g_2\\\\ b_2 \\end{bmatrix} \\] Expanded out, this means that the offset terms \\(k_1\\) , \\(k_2\\) , and \\(k_3\\) are added to each of the normal matrix calculations: \\[ \\begin{aligned} r_2 = (r_1 \\cdot a_{11}) + (g_1 \\cdot a_{12}) + (b_1 \\cdot a_{13}) + k_1\\\\ g_2 = (r_1 \\cdot a_{21}) + (g_1 \\cdot a_{22}) + (b_1 \\cdot a_{23}) + k_2\\\\ b_2 = (r_1 \\cdot a_{31}) + (g_1 \\cdot a_{32}) + (b_1 \\cdot a_{33}) + k_3 \\end{aligned} \\] Elements: Array (required) a table that provides the coefficients of the transformation matrix. The matrix dimensions are either 3x3 or 3x4. The matrix is serialized row by row from top to bottom and from left to right, i.e., \" \\(a_{11}\\ a_{12}\\ a_{13}\\ a_{21}\\ a_{22}\\ a_{23}\\ \\ldots\\) \" for a 3x3 matrix. \\[ \\begin{bmatrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\\\ a_{31} & a_{32} & a_{33} \\\\ \\end{bmatrix} \\] Attributes: dim (required) two integers that describe the dimensions of the matrix array. The first value define the number of rows and the second is the number of columns. 2 entries have the dimensions of a matrix Example dim = \"3 3\" indicates a 3x3 matrix Example dim = \"3 4\" indicates a 3x4 matrix Note Previous versions of this specification used three integers for the dim attribute, rather than the current two. In order to facilitate backwards compatibility, implementations should allow a third value for the dim attribute and may simply ignore it. Note Array is formatted differently when nit is contained in a LUT1D or LUT3D element (see Array ) Examples: <Matrix id= \"lut-28\" name= \"AP0 to AP1\" inBitDepth= \"16f\" outBitDepth= \"16f\" > <Description> 3x3 color space conversion from AP0 to AP1 </Description> <Array dim= \"3 3\" > 1.45143931614567 -0.236510746893740 -0.214928569251925 -0.0765537733960204 1.17622969983357 -0.0996759264375522 0.00831614842569772 -0.00603244979102103 0.997716301365324 </Array> </Matrix> Example 3. Example of a Matrix node with dim=\"3 3 3\" <Matrix id= \"lut-25\" name= \"colorspace conversion\" inBitDepth= \"10i\" outBitDepth= \"10i\" > <Description> 3x4 Matrix , 4th column is offset </Description> <Array dim= \"3 4\" > 1.2 0.0 0.0 0.002 0.0 1.03 0.001 -0.005 0.004 -0.007 1.004 0.0 </Array> </Matrix> Example 4. Example of a Matrix node","title":"Matrix"},{"location":"specifications/clf/#range","text":"Description: This node maps the input domain to the output range by scaling and offsetting values. The Range element can also be used to clamp values. Unless otherwise specified, the node\u2019s default behavior is to scale and offset with clamping. If clamping is not desired, the style attribute can be set to \"noClamp\" . To achieve scale and/or offset of values, all of minInValue , minOutValue , maxInValue , and maxOutValue must be present. In this explicit case, the formula for Range shall be: \\[ out = in \\times scale + \\texttt{minOutValue} - \\texttt{minInValue} \\times scale \\] where: \\(scale = \\dfrac{(\\texttt{maxOutValue} - \\texttt{minOutValue})}{(\\texttt{maxInValue} - \\texttt{minInValue})}\\) The scaling of minInValue and maxInValue depends on the input bit-depth, and the scaling of minOutValue and maxOutValue depends on the output bit-depth. If style=\"Clamp\" , the output value of \\(out\\) from the above equation is furthur modified as follows: \\[ out_{clamped} = \\mathrm{MIN}(\\texttt{maxOutValue}, \\mathrm{MAX}( \\texttt{minOutValue}, out)) \\] where: \\(\\mathrm{MAX}(a,b)\\) returns \\(a\\) if \\(a > b\\) and \\(b\\) if \\(b \\geq a\\) \\(\\mathrm{MIN}(a,b)\\) returns \\(a\\) if \\(a < b\\) and \\(b\\) if \\(b \\leq a\\) The Range element can also be used to clamp values on only the top or bottom end. In such instances, no offset is applied, and the formula simplifies because only one pair of min or max values are required. (The style shall not be \"noClamp\" for this use-case.) If only the minimum value pair is provided, then the result shall be clamping at the low end, according to: \\[ out = \\mathrm{MAX}( \\texttt{minOutValue}, in \\times bitDepthScale) \\] If only the maximum values pairs are provided, the result shall be clamping at the high end, according to: \\[ out = \\mathrm{MIN}( \\texttt{maxOutValue}, in \\times bitDepthScale) \\] where: \\[ bitDepthScale = \\dfrac{\\mathrm{SIZE}(\\texttt{outBitDepth})}{\\mathrm{SIZE}(\\texttt{inBitDepth})} \\] \\[ \\mathrm{SIZE}(a) = \\begin{cases} 2^{bitDepth}-1 & \\text{when }a \\in \\{\\texttt{\"8i\"},\\texttt{\"10i\"},\\texttt{\"12i\"},\\texttt{\"16i\"}\\} \\\\ 1.0 & \\text{when }a \\in \\{\\texttt{\"16f\"},\\texttt{\"32f\"}\\} \\end{cases} \\] In both instances, values must be set such that \\(\\texttt{maxOutValue} = \\texttt{maxInValue} \\times bitDepthScale\\) . Note The bit depth scale factor intentionally uses \\(2^{bitDepth}\u22121\\) and not \\(2^{bitDepth}\\) . This means that the scale factor created for scaling between different bit depths is \"non-integer\" and is slightly different depending on the bit depths being scaled between. While instinct might be that this scale should be a clean bit-shift factor (i.e. \\(2\\times\\) or \\(4\\times\\) scale), testing with a few example values plugged into the formula will show that the resulting non-integer scale is the correct and intended behavior. At least one pair of either minimum or maximum values, or all four values, must be provided. Elements: minInValue (optional) The minimum input value. Required if minOutValue is present. maxInValue (optional) The maximum input value. Required if maxOutValue is present. The maxInValue shall be greater than the minInValue . minOutValue (optional) The minimum output value. Required if minInValue is present. maxOutValue (optional) :The maximum output value. Required if maxInValue is present. The maxOutValue shall be greater than or equal to the minOutValue . Attributes: style (optional) Describes the preferred handling of the scaling calculation of the Range node. If the style attribute is not present, clamping is performed. The options for style are: \"noClamp\" If present, scale and offset is applied without clamping (i.e. values below minOutValue or above maxOutValue are preserved) \"Clamp\" If present, clamping is applied upon the result of the scale and offset expressed by the result of the non-clamping Range equation Examples: <Range inBitDepth= \"10i\" outBitDepth= \"10i\" > <Description> 10-bit full range to SMPTE range </Description> <minInValue> 0 </minInValue> <maxInValue> 1023 </minInValue> <minOutValue> 64 </minInValue> <maxOutValue> 940 </minInValue> </Range> Example 5. Using \"Range\" for scaling 10-bit full range to 10-bit SMPTE (legal) range.","title":"Range"},{"location":"specifications/clf/#log","text":"Description: This node contains parameters for processing pixels through a logarithmic or anti-logarithmic function. A couple of main formulations are supported. The most basic formula follows a pure logarithm or anti-logarithm of either base 2 or base 10. Another supported formula allows for a logarithmic function with a gain factor and offset. This formulation can be used to convert from linear to Cineon. Another style of log formula follows a piece-wise function consisting of a logarithmic function with a gain factor, an offset, and a linear segment. This style can be used to implement many common \u201ccamera-log\u201d encodings. Note The equations for the Log node assume integer data is normalized to floating-point scaling. LogParams do not change based on the input and output bit-depths. Note On occasion it may be necessary to transform a logarithmic function specified in terms of traditional Cineon-style parameters to the parameters used by CLF . Guidance on how to do this is provided in Appendix B . Attributes: style (required specifies the form of the of log function to be applied Supported values for \u201dstyle\u201d are: \"log10\" \"antiLog10\" \"log2\" \"antiLog2\" \"linToLog\" \"logToLin\" \"cameraLinToLog\" \"cameraLogToLin\" The formula to be applied for each style is described by the equations below, for all of which: \\[ \\texttt{FLT_MIN} = 1.175494e\u221238 \\] \\(\\textrm{MAX}(a, b)\\) returns \\(a\\) if \\(a \\gt b\\) and \\(b\\) if \\(b \\geq a\\) \"log10\" : applies a base 10 logarithm according to \\[ y = log_{10}(\\textrm{MAX}(x,\\texttt{FLT_MIN})) \\] \"antiLog10\" : applies a base 10 anti-logarithm according to \\[ x = 10^{y} \\] \"log2\" : applies a base 2 logarithm according to \\[ y = log_{2}(\\textrm{MAX}(x,\\texttt{FLT_MIN})) \\] \"antiLog2\" : applies a base 2 anti-logarithm according to \\[ x = 2^{y} \\] \"linToLog\" : applies a logarithm according to \\[ y = \\text{logSideSlope} \\times \\text{log}_\\text{base}(\\textrm{MAX}(\\text{linSideSlope} \\times x + \\text{linSideOffset}, \\texttt{FLT_MIN}))+\\text{logSideOffset} \\] \"logToLin\" : applies an anti-logarithm according to \\[ x = \\frac{\\left(\\text{base}^{\\frac{y-\\text{logSideOffset}}{\\text{logSideSlope}}} - \\text{linSideOffset}\\right)}{\\text{linSideSlope}} \\] \"cameraLinToLog\" : applies a piecewise function with logarithmic and linear segments on linear values, converting them to non-linear values \\[ y = \\begin{cases} \\text{linearSlope} \\times x + \\text{linearOffset} & \\text{if } x \\leq \\text{linSideBreak}\\\\ \\text{logSideSlope} \\times \\text{log}_{\\text{base}}(\\mathrm{MAX}(\\text{linSideSlope} \\times x + \\text{linSideOffset},\\texttt{FLT_MIN})) + \\text{logSideOffset} & \\text{otherwise} \\\\ \\end{cases} \\\\ \\] Note The calculation of \\(\\text{linearSlope}\\) , and \\(\\text{linearOffset}\\) is described in Solving for LogParams \"cameraLogToLin\" : applies a piecewise function with logarithmic and linear segments on non-linear values, converting them to linear values \\[ x = \\begin{cases} \\frac{(y - \\text{linearOffset})}{\\text{linearSlope}} & \\text{if } y \\leq \\text{logSideBreak} \\\\ \\frac{\\left(\\text{base}^{\\frac{y-\\text{logSideOffset}}{\\text{logSideSlope}}} - \\text{linSideOffset}\\right)}{\\text{linSideSlope}} & \\text{otherwise} \\end{cases} \\] Note The calculation of \\(\\text{logSideBreak}\\) , \\(\\text{linearSlope}\\) , and \\(\\text{linearOffset}\\) is described in Solving for LogParams Elements: LogParams (required - if \"style\" is not a basic logarithm) contains the attributes that control the \"linToLog\" , \"logToLin\" , \"cameraLinToLog\" , or \"cameraLogToLin\" functions This element is required if style is of type \"linToLog\" , \"logToLin\" , \"cameraLinToLog\" , or \"cameraLogToLin\" . Attributes: \"base\" (optional) the base of the logarithmic function Default is 2. \"logSideOffset\" (optional) offset applied to the log side of the logarithmic segment. Default is 0. \"linSideSlope\" (optional) slope of the linear side of the logarithmic segment. Default is 1. \"linSideOffset\" (optional) offset applied to the linear side of the logarithmic segment. Default is 0. \"linSideBreak\" (optional) the break-point, defined in linear space, at which the piece-wise function transitions between the logarithmic and linear segments. This is required if style=\"cameraLinToLog\" or \"cameraLogToLin\" \"linearSlope\" (optional) the slope of the linear segment of the piecewise function. This attribute does not need to be provided unless the formula being implemented requires it. The default is to calculate using linSideBreak such that the linear portion is continuous in value with the logarithmic portion of the curve, by using the value of the logarithmic portion of the curve at the break-point. This is described in the following note below. \"channel\" (optional) the color channel to which the exponential function is applied. Possible values are \"R\" , \"G\" , \"B\" . If this attribute is utilized to target different adjustments per channel, then up to three LogParams elements may be used, provided that \"channel\" is set differently in each. However, the same value of base must be used for all channels. If this attribute is not otherwise specified, the logarithmic function is applied identically to all three color channels. Solving for LogParams \\(\\text{linearOffset}\\) is the offset of the linear segment of the piecewise function. This value is calculated using the position of the break-point and the linear slope in order to ensure continuity of the two segments. The following steps describe how to calculate \\(\\text{linearOffset}\\) . First, the value of the break-point on the log-axis is calculated using the value of \\(\\text{linSideBreak}\\) as input to the logarithmic segment of the piecewise function , as below: \\[ logSideBreak = logSideSlope \u00d7 logbase(linSideSlope \u00d7 linSideBreak + linSideOffset) + logSideOffset \\] Then, if \\(\\text{linearSlope}\\) was not provided, the value of \\(\\text{linSideBreak}\\) is used again to solve for the derivative of the logarithmic function. The value of \\(\\text{linearSlope}\\) is set to equal the instantaneous slope at the break-point, or derivative, as shown below: \\[ \\text{linearSlope} = \\text{logSideSlope} \\times \\left(\\frac{\\text{linSideSlope}}{(\\text{linSideSlope} \\times \\textbf{linSideBreak} + \\text{linSideOffset}) \\times \\text{ln}(\\text{base})}\\right) \\] Finally, the value of \\(\\text{linearOffset}\\) can be solved for by rearranging the linear segment of of the piecewise function and using the values of \\(\\text{logSideBreak|\\) and \\(\\text{linearSlope}\\) \\[ \\text{linearOffset} = \\textbf{logSideBreak} - \\textbf{ linearSlope} \\times \\text{linSideBreak} \\] Examples: <Log inBitDepth= \"16f\" outBitDepth= \"16f\" style= \"log10\" > <Description> Base 10 Logarithm </Description> </Log> Example 6. Log node applying a base 10 logarithm. <Log inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"cameraLinToLog\" > <Description> Linear to DJI D-Log </Description> <LogParams base= \"10\" logSideSlope= \"0.256663\" logSideOffset= \"0.584555\" linSideSlope= \"0.9892\" linSideOffset= \"0.0108\" linSideBreak= \"0.0078\" linearSlope= \"6.025\" /> </Log> Example 7. Log node applying the DJI D-Log formula.","title":"Log"},{"location":"specifications/clf/#exponent","text":"Description: This node contains parameters for processing pixels through a power law function. Two main formulations are supported. The first follows a pure power law. The second is a piecewise function that follows a power function for larger values and has a linear segment that is followed for small and negative values. The latter formulation can be used to represent the Rec. 709, sRGB, and CIE L* equations. Attributes: style (required) specifies the form of the exponential function to be applied. Supported values are: \"basicFwd\" \"basicRev\" \"basicMirrorFwd\" \"basicMirrorRev\" \"basicPassThruFwd\" \"basicPassThruRev\" \"monCurveFwd\" \"monCurveRev\" \"monCurveMirrorFwd\" \"monCurveMirrorRev\" Each of these supported styles are described in detail below, and for all of which the following definitions apply: \\(g =\\) exponent \\(k =\\) offset \\(\\textrm{MAX}(a, b)\\) returns \\(a\\) if \\(a \\gt b\\) and \\(b\\) if \\(b \\geq a\\) \"basicFwd\" applies a power law using the exponent value specified in the ExponentParams element. Values less than zero are clamped. \\[ \\text{basicFwd}(x) = [\\textrm{MAX}(0,x)]^g \\] \"basicRev\" applies power law using the exponent value specified in the ExponentParams element. Values less than zero are clamped. \\[ \\text{basicRev}(y) = [\\textrm{MAX}(0,y)]^{1/g} \\] \"basicMirrorFwd\" applies a basic power law using the exponent value specified in the ExponentParams element for values greater than or equal to zero and mirrors the function for values less than zero (i.e. rotationally symmetric around the origin): \\[ \\text{basicMirrorFwd}(x) = \\begin{cases} x^{g} & \\text{if } x \\geq 0 \\\\ [6pt] -\\Big[(-x)^{g}\\Big] & \\text{otherwise} \\end{cases} \\] \"basicMirrorRev\" applies a basic power law using the exponent value specified in the ExponentParams element for values greater than or equal to zero and mirrors the function for values less than zero (i.e. rotationally symmetric around the origin): \\[ \\text{basicMirrorRev}(y) = \\begin{cases} y^{1/g} & \\text{if } y \\geq 0 \\\\[6pt] -\\Big[(-y)^{1/g}\\Big] & \\text{otherwise} \\end{cases} \\] \"basicPassThruFwd\" applies a basic power law using the exponent value specified in the ExponentParams element for values greater than or equal to zero and passes values less than zero unchanged: \\[ \\text{basicPassThruFwd}(x) = \\begin{cases} x^{g} & \\text{if } x \\geq 0 \\\\[6pt] x & \\text{otherwise} \\end{cases} \\] \"basicPassThruRev\" applies a basic power law using the exponent value specified in the ExponentParams element for values greater than or equal to zero and and passes values less than zero un- changed: \\[ \\text{basicPassThruRev}(y) = \\begin{cases} y^{1/g} & \\text{if } y \\geq 0 \\\\[6pt] y & \\text{otherwise} \\end{cases} \\] \"monCurveFwd\" applies a power law function with a linear segment near the origin \\[ \\text{monCurveFwd}(x) = \\begin{cases} \\left( \\frac{x\\:+\\:k}{1\\:+\\:k} \\right)^{g} & \\text{if } x \\geq xBreak \\\\[8pt] x\\:s & \\text{otherwise} \\end{cases} \\] where: \\(xBreak = \\dfrac{k}{g-1}\\) and, for the \\(\\text{monCurveFwd}\\) ( above ) and \\(\\text{monCurveRev}\\) ( below ) equations: \\(s = \\left(\\dfrac{g-1}{k}\\right) \\left(\\dfrac{k g}{(g-1)(1+k)}\\right)^{g}\\) \"monCurveRev\" applies a power law function with a linear segment near the origin \\[ \\text{monCurveRev}(y) = \\begin{cases} (1 + k)\\:y^{(1/g)} - k & \\text{if } y \\geq yBreak \\\\[8pt] \\dfrac{y}{s} & \\text{otherwise} \\end{cases} \\] where: \\(yBreak = \\left(\\dfrac{k g}{(g-1)(1+k)}\\right)^g\\) \"monCurveMirrorFwd\" applies a power law function with a linear segment near the origin and mirrors the function for values less than zero (i.e. rotationally symmetric around the origin): \\[ \\text{monCurveMirrorFwd}(x) = \\begin{cases} \\text{monCurveFwd}(x) & \\text{if } x \\geq 0 \\\\[8pt] -[\\text{monCurveFwd}(-x)] & \\text{otherwise} \\end{cases} \\] \"monCurveMirrorRev\" applies a power law function with a linear segment near the origin and mirrors the function for values less than zero (i.e. rotationally symmetric around the origin): \\[ \\text{monCurveMirrorRev}(y) = \\begin{cases} \\text{monCurveRev}(y) & \\text{if } y \\geq 0 \\\\[8pt] -[\\text{monCurveRev}(-y)] & \\text{otherwise} \\end{cases} \\] Note The above equations assume that the input and output bit-depths are floating-point. Integer values are normalized to the range \\([0.0, 1.0]\\) . Elements: Description (optional) See ProcessNode ExponentParams (required) contains one or more attributes that provide the values to be used by the enclosing Exponent element. If style is any of the \u201cbasic\u201d types, then only exponent is required. If style is any of the \u201cmonCurve\u201d types, then exponent and offset are required. Attributes: \"exponent\" (required) the power to which the value is to be raised If style is any of the \u201cmonCurve\u201d types, the valid range is \\([1.0, 10.0]\\) . The nominal value is 1.0. Note When using a \u201cmonCurve\u201d style, a value of 1.0 assigned to exponent could result in a divide-by-zero error. Implementors should protect against this case. \"offset\" (optional) the offset value to use If offset is used, the enclosing Exponent element\u2019s style attribute must be set to one of the \u201cmonCurve\u201d types. Offset is not allowed when style is any of the \u201cbasic\u201d types. The valid range is \\([0.0, 0.9]\\) . The nominal value is 0.0. Note If zero is provided as a value for offset , the calculation of \\(xBreak\\) or \\(yBreak\\) could result in a divide-by-zero error. Implementors should protect against this case. \"channel\" (optional) the color channel to which the exponential function is applied. Possible values are \"R\" , \"G\" , \"B\" . If this attribute is utilized to target different adjustments per channel, up to three ExponentParams elements may be used, provided that \"channel\" is set differently in each. If this attribute is not otherwise specified, the exponential function is applied identically to all three color channels. Examples: <Exponent inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"basicFwd\" > <Description> Basic 2.2 Gamma </Description> <ExponentParams exponent= \"2.2\" /> </Exponent> Example 8. Using Exponent node for applying a 2.2 gamma. <Exponent inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"monCurveFwd\" > <Description> EOTF (sRGB) </Description> <ExponentParams exponent= \"2.4\" offset= \"0.055\" /> </Exponent> Example 9. Using Exponent node for applying the intended EOTF found in IEC 61966-2-1:1999 (sRGB). <Exponent inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"monCurveRev\" > <Description> CIE L* </Description> <ExponentParams exponent= \"3.0\" offset= \"0.16\" /> </Exponent> Example 10. Using Exponent node to apply CIE L* formula. <Exponent inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"monCurveRev\" > <Description> Rec. 709 OETF </Description> <ExponentParams exponent= \"2.2222222222222222\" offset= \"0.099\" /> </Exponent> Example 11. Using Exponent node to apply Rec. 709 OETF.","title":"Exponent"},{"location":"specifications/clf/#asc_cdl","text":"Description: This node processes values according to the American Society of Cinematographers\u2019 Color Decision List ( ASC CDL ) equations. Color correction using ASC CDL is an industry-wide method of recording and exchanging basic color correction adjustments via parameters that set particular color processing equations. The ASC CDL equations are designed to work on an input domain of floating-point values of [0 to 1.0] although values greater than 1.0 can be present. The output data may or may not be clamped depending on the processing style used. Note Equations 4.31-4.34 assume that \\(in\\) and \\(out\\) are scaled to normalized floating-point range. If the ASC_CDL node has inBitDepth or outBitDepth that are integer types, then the input or output values must be normalized to or from 0-1 scaling. In other words, the slope, offset, power, and saturation values stored in the ProcessNode do not depend on inBitDepth and outBitDepth ; they are always interpreted as if the bit depths were float. Attributes: id (optional) This should match the id attribute of the ColorCorrection element in the ASC CDL XML format. style (required) Determines the formula applied by the operator. The valid options are: \"Fwd\" implementation of v1.2 ASC CDL equation \"Rev\" inverse equation \"FwdNoClamp\" similar to the Fwd equation, but without clamping \"RevNoClamp\" inverse equation, without clamping The first two implement the math provided in version 1.2 of the ASC CDL specification. The second two omit the clamping step and are intended to provide compatibility with the many applications that take that alternative approach. Elements: SOPNode (optional) The SOPNode is optional, and if present, must contain each of the following sub-elements: Slope three decimal values representing the R, G, and B slope values, which is similar to gain, but changes the slope of the transfer function without shifting the black level established by offset Valid values for slope must be greater than or equal to zero ( \\(\\geq\\) 0). The nominal value is 1.0 for all channels. Offset three decimal values representing the R, G, and B offset values, which raise or lower overall brightness of a color component by shifting the transfer function up or down while holding the slope constant The nominal value is 0.0 for all channels. Power three decimal values representing the R, G, and B power values, which change the intermediate shape of the transfer function Valid values for power must be greater than zero ( \\(\\gt\\) 0). The nominal value is 1.0 for all channels. SatNode (optional) The SatNode is optional, but if present, must contain one of the following sub-element: Saturation a single decimal value applied to all color channels Valid values for saturation must be greater than or equal to zero ( \\(\\geq\\) 0). The nominal value is 1.0. Note If either element is not specified, values should default to the nominal values for each element. If using the \"noClamp\" style, the result of the defaulting to the nominal values is a no-op. Note The structure of this ProcessNode matches the structure of the XML format described in the v1.2 ASC CDL specification. However, unlike the ASC CDL XML format, there are no alternate spellings allowed for these elements. The math for style=\"Fwd\" is: \\[ out_{\\textrm{SOP}} = \\textrm{CLAMP}(in \\times \\textrm{slope} + \\textrm{offset})^{\\textrm{power}} \\] \\[ \\begin{aligned} luma &= 0.2126 \\times out_{\\textrm{SOP,R}} + 0.7152 \\times out_{\\textrm{SOP,G}} + 0.0722 \\times out_{\\textrm{SOP,B}} \\\\ out &= \\textrm{CLAMP}\\Big[luma + \\textrm{saturation} \\times (out_{\\textrm{SOP}} \u2212 luma)\\Big] \\end{aligned} \\] Where: \\(\\textrm{CLAMP()}\\) clamps the argument to \\([0,1]\\) The math for style=\"FwdNoClamp\" is the same as for \"Fwd\" but the two clamp() functions are omitted. Also, if \\((in \\times \\textrm{slope} + \\textrm{offset}) < 0\\) , then no power function is applied. The math for style=\"Rev\" is: \\[ \\begin{aligned} in_{\\textrm{clamp}} &= \\mathrm{CLAMP}(in) \\\\ luma &= 0.2126 \\times in_{\\textrm{clamp,R}} + 0.7152 \\times in_{\\textrm{clamp,G}} + 0.0722 \\times in_{\\textrm{clamp,B}} \\\\ out_{\\textrm{SAT}} &= luma + \\frac{(in_{\\textrm{clamp}} - luma)}{\\textrm{saturation}} \\end{aligned} \\] \\[ out = \\mathrm{CLAMP}\\left(\\frac{\\mathrm{CLAMP}(out_{\\textrm{SAT}})^{\\frac{1}{\\textrm{power}}} - \\textrm{offset}}{\\textrm{slope}}\\right) \\\\ \\] Where: \\(\\textrm{CLAMP()}\\) clamps the argument to \\([0,1]\\) The math for style=\"RevNoClamp\" is the same as for \"Rev\" but the \\(\\textrm{CLAMP}()\\) functions are omitted. Also, if \\(out_{\\textrm{SAT}} \\lt 0\\) , then no power function is applied. Examples: <ASC_CDL id= \"cc01234\" inBitDepth= \"16f\" outBitDepth= \"16f\" style= \"Fwd\" > <Description> scene 1 exterior look </Description> <SOPNode> <Slope> 1.000000 1.000000 0.900000 </Slope> <Offset> -0.030000 -0.020000 0.000000 </Offset> <Power> 1.2500000 1.000000 1.000000 </Power> </SOPNode> <SatNode> <Saturation> 1.700000 </Saturation> </SatNode> </ASC_CDL> Example 12. Example of an ASC_CDL node.","title":"ASC_CDL"},{"location":"specifications/clf/#implementation-notes","text":"","title":"Implementation Notes"},{"location":"specifications/clf/#bit-depth","text":"","title":"Bit Depth"},{"location":"specifications/clf/#required-vs-optional","text":"The required or optional indicated in parentheses throughout this specification indicate the requirement for an element or attribute to be present for a valid CLF file. In the spirit of a LUT format to be used commonly across different software and hardware, none of the elements or attributes should be considered optional for implementors to support. All elements and attributes, if present, should be recognized and supported by an implementation. If, due to hardware or software limitations, a particular element or attribute is not able to be supported, a warning should be issued to the user of a LUT that contains one of the offending elements. The focus shall be on the user and maintaining utmost compatibility with the specification so that LUTs can be interchanged seamlessly.","title":"Required vs Optional"},{"location":"specifications/clf/#efficient-processing","text":"The transform engine may merge some ProcessNodes in order to obtain better performance. For example, adjacent Matrix operators may be combined into a single matrix. However, in general, combining operators in a way that preserves accuracy is difficult and should be avoided. Hardware implementations may need to convert all ProcessNodes into some other form that is consistent with what the hardware supports. For example, all ProcessNodes might need to be combined into a single 3D LUT . Using a grid size of 64 or larger is recommended to preserve as much accuracy as possible. Implementors should be aware that the success of such approximations varies greatly with the nature of the input and output color spaces. For example, if the input color space is scene-linear in nature, it may be necessary to use a \u201cshaper LUT \u201d or similar non-linearity before the 3D LUT in order to convert values into a more perceptually uniform representation.","title":"Efficient Processing"},{"location":"specifications/clf/#extensions","text":"It is recommended that implementors of CLF file readers protect against unrecognized elements or attributes that are not defined in this specification. Unrecognized elements that are not children of the Info element should either raise an error or at least provide a warning message to the user to indicate that there is an operator present that is not recognized by the reader. Applications that need to add custom metadata should place it under the Info element rather than at the top level of the ProcessList. One or more Description elements in the ProcessList can and should be used for metadata that does not fit into a provided field in the Info element and/or is unlikely to be recognized by other applications.","title":"Extensions"},{"location":"specifications/clf/#examples","text":"<?xml version=\"1.0\" encoding=\"UTF-8\"?> <ProcessList id= \"ACEScsc.ACES_to_ACEScg.a1.0.3\" name= \"ACES2065-1 to ACEScg\" compCLFversion= \"3.0\" > <Info> <ACEStransformID> ACEScsc.ACES_to_ACEScg.a1.0.3 </ACEStransformID> <ACESuserName> ACES2065-1 to ACEScg </ACESuserName> </Info> <Description> ACES2065-1 to ACEScg </Description> <InputDescriptor> ACES2065-1 </InputDescriptor> <OutputDescriptor> ACEScg </OutputDescriptor> <Matrix inBitDepth= \"16f\" outBitDepth= \"16f\" > <Array dim= \"3 3\" > 1.451439316146 -0.236510746894 -0.214928569252 -0.076553773396 1.176229699834 -0.099675926438 0.008316148426 -0.006032449791 0.997716301365 </Array> </Matrix> </ProcessList> Example 13. ACES2065-1 to ACEScg <?xml version=\"1.0\" encoding=\"UTF-8\"?> <ProcessList id= \"ACEScsc.ACES_to_ACEScct.a1.0.3\" name= \"ACES2065-1 to ACEScct\" compCLFversion= \"3.0\" > <Description> ACES2065-1 to ACEScct Log working space </Description> <InputDescriptor> Academy Color Encoding Specification (ACES2065-1) </InputDescriptor> <OutputDescriptor> ACEScct Log working space </OutputDescriptor> <Info> <ACEStransformID> ACEScsc.ACES_to_ACEScct.a1.0.3 </ACEStransformID> <ACESuserName> ACES2065-1 to ACEScct </ACESuserName> </Info> <Matrix inBitDepth= \"16f\" outBitDepth= \"16f\" > <Array dim= \"3 3\" > 1.451439316146 -0.236510746894 -0.214928569252 -0.076553773396 1.176229699834 -0.099675926438 0.008316148426 -0.006032449791 0.997716301365 </Array> </Matrix> <Log inBitDepth= \"16f\" outBitDepth= \"16f\" style= \"cameraLinToLog\" > <LogParams base= \"2\" logSideSlope= \"0.05707762557\" logSideOffset= \"0.5547945205\" linSideBreak= \"0.0078125\" /> </Log> </ProcessList> Example 14. ACES2065-1 to ACEScct <?xml version=\"1.0\" encoding=\"UTF-8\"?> <ProcessList id= \"5ac02dc7-1e02-4f87-af46-fa5a83d5232d\" compCLFversion= \"3.0\" > <Description> CIE-XYZ D65 to CIELAB L*, a*, b* (scaled by 1/100, neutrals at 0.0 chroma) </Description> <InputDescriptor> CIE-XYZ, D65 white (scaled [0,1]) </InputDescriptor> <OutputDescriptor> CIELAB L*, a*, b* (scaled by 1/100, neutrals at 0.0 chroma) </OutputDescriptor> <Matrix inBitDepth= \"16f\" outBitDepth= \"16f\" > <Array dim= \"3 3\" > 1.052126639 0.000000000 0.000000000 0.000000000 1.000000000 0.000000000 0.000000000 0.000000000 0.918224951 </Array> </Matrix> <Exponent inBitDepth= \"16f\" outBitDepth= \"16f\" style= \"monCurveRev\" > <ExponentParams exponent= \"3.0\" offset= \"0.16\" /> </Exponent> <Matrix inBitDepth= \"16f\" outBitDepth= \"16f\" > <Array dim= \"3 3\" > 0.00000000 1.00000000 0.00000000 4.31034483 -4.31034483 0.00000000 0.00000000 1.72413793 -1.72413793 </Array> </Matrix> </ProcessList> Example 15. CIE XYZ to CIELAB","title":"Examples"},{"location":"specifications/clf/#appendices","text":"","title":"Appendices"},{"location":"specifications/clf/#appendix-interpolation","text":"When an input value falls between sampled positions in a LUT , the output value must be calculated as a proportion of the distance along some function that connects the nearest surrounding values in the LUT . There are many different types of interpolation possible, but only three types of interpolation are currently specified for use with the Common LUT Format ( CLF ). The first interpolation type, linear , is specified for use with a LUT1D node. The other two, trilinear and tetrahedral interpolation, are specified for use with a LUT3D node.","title":"Appendix A: Interpolation"},{"location":"specifications/clf/#appendix-cineon-style","text":"When using a Log node, it might be desirable to conform an existing logarithmic function that uses Cineon style parameters to the parameters used by CLF . A translation from Cineon-style parameters to those used by CLF 's LogParams element is quite straightforward using the following steps. Traditionally, \\(\\textrm{refWhite}\\) and \\(\\textrm{refBlack}\\) are provided as 10-bit quantities, and if they indeed are, first normalize them to floating point by dividing by 1023: \\[ \\begin{align} \\textrm{refWhite} = \\frac{\\textrm{refWhite}_{10i}}{1023.0} \\\\[12pt] \\textrm{refBlack} = \\frac{\\textrm{refBlack}_{10i}}{1023.0} \\end{align} \\] where subscript 10 \\(i\\) indicates a 10-bit quantity. The density range is assumed to be: \\[ \\textrm{range} = 0.002 \\times 1023.0 \\] Then solve the following quantities: \\[ \\begin{align} \\textrm{multFactor} =& \\frac{\\textrm{range}}{\\textrm{gamma}} \\\\ \\textrm{gain} =& \\frac{\\textrm{highlight} - \\textrm{shadow}}{1.0 - 10^{( MIN( \\textrm{multFactor} \\times (\\textrm{refBlack}-\\textrm{refWhite}), -0.0001)}} \\\\[6pt] \\textrm{offset} =& \\ \\textrm{gain} - (\\textrm{highlight} - \\textrm{shadow}) \\\\ \\end{align} \\] Where \\(MIN(x,y)\\) returns \\(x\\) if \\(x<y\\) , otherwise returns \\(y\\) The parameters for the LogParams element are then: \\[\\begin{align} \\texttt{base} =& \\ 10.0 \\\\[6pt] \\texttt{logSlope} =& \\ \\frac{1}{\\textrm{multFactor}} \\\\[6pt] \\texttt{logOffset} =& \\ \\textrm{refWhite} \\\\[6pt] \\texttt{linSlope} =& \\ \\frac{1}{\\textrm{gain}} \\\\[6pt] \\texttt{linOffset} =& \\ \\frac{\\textrm{offset}-\\textrm{shadow}}{\\textrm{gain}} \\end{align}\\]","title":"Appendix B: Cineon-style Log Parameters"},{"location":"specifications/clf/#appendix-c-changes-between-v20-and-v30","text":"Add Log ProcessNode Add Exponent ProcessNode Revise formulas for defining use of Range ProcessNode to clamp at the low or high end. IndexMaps removed. Use a halfDomain LUT to achieve reshaping of input to a LUT . Move ACEStransform elements to Info element of ProcessList in main spec Changed syntax for dim attribute of Array when contained in a Matrix . Two integers are now used to define the dimensions of the matrix instead of the previous three values which defined the dimensions of the matrix and the number of color components. @import \"../../stylesheets/sections.css\"","title":"Appendix C: Changes between v2.0 and v3.0"},{"location":"specifications/rgc/","text":"Reference Gamut Compression ( RGC ) - A Look Transform to bring pixel values within AP1 \u00b6 Scope \u00b6 This document introduces a Reference Gamut Compression ( RGC ) operator, published in ACES 1.3, which may be applied to ACES image data to \u201cheal\u201d pixel values outside the AP1 gamut. The Reference Gamut Compression algorithm is intended to replace the Blue Light Artifact LMT , which is now deprecated. References \u00b6 The following standards, specifications, articles, presentations, and texts are referenced in this text: ACES Gamut Mapping Architecture VWG - Technical Documentation Deliverable ISO 17321-1:2012 - Colour characterisation of digital still cameras (DSCs) - Part 1: Stimuli, metrology and test procedures RP 177:1993 - SMPTE Recommended Practice - Derivation of Basic Television Color Equations S-2014-004: ACEScg \u2014 A Working Space for CGI Render and Compositing Introduction \u00b6 A common complaint from users of ACES has been the artifacts resulting from out of gamut values in source images. These artifacts are most known for appearing in highly saturated, bright LED light sources such as police car lights, stoplights, etc - but also appear frequently in LED sources used to light scenes. In an ACES workflow, these artifacts appear at two stages - first in the conversion from camera raw RGB via an Input Transform ( IDT ) into ACES AP0 - and second in the conversion from ACES AP0 into ACES AP1 (ACEScg and ACEScct). These out of gamut pixel values are problematic when their negative components cause issues in compositing, and may also produce visual artifacts when viewed through an ACES Output Transform. A Look Modification Transform ( LMT ) referred to as the blue light artifact fix was created as a temporary solution, but this affected all pixels in the image, rather than just the problem areas. A new solution was needed which preserved colors within a \u201czone of trust\u201d, only altering the most saturated values. Specification \u00b6 ACEScg values within the AP1 gamut are positive. Values outside of the AP1 gamut are negative in one or two of their components. The gamut compression algorithm runs per-pixel. ACES RGB values shall be converted to gamut compressed ACES RGB values using the following steps. Step 1 \u2013 Convert ACES 2065-1 RGB to ACEScg RGB \u00b6 ACES 2065-1 RGB values shall be converted to ACEScg RGB values using the transformation matrix ( \\(TRA_1\\) ) calculated and applied using the methods provided in Section 4 of SMPTE RP 177:1993. Note Equation 1 shows the relationship between ACES R, G, and B values and ACEScg RGB values. NPM, rounded to 10 decimal places, is derived using the color space chromaticity coordinates specified in SMPTE S 2065-1, Academy Specification S-2014-004, and the methods provided in Section 3.3 of SMPTE RP 177:1993. \\[ \\begin{bmatrix}R_{ACEScg}\\\\G_{ACEScg}\\\\B_{ACEScg}\\end{bmatrix}=TRA_1\\cdot \\begin{bmatrix}R_{ACES}\\\\G_{ACES}\\\\B_{ACES}\\end{bmatrix} \\] \\[ TRA_1=\\begin{bmatrix}\\phantom{-}1.4514393161 & -0.2365107469 & -0.2149285693 \\\\-0.0765537734 & \\phantom{-}1.1762296998 & -0.0996759264\\\\\\phantom{-}0.0083161484 & -0.0060324498 & \\phantom{-}0.9977163014 \\\\\\end{bmatrix} \\] \\[ TRA_1 = {NPM_{AP1}}^{-1}\\cdot NPM_{AP0} \\] Equation 1 Step 2 \u2013 Calculate A \u00b6 Calculate \\(A\\) using Equation 2. \\[ A = \\text{MAX}(R_{ACEScg}, G_{ACEScg}, B_{ACEScg}) \\] where: \\(\\textrm{MAX()}\\) returns the maximum of the arguments Equation 2 Note A is used as representative of the achromatic value of the pixel. Step 3 \u2013 Calculate d n \u00b6 Calculate \\(d_n\\) using Equation 3. \\[ d_n = \\begin{cases}\\frac{A - RGB_{ACEScg}}{\\text{ABS} \\left ( A \\right )},& \\text{if } A\\neq0\\\\0,& \\text{otherwise}\\end{cases} \\] where : \\(\\textrm{ABS()}\\) returns the absolute value of the argument Equation 3 Note \\(d_n\\) represents the normalized distances of the channels from the achromatic, or \u201cinverse RGB ratios\u201d. Step 4 \u2013 Calculate d c \u00b6 Compress \\(d_n\\) to produce \\(d_c\\) using Equation 4. \\[ d_c = \\begin{cases}d_n,& \\text{if }d_n < t\\\\t + \\frac{d_n-t}{\\left ( 1+d_p \\right ) ^{\\frac{1}{p}}}\\end{cases} \\] where : \\[ l = \\begin{bmatrix}1.147 \\\\ 1.264 \\\\ 1.312\\end{bmatrix}\\ t = \\begin{bmatrix}0.815 \\\\ 0.803 \\\\ 0.880\\end{bmatrix}\\ p = 1.2 \\] \\[ s = \\frac{l - t}{\\left (\\left (\\frac{1 - t}{l - t} \\right )^{-p} - 1\\right )^\\frac{1}{p}} \\] \\[ d_p = \\left ( \\frac{d_n - t}{s} \\right )^{p} \\] Equation 4 Note The compression function compresses values at limit ( \\(l\\) ) to 1.0. This results in values beyond this limit remaining outside AP1 after compression. A function which compressed all values to within AP1 would require a significant proportion of the space between threshold ( \\(t\\) ) and 1.0 to be reserved for values which are highly unlikely to occur, thus compressing other values more than necessary. Limit ( \\(l\\) ) values have been chosen so that the encoding gamuts of all digital cinema cameras with official ACES IDTs (ARRI, RED, Canon, Sony, Panasonic) will compress to within AP1. Threshold ( \\(t\\) ) values have been derived from the boundary of the ACEScg values for the ColorChecker Classic 24 (as specified in ISO 17321-1). The exponent ( \\(p\\) ) has been set to an average value, chosen following user testing, since there is no objective measure of the correctness of this value. Step 5 \u2013 Calculate RGB c \u00b6 Calculate \\(RGB_c\\) using Equation 5. \\[ RGB_c = A - d_c \\times \\text{ABS}\\left ( A \\right ) \\] where : \\(\\textrm{ABS()}\\) returns the absolute value of the argument Equation 5 Step 6 \u2013 Convert RGB c to ACES2065-1 RGB \u00b6 Gamut compressed ACEScg RGB values ( \\(RGB_c\\) ) shall be converted to ACES2065-1 RGB values using the transformation matrix ( \\(TRA_2\\) ) calculated and applied using the methods provided in Section 4 of SMPTE RP 177:1993. Note Equation 6 shows the relationship between ACEScg R, G, and B values and ACES2065-1 RGB values. NPM, rounded to 10 decimal places, is derived using the color space chromaticity coordinates specified in SMPTE S 2065-1, Academy Specification S-2014-004, and the methods provided in Section 3.3 of SMPTE RP 177. \\[ \\begin{bmatrix}R_{ACES}\\\\G_{ACES}\\\\B_{ACES}\\end{bmatrix}=TRA_2\\cdot \\begin{bmatrix}R_c\\\\G_c\\\\B_c\\end{bmatrix} \\] \\[ TRA_2=\\begin{bmatrix} \\phantom{-}0.6954522414 & \\phantom{-}0.1406786965 & \\phantom{-}0.1638690622 \\\\ \\phantom{-}0.0447945634 & \\phantom{-}0.8596711185 & \\phantom{-}0.0955343182 \\\\ -0.0055258826 & \\phantom{-}0.0040252103 & \\phantom{-}1.0015006723 \\\\\\end{bmatrix} \\] \\[ TRA_2 = {NPM_{AP0}}^{-1} \\cdot NPM_{AP1} \\] Equation 6 Gamut Decompression \u00b6 While the Reference Gamut Compression has a closed form inverse, its use is not normally recommended. Gamut compressed ACES RGB values may be converted back to the original ACES RGB values using the same steps as for compression above, but using Equation 4b in place of Equation 4. \\[ d_c = \\begin{cases}t + s \\times \\left ( \\frac{d_p}{1-d_p} \\right ) ^{\\frac{1}{p}},& \\text{if }t \\leq d_n \\leq t + s\\\\d_n,& \\text{otherwise}\\end{cases} \\] Equation 4b Note \\(l\\) , \\(t\\) , \\(p\\) , \\(s\\) and \\(d_p\\) are as defined in Equation 4. Tracking \u00b6 The Reference Gamut Compression is defined as a Look Transform ( LMT ) in CTL and has the following ACES Transform ID: <ACEStransformID>urn:ampas:aces:transformId:v1.5:LMT.Academy.GamutCompress.a1.3.0</ACEStransformID> This is trackable via a lookTransform element in an AMF file. If the RCG is used in the viewing pipeline, the lookTransform will be listed in the associated AMF . If the AMF is accompanying rendered media, the applied flag should be used to track whether or not the RGC has been \u201cbaked in\u201d. If using the RGC in a viewing pipeline, this lookTransform should appear directly after the IDT , first in the list of any LMTs, to make sure other operations benefit from the gamut compression. The Transform ID should be included in any exported AMFs, with the applied flag set as appropriate, and the description set to the ACESuserName to enable proper tracking. Currently, only the Reference (i.e. static) Gamut Compression is trackable via AMF . Appendix A - History / Research \u00b6 The Architecture Virtual Working Group, chaired by Carol Payne (Netflix) and Matthias Scharfenberg (ILM), to investigate gamut mapping in ACES began its work in January 2020, with a proposal outlining the main issue as: Users of ACES are experiencing problems with out of gamut colors and the resulting artifacts (loss of texture, intensification of color fringes). This issue occurs at two stages in the pipeline. Conversion from camera raw RGB or from the manufacturer\u2019s encoding space into ACES AP0 Conversion from ACES AP0 into the working color space ACES AP1 It was acknowledged early on in the group that this artifacting can also occur in VFX /Color grading, as well as the Output Transform stages in the pipeline. The working group chairs set the scope: Propose transforms between color spaces that avoid or reduce color clipping. Solutions for this may include: Proposing a suitable color encoding space for digital motion-picture cameras. Proposing a suitable working color space. Propose a suitable gamut mapping/compression algorithm that performs well with wide gamut, high dynamic range, scene referred content that is robust and invertible. The group started out investigating the working and encoding spaces ( ACES 2065-1 and ACEScg). However, it was agreed early on that although the possibility of creating a new ACES working space which mitigates common gamut issues should not be discounted, it would require a very strong case as to the benefits. Changing a core component of ACES would potentially introduce backwards compatibility issues, and would also be based only on the situation at the current time. It raised the possibility of having to change the working space repeatedly in future. Thus, the focus moved on to the third option - a suitable algorithm to solve the artifacting while maintaining as much of the current ACES standards and structure as possible. The gamut mapping approach chosen is one of compression. It deals with the ACES image data \u201cas is\u201d, and simply strives to convert that into less problematic image data. Based on the history above, the general working assumptions were: Samples are relative scene exposure values (i.e. scene-referred linear data) with no assumed min/max value range boundaries The gamut mapping operator is per-pixel only (i.e. not spatial or temporal) The stated ideals for a gamut compression algorithm were: Exposure invariance \u2014 \\(f(a \\cdot RGB) = a \\cdot f(RGB)\\) Source gamut agnosticism Monotonicity Simplicity \u2013 suited to a fast shader implementation Invertibility (see caveats in Appendix II) Colors in a \u201czone of trust\u201d will be left unaltered While a suitable algorithm should be able to map arbitrary gamut A into arbitrary gamut B, it should not be a requirement that all source data must be contained within gamut A. Nor is it necessarily a requirement that the output should be entirely bounded by gamut B. Indeed, allowing extreme source values to be mapped to output values close to, but not within, the target gamut means that the compression function does not need to tend to the horizontal at the boundary. This means that its inverse will not tend to the vertical, which is beneficial for invertibility. Because the unreal colors which occur are a result of the mismatch between a camera and human observer (among other causes) and are outliers in the residual error of a transform optimized for a subset of important \u201cmemory\u201d colors, what they \u201cshould\u201d look like is somewhat undefined. The important thing is to remap them into values which are plausible rather than \u201caccurate\u201d. What was determined to be outside the scope: Colorimetric accuracy or spectral plausibility of input device transforms (IDTs) Display gamut mapping. (Required modifications to the RRT / ODT will need to be addressed by a subsequent group.) Customizing for specific input/output gamuts Working in bounded or volume-based gamuts Actions which could limit creative choices further down the line (e.g. excessive desaturation) User Testing \u00b6 Once the working group settled on the baseline algorithm and its properties a set of targeted, small scale user tests were conducted to ensure the foundations of the work were solid. The testing was composed of two groups - VFX compositors and colorists. Between these two disciplines every major use case for the gamut compression algorithm could be tested and measured. The group gathered an open repository of test images that clearly exhibited the problem to be solved. It then derived a set of test scenarios for each group ranging from keying, blur, grain matching, hue adjustment, and more. The tests were conducted in Nuke and Resolve, on both SDR and HDR monitors. User Testing Footage Examples Overall, the results of the user testing were positive and uncovered no major issues in the algorithm functionality. 75% of compositors and 96% of colorists stated that using the algorithm helped them complete their work and achieve their creative goals. For full user testing results, please refer to the working group historical repository . Appendix B \u2013 Implementation Considerations \u00b6 Invertibility \u00b6 Invertibility of the transformation is an aspect that was discussed at length. The consensus was that while an inverse transform should be defined it comes with the caveat that gamut expansion can create undesirable results when used with highly saturated pixel values, such as those added as part of graphics or CG rendered imagery As this operation is considered more of a \u201cpixel healing\u201d technical operation, inversion should not be a required part of the workflow. It is more akin to a despill after pulling a key, or a bit of sharpening on a scale operation. 3D LUT Approximation \u00b6 If there is an unavoidable requirement to implement the Reference Gamut Compression on legacy systems using a 3D lookup table ( LUT ) special consideration must be given to the shaper function. Common functions for implementing ACES transforms as 3D LUTs are the Log2 shaper or ACEScct. However neither of those are designed to cover the negative value range required to map the negative components of out of gamut colors into a normalized 0 to 1 domain. For a successful 3D LUT implementation the normalizing shaper function must also cover a significant range of negative values. Due to the residual error a 3D LUT approximation of the transform should be considered to be non-invertible. Systems used as part of the finishing pipeline should use a mathematical implementation of the RGC , rather than a LUT . But for preview purposes, a well constructed LUT may be acceptable, particularly if it is a concatenation of all the required transforms, such as an on-set preview LUT transforming camera log to Rec.709. Parametric Version \u00b6 Some implementations may also choose to offer a parametric variation of the RGC . This is not officially endorsed as part of ACES , and should be treated simply as another grading operator. It should not be used as a replacement for the RGC since its parameters cannot be tracked by AMF and must instead be stored in the project files of the implementing application. Suggested parameter names, and default values for a parametric version are given in Section 9 of the RGC Implementation guide . Appendix C: Illustrations \u00b6 Distance Limit (CIExy Chromaticity Plot) Compression Threshold and ColorChecker 24 Patches (CIExy Chromaticity Plot) Before Gamut Compression (ACES Rec. 709 Output Transform) Gamut Compression Note that the red value has also been moved slightly, because although it was not negative, its normalized distance was close to 1.0, and beyond the protected threshold for that channel (0.815). After Gamut Compression (ACES Rec. 709 Output Transform) Gamut Compression Polar Chromaticity Grid Appendix D: CTL Reference Implementation \u00b6 // <ACEStransformID>urn:ampas:aces:transformId:v1.5:LMT.Academy.ReferenceGamutCompress.a1.v1.0</ACEStransformID> // <ACESuserName>ACES 1.3 Look - Reference Gamut Compress</ACESuserName> // // Gamut compression algorithm to bring out-of-gamut scene-referred values into AP1 // // // Usage: // This transform is intended to be applied to AP0 data, immediately after the IDT, so // that all grading or compositing operations are downstream of the compression, and // therefore work only with positive AP1 values. // // Note: // It is not recommended to bake the compression into VFX pulls, as it may be beneficial // for compositors to have access to the unmodified image data. // // // Input and output: ACES2065-1 // import \"ACESlib.Transform_Common\"; /* --- Gamut Compress Parameters --- */ // Distance from achromatic which will be compressed to the gamut boundary // Values calculated to encompass the encoding gamuts of common digital cinema cameras const float LIM_CYAN = 1.147; const float LIM_MAGENTA = 1.264; const float LIM_YELLOW = 1.312; // Percentage of the core gamut to protect // Values calculated to protect all the colors of the ColorChecker Classic 24 as given by // ISO 17321-1 and Ohta (1997) const float THR_CYAN = 0.815; const float THR_MAGENTA = 0.803; const float THR_YELLOW = 0.880; // Aggressiveness of the compression curve const float PWR = 1.2; // Calculate compressed distance float compress(float dist, float lim, float thr, float pwr) { float comprDist; float scl; float nd; float p; if (dist < thr) { comprDist = dist; // No compression below threshold } else { // Calculate scale factor for y = 1 intersect scl = (lim - thr) / pow(pow((1.0 - thr) / (lim - thr), -pwr) - 1.0, 1.0 / pwr); // Normalize distance outside threshold by scale factor nd = (dist - thr) / scl; p = pow(nd, pwr); comprDist = thr + scl * nd / (pow(1.0 + p, 1.0 / pwr)); // Compress } return comprDist; } void main ( input varying float rIn, input varying float gIn, input varying float bIn, input varying float aIn, output varying float rOut, output varying float gOut, output varying float bOut, output varying float aOut ) { // Source values float ACES[3] = {rIn, gIn, bIn}; // Convert to ACEScg float linAP1[3] = mult_f3_f44(ACES, AP0_2_AP1_MAT); // Achromatic axis float ach = max_f3(linAP1); // Distance from the achromatic axis for each color component aka inverse RGB ratios float dist[3]; if (ach == 0.0) { dist[0] = 0.0; dist[1] = 0.0; dist[2] = 0.0; } else { dist[0] = (ach - linAP1[0]) / fabs(ach); dist[1] = (ach - linAP1[1]) / fabs(ach); dist[2] = (ach - linAP1[2]) / fabs(ach); } // Compress distance with parameterized shaper function float comprDist[3] = { compress(dist[0], LIM_CYAN, THR_CYAN, PWR), compress(dist[1], LIM_MAGENTA, THR_MAGENTA, PWR), compress(dist[2], LIM_YELLOW, THR_YELLOW, PWR) }; // Recalculate RGB from compressed distance and achromatic float comprLinAP1[3] = { ach - comprDist[0] * fabs(ach), ach - comprDist[1] * fabs(ach), ach - comprDist[2] * fabs(ach) }; // Convert back to ACES2065-1 ACES = mult_f3_f44(comprLinAP1, AP1_2_AP0_MAT); // Write output rOut = ACES[0]; gOut = ACES[1]; bOut = ACES[2]; aOut = aIn; } @import \"../../stylesheets/sections.css\"","title":"Index"},{"location":"specifications/rgc/#reference-gamut-compression-rgc-a-look-transform-to-bring-pixel-values-within-ap1","text":"","title":"Reference Gamut Compression (RGC) - A Look Transform to bring pixel values within AP1"},{"location":"specifications/rgc/#scope","text":"This document introduces a Reference Gamut Compression ( RGC ) operator, published in ACES 1.3, which may be applied to ACES image data to \u201cheal\u201d pixel values outside the AP1 gamut. The Reference Gamut Compression algorithm is intended to replace the Blue Light Artifact LMT , which is now deprecated.","title":"Scope"},{"location":"specifications/rgc/#references","text":"The following standards, specifications, articles, presentations, and texts are referenced in this text: ACES Gamut Mapping Architecture VWG - Technical Documentation Deliverable ISO 17321-1:2012 - Colour characterisation of digital still cameras (DSCs) - Part 1: Stimuli, metrology and test procedures RP 177:1993 - SMPTE Recommended Practice - Derivation of Basic Television Color Equations S-2014-004: ACEScg \u2014 A Working Space for CGI Render and Compositing","title":"References"},{"location":"specifications/rgc/#introduction","text":"A common complaint from users of ACES has been the artifacts resulting from out of gamut values in source images. These artifacts are most known for appearing in highly saturated, bright LED light sources such as police car lights, stoplights, etc - but also appear frequently in LED sources used to light scenes. In an ACES workflow, these artifacts appear at two stages - first in the conversion from camera raw RGB via an Input Transform ( IDT ) into ACES AP0 - and second in the conversion from ACES AP0 into ACES AP1 (ACEScg and ACEScct). These out of gamut pixel values are problematic when their negative components cause issues in compositing, and may also produce visual artifacts when viewed through an ACES Output Transform. A Look Modification Transform ( LMT ) referred to as the blue light artifact fix was created as a temporary solution, but this affected all pixels in the image, rather than just the problem areas. A new solution was needed which preserved colors within a \u201czone of trust\u201d, only altering the most saturated values.","title":"Introduction"},{"location":"specifications/rgc/#specification","text":"ACEScg values within the AP1 gamut are positive. Values outside of the AP1 gamut are negative in one or two of their components. The gamut compression algorithm runs per-pixel. ACES RGB values shall be converted to gamut compressed ACES RGB values using the following steps.","title":"Specification"},{"location":"specifications/rgc/#step-1-convert-aces-2065-1-rgb-to-acescg-rgb","text":"ACES 2065-1 RGB values shall be converted to ACEScg RGB values using the transformation matrix ( \\(TRA_1\\) ) calculated and applied using the methods provided in Section 4 of SMPTE RP 177:1993. Note Equation 1 shows the relationship between ACES R, G, and B values and ACEScg RGB values. NPM, rounded to 10 decimal places, is derived using the color space chromaticity coordinates specified in SMPTE S 2065-1, Academy Specification S-2014-004, and the methods provided in Section 3.3 of SMPTE RP 177:1993. \\[ \\begin{bmatrix}R_{ACEScg}\\\\G_{ACEScg}\\\\B_{ACEScg}\\end{bmatrix}=TRA_1\\cdot \\begin{bmatrix}R_{ACES}\\\\G_{ACES}\\\\B_{ACES}\\end{bmatrix} \\] \\[ TRA_1=\\begin{bmatrix}\\phantom{-}1.4514393161 & -0.2365107469 & -0.2149285693 \\\\-0.0765537734 & \\phantom{-}1.1762296998 & -0.0996759264\\\\\\phantom{-}0.0083161484 & -0.0060324498 & \\phantom{-}0.9977163014 \\\\\\end{bmatrix} \\] \\[ TRA_1 = {NPM_{AP1}}^{-1}\\cdot NPM_{AP0} \\] Equation 1","title":"Step 1 \u2013 Convert ACES 2065-1 RGB to ACEScg RGB"},{"location":"specifications/rgc/#step-2-calculate-a","text":"Calculate \\(A\\) using Equation 2. \\[ A = \\text{MAX}(R_{ACEScg}, G_{ACEScg}, B_{ACEScg}) \\] where: \\(\\textrm{MAX()}\\) returns the maximum of the arguments Equation 2 Note A is used as representative of the achromatic value of the pixel.","title":"Step 2 \u2013 Calculate A"},{"location":"specifications/rgc/#step-3-calculate-dn","text":"Calculate \\(d_n\\) using Equation 3. \\[ d_n = \\begin{cases}\\frac{A - RGB_{ACEScg}}{\\text{ABS} \\left ( A \\right )},& \\text{if } A\\neq0\\\\0,& \\text{otherwise}\\end{cases} \\] where : \\(\\textrm{ABS()}\\) returns the absolute value of the argument Equation 3 Note \\(d_n\\) represents the normalized distances of the channels from the achromatic, or \u201cinverse RGB ratios\u201d.","title":"Step 3 \u2013 Calculate dn"},{"location":"specifications/rgc/#step-4-calculate-dc","text":"Compress \\(d_n\\) to produce \\(d_c\\) using Equation 4. \\[ d_c = \\begin{cases}d_n,& \\text{if }d_n < t\\\\t + \\frac{d_n-t}{\\left ( 1+d_p \\right ) ^{\\frac{1}{p}}}\\end{cases} \\] where : \\[ l = \\begin{bmatrix}1.147 \\\\ 1.264 \\\\ 1.312\\end{bmatrix}\\ t = \\begin{bmatrix}0.815 \\\\ 0.803 \\\\ 0.880\\end{bmatrix}\\ p = 1.2 \\] \\[ s = \\frac{l - t}{\\left (\\left (\\frac{1 - t}{l - t} \\right )^{-p} - 1\\right )^\\frac{1}{p}} \\] \\[ d_p = \\left ( \\frac{d_n - t}{s} \\right )^{p} \\] Equation 4 Note The compression function compresses values at limit ( \\(l\\) ) to 1.0. This results in values beyond this limit remaining outside AP1 after compression. A function which compressed all values to within AP1 would require a significant proportion of the space between threshold ( \\(t\\) ) and 1.0 to be reserved for values which are highly unlikely to occur, thus compressing other values more than necessary. Limit ( \\(l\\) ) values have been chosen so that the encoding gamuts of all digital cinema cameras with official ACES IDTs (ARRI, RED, Canon, Sony, Panasonic) will compress to within AP1. Threshold ( \\(t\\) ) values have been derived from the boundary of the ACEScg values for the ColorChecker Classic 24 (as specified in ISO 17321-1). The exponent ( \\(p\\) ) has been set to an average value, chosen following user testing, since there is no objective measure of the correctness of this value.","title":"Step 4 \u2013 Calculate dc"},{"location":"specifications/rgc/#step-5-calculate-rgbc","text":"Calculate \\(RGB_c\\) using Equation 5. \\[ RGB_c = A - d_c \\times \\text{ABS}\\left ( A \\right ) \\] where : \\(\\textrm{ABS()}\\) returns the absolute value of the argument Equation 5","title":"Step 5 \u2013 Calculate RGBc"},{"location":"specifications/rgc/#step-6-convert-rgbc-to-aces2065-1-rgb","text":"Gamut compressed ACEScg RGB values ( \\(RGB_c\\) ) shall be converted to ACES2065-1 RGB values using the transformation matrix ( \\(TRA_2\\) ) calculated and applied using the methods provided in Section 4 of SMPTE RP 177:1993. Note Equation 6 shows the relationship between ACEScg R, G, and B values and ACES2065-1 RGB values. NPM, rounded to 10 decimal places, is derived using the color space chromaticity coordinates specified in SMPTE S 2065-1, Academy Specification S-2014-004, and the methods provided in Section 3.3 of SMPTE RP 177. \\[ \\begin{bmatrix}R_{ACES}\\\\G_{ACES}\\\\B_{ACES}\\end{bmatrix}=TRA_2\\cdot \\begin{bmatrix}R_c\\\\G_c\\\\B_c\\end{bmatrix} \\] \\[ TRA_2=\\begin{bmatrix} \\phantom{-}0.6954522414 & \\phantom{-}0.1406786965 & \\phantom{-}0.1638690622 \\\\ \\phantom{-}0.0447945634 & \\phantom{-}0.8596711185 & \\phantom{-}0.0955343182 \\\\ -0.0055258826 & \\phantom{-}0.0040252103 & \\phantom{-}1.0015006723 \\\\\\end{bmatrix} \\] \\[ TRA_2 = {NPM_{AP0}}^{-1} \\cdot NPM_{AP1} \\] Equation 6","title":"Step 6 \u2013 Convert RGBc to ACES2065-1 RGB"},{"location":"specifications/rgc/#gamut-decompression","text":"While the Reference Gamut Compression has a closed form inverse, its use is not normally recommended. Gamut compressed ACES RGB values may be converted back to the original ACES RGB values using the same steps as for compression above, but using Equation 4b in place of Equation 4. \\[ d_c = \\begin{cases}t + s \\times \\left ( \\frac{d_p}{1-d_p} \\right ) ^{\\frac{1}{p}},& \\text{if }t \\leq d_n \\leq t + s\\\\d_n,& \\text{otherwise}\\end{cases} \\] Equation 4b Note \\(l\\) , \\(t\\) , \\(p\\) , \\(s\\) and \\(d_p\\) are as defined in Equation 4.","title":"Gamut Decompression"},{"location":"specifications/rgc/#tracking","text":"The Reference Gamut Compression is defined as a Look Transform ( LMT ) in CTL and has the following ACES Transform ID: <ACEStransformID>urn:ampas:aces:transformId:v1.5:LMT.Academy.GamutCompress.a1.3.0</ACEStransformID> This is trackable via a lookTransform element in an AMF file. If the RCG is used in the viewing pipeline, the lookTransform will be listed in the associated AMF . If the AMF is accompanying rendered media, the applied flag should be used to track whether or not the RGC has been \u201cbaked in\u201d. If using the RGC in a viewing pipeline, this lookTransform should appear directly after the IDT , first in the list of any LMTs, to make sure other operations benefit from the gamut compression. The Transform ID should be included in any exported AMFs, with the applied flag set as appropriate, and the description set to the ACESuserName to enable proper tracking. Currently, only the Reference (i.e. static) Gamut Compression is trackable via AMF .","title":"Tracking"},{"location":"specifications/rgc/#appendix-a-history-research","text":"The Architecture Virtual Working Group, chaired by Carol Payne (Netflix) and Matthias Scharfenberg (ILM), to investigate gamut mapping in ACES began its work in January 2020, with a proposal outlining the main issue as: Users of ACES are experiencing problems with out of gamut colors and the resulting artifacts (loss of texture, intensification of color fringes). This issue occurs at two stages in the pipeline. Conversion from camera raw RGB or from the manufacturer\u2019s encoding space into ACES AP0 Conversion from ACES AP0 into the working color space ACES AP1 It was acknowledged early on in the group that this artifacting can also occur in VFX /Color grading, as well as the Output Transform stages in the pipeline. The working group chairs set the scope: Propose transforms between color spaces that avoid or reduce color clipping. Solutions for this may include: Proposing a suitable color encoding space for digital motion-picture cameras. Proposing a suitable working color space. Propose a suitable gamut mapping/compression algorithm that performs well with wide gamut, high dynamic range, scene referred content that is robust and invertible. The group started out investigating the working and encoding spaces ( ACES 2065-1 and ACEScg). However, it was agreed early on that although the possibility of creating a new ACES working space which mitigates common gamut issues should not be discounted, it would require a very strong case as to the benefits. Changing a core component of ACES would potentially introduce backwards compatibility issues, and would also be based only on the situation at the current time. It raised the possibility of having to change the working space repeatedly in future. Thus, the focus moved on to the third option - a suitable algorithm to solve the artifacting while maintaining as much of the current ACES standards and structure as possible. The gamut mapping approach chosen is one of compression. It deals with the ACES image data \u201cas is\u201d, and simply strives to convert that into less problematic image data. Based on the history above, the general working assumptions were: Samples are relative scene exposure values (i.e. scene-referred linear data) with no assumed min/max value range boundaries The gamut mapping operator is per-pixel only (i.e. not spatial or temporal) The stated ideals for a gamut compression algorithm were: Exposure invariance \u2014 \\(f(a \\cdot RGB) = a \\cdot f(RGB)\\) Source gamut agnosticism Monotonicity Simplicity \u2013 suited to a fast shader implementation Invertibility (see caveats in Appendix II) Colors in a \u201czone of trust\u201d will be left unaltered While a suitable algorithm should be able to map arbitrary gamut A into arbitrary gamut B, it should not be a requirement that all source data must be contained within gamut A. Nor is it necessarily a requirement that the output should be entirely bounded by gamut B. Indeed, allowing extreme source values to be mapped to output values close to, but not within, the target gamut means that the compression function does not need to tend to the horizontal at the boundary. This means that its inverse will not tend to the vertical, which is beneficial for invertibility. Because the unreal colors which occur are a result of the mismatch between a camera and human observer (among other causes) and are outliers in the residual error of a transform optimized for a subset of important \u201cmemory\u201d colors, what they \u201cshould\u201d look like is somewhat undefined. The important thing is to remap them into values which are plausible rather than \u201caccurate\u201d. What was determined to be outside the scope: Colorimetric accuracy or spectral plausibility of input device transforms (IDTs) Display gamut mapping. (Required modifications to the RRT / ODT will need to be addressed by a subsequent group.) Customizing for specific input/output gamuts Working in bounded or volume-based gamuts Actions which could limit creative choices further down the line (e.g. excessive desaturation)","title":"Appendix A - History / Research"},{"location":"specifications/rgc/#user-testing","text":"Once the working group settled on the baseline algorithm and its properties a set of targeted, small scale user tests were conducted to ensure the foundations of the work were solid. The testing was composed of two groups - VFX compositors and colorists. Between these two disciplines every major use case for the gamut compression algorithm could be tested and measured. The group gathered an open repository of test images that clearly exhibited the problem to be solved. It then derived a set of test scenarios for each group ranging from keying, blur, grain matching, hue adjustment, and more. The tests were conducted in Nuke and Resolve, on both SDR and HDR monitors. User Testing Footage Examples Overall, the results of the user testing were positive and uncovered no major issues in the algorithm functionality. 75% of compositors and 96% of colorists stated that using the algorithm helped them complete their work and achieve their creative goals. For full user testing results, please refer to the working group historical repository .","title":"User Testing"},{"location":"specifications/rgc/#appendix-b-implementation-considerations","text":"","title":"Appendix B  \u2013 Implementation Considerations"},{"location":"specifications/rgc/#invertibility","text":"Invertibility of the transformation is an aspect that was discussed at length. The consensus was that while an inverse transform should be defined it comes with the caveat that gamut expansion can create undesirable results when used with highly saturated pixel values, such as those added as part of graphics or CG rendered imagery As this operation is considered more of a \u201cpixel healing\u201d technical operation, inversion should not be a required part of the workflow. It is more akin to a despill after pulling a key, or a bit of sharpening on a scale operation.","title":"Invertibility"},{"location":"specifications/rgc/#3d-lut-approximation","text":"If there is an unavoidable requirement to implement the Reference Gamut Compression on legacy systems using a 3D lookup table ( LUT ) special consideration must be given to the shaper function. Common functions for implementing ACES transforms as 3D LUTs are the Log2 shaper or ACEScct. However neither of those are designed to cover the negative value range required to map the negative components of out of gamut colors into a normalized 0 to 1 domain. For a successful 3D LUT implementation the normalizing shaper function must also cover a significant range of negative values. Due to the residual error a 3D LUT approximation of the transform should be considered to be non-invertible. Systems used as part of the finishing pipeline should use a mathematical implementation of the RGC , rather than a LUT . But for preview purposes, a well constructed LUT may be acceptable, particularly if it is a concatenation of all the required transforms, such as an on-set preview LUT transforming camera log to Rec.709.","title":"3D LUT Approximation"},{"location":"specifications/rgc/#parametric-version","text":"Some implementations may also choose to offer a parametric variation of the RGC . This is not officially endorsed as part of ACES , and should be treated simply as another grading operator. It should not be used as a replacement for the RGC since its parameters cannot be tracked by AMF and must instead be stored in the project files of the implementing application. Suggested parameter names, and default values for a parametric version are given in Section 9 of the RGC Implementation guide .","title":"Parametric Version"},{"location":"specifications/rgc/#appendix-c-illustrations","text":"Distance Limit (CIExy Chromaticity Plot) Compression Threshold and ColorChecker 24 Patches (CIExy Chromaticity Plot) Before Gamut Compression (ACES Rec. 709 Output Transform) Gamut Compression Note that the red value has also been moved slightly, because although it was not negative, its normalized distance was close to 1.0, and beyond the protected threshold for that channel (0.815). After Gamut Compression (ACES Rec. 709 Output Transform) Gamut Compression Polar Chromaticity Grid","title":"Appendix C: Illustrations"},{"location":"specifications/rgc/#appendix-d-ctl-reference-implementation","text":"// <ACEStransformID>urn:ampas:aces:transformId:v1.5:LMT.Academy.ReferenceGamutCompress.a1.v1.0</ACEStransformID> // <ACESuserName>ACES 1.3 Look - Reference Gamut Compress</ACESuserName> // // Gamut compression algorithm to bring out-of-gamut scene-referred values into AP1 // // // Usage: // This transform is intended to be applied to AP0 data, immediately after the IDT, so // that all grading or compositing operations are downstream of the compression, and // therefore work only with positive AP1 values. // // Note: // It is not recommended to bake the compression into VFX pulls, as it may be beneficial // for compositors to have access to the unmodified image data. // // // Input and output: ACES2065-1 // import \"ACESlib.Transform_Common\"; /* --- Gamut Compress Parameters --- */ // Distance from achromatic which will be compressed to the gamut boundary // Values calculated to encompass the encoding gamuts of common digital cinema cameras const float LIM_CYAN = 1.147; const float LIM_MAGENTA = 1.264; const float LIM_YELLOW = 1.312; // Percentage of the core gamut to protect // Values calculated to protect all the colors of the ColorChecker Classic 24 as given by // ISO 17321-1 and Ohta (1997) const float THR_CYAN = 0.815; const float THR_MAGENTA = 0.803; const float THR_YELLOW = 0.880; // Aggressiveness of the compression curve const float PWR = 1.2; // Calculate compressed distance float compress(float dist, float lim, float thr, float pwr) { float comprDist; float scl; float nd; float p; if (dist < thr) { comprDist = dist; // No compression below threshold } else { // Calculate scale factor for y = 1 intersect scl = (lim - thr) / pow(pow((1.0 - thr) / (lim - thr), -pwr) - 1.0, 1.0 / pwr); // Normalize distance outside threshold by scale factor nd = (dist - thr) / scl; p = pow(nd, pwr); comprDist = thr + scl * nd / (pow(1.0 + p, 1.0 / pwr)); // Compress } return comprDist; } void main ( input varying float rIn, input varying float gIn, input varying float bIn, input varying float aIn, output varying float rOut, output varying float gOut, output varying float bOut, output varying float aOut ) { // Source values float ACES[3] = {rIn, gIn, bIn}; // Convert to ACEScg float linAP1[3] = mult_f3_f44(ACES, AP0_2_AP1_MAT); // Achromatic axis float ach = max_f3(linAP1); // Distance from the achromatic axis for each color component aka inverse RGB ratios float dist[3]; if (ach == 0.0) { dist[0] = 0.0; dist[1] = 0.0; dist[2] = 0.0; } else { dist[0] = (ach - linAP1[0]) / fabs(ach); dist[1] = (ach - linAP1[1]) / fabs(ach); dist[2] = (ach - linAP1[2]) / fabs(ach); } // Compress distance with parameterized shaper function float comprDist[3] = { compress(dist[0], LIM_CYAN, THR_CYAN, PWR), compress(dist[1], LIM_MAGENTA, THR_MAGENTA, PWR), compress(dist[2], LIM_YELLOW, THR_YELLOW, PWR) }; // Recalculate RGB from compressed distance and achromatic float comprLinAP1[3] = { ach - comprDist[0] * fabs(ach), ach - comprDist[1] * fabs(ach), ach - comprDist[2] * fabs(ach) }; // Convert back to ACES2065-1 ACES = mult_f3_f44(comprLinAP1, AP1_2_AP0_MAT); // Write output rOut = ACES[0]; gOut = ACES[1]; bOut = ACES[2]; aOut = aIn; } @import \"../../stylesheets/sections.css\"","title":"Appendix D: CTL Reference Implementation"}]}