{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"glossary/","text":"Terms and Definitions \u00b6 A \u00b6 Academy Color Encoding Specification ( ACES ) RGB color encoding for exchange of image data that have not been color rendered, between and throughout production and postproduction, within the Academy Color Encoding System. ACES is specified in SMPTE ST 2065-1. ACES RGB relative exposure values Relative responses to light of the ACES Reference Image Capture Device, determined by the integrated spectral responsivities of its color channels and the spectral radiances of scene stimuli. ACES unity neutral A triplet of ACES RGB relative exposure values all of which have unity magnitude. ACES Metadata File ( AMF ) Metadata \u201csidecar\u201d XML -based file that contains information describing a collection of image files color-managed using the Academy Color Encoding System ( ACES ). ACES Encodings Color encoding specifications specified as part of the Academy Color Encoding System, e.g., ACES2065-1, ACEScc, etc. ACES File Formats Digital data containers specified as part of the Academy Color Encoding System, e.g., ACES Metadata Files, ACES Image Container ( SMPTE ST2065-4), etc. ACES Product Partners Companies that integrate ACES concepts and components into their products and/or services. ACES System Complete set of components that comprise the Academy Color Encoding System. ACES System Release Published ACES System. ACES Transforms Color transformations specified as part of the Academy Color Encoding System, e.g., Reference Rendering Transform ( RRT ), Output Device Transforms ( ODT ), etc. ACES Viewing Transform Combined RRT and ACES Output Device Transform. B \u00b6 C \u00b6 chromatic adaptation process by which the visual mechanism adjusts in response to the radiant energy to which the eyes are exposed. chromaticity property of a color stimulus defined by the ratios of each tristimulus value of the color stimulus to their sum. Color Transform Langage ( CTL ) small open-source programming language, consisting of an interpreter and one or more CLT modules, that has been designed to serve as a building block for digital color management systems. CTL modules (files) files containing Color Transformation Language code. Note: CTL files are the primary documentation for ACES transforms. D \u00b6 DateTime (reference: ISO 8601:2004 ) timestamp format The DateTime is specified in the following form YYYY-MM-DDThh:mm:ss{offset} where: YYYY indicates the year MM indicates the month DD indicates the day T indicates the start of the required time section hh indicates the hour mm indicates the minute ss indicates the second {offset} time zone offset from UTC Note All components are required. Example 2014-11-20T12:24:13-8:00 E \u00b6 Edit Decision List ( EDL ) list used in the post-production process of film editing and video editing containing an ordered sequence of reel and timecode data representing where each video clip can be obtained in order to conform to the final cut. Extensible Markup Language ( XML ) a markup language and file format for storing, transmitting, and reconstructing arbitrary data. It defines a set of rules for encoding documents in a format that is both human-readable and machine-readable F \u00b6 G \u00b6 H \u00b6 I \u00b6 Implementation Transforms ACES System transforms implemented by ACES Product Partners, likely as a Color Look-up Table or as GPU or CPU code. Internet Engineering Task Force ( IETF ) an open standards organization, which develops and promotes voluntary Internet standards, in particular the technical standards that comprise the Internet protocol suite (TCP/IP). J \u00b6 K \u00b6 L \u00b6 Look Transform ( LMT ) Look Modification Transform ( deprecated term ) ACES transform which applies a global look or other modification to scene-referred image data. M \u00b6 N \u00b6 O \u00b6 P \u00b6 Q \u00b6 R \u00b6 Reference Gamut Compression ( RGC ) ACES LMT which compresses scene-referred image data to within the AP1 gamut. Reference Rendering Transform ( RRT ) Core ACES transform that converts scene-referred image data that conforms to SMPTE ST 2065-1:2012 to output-referred image data. RFN technical specification or organizational note published by the Internet Engineering Task Force ( IETF ) S \u00b6 T \u00b6 TransformIDs Transform Identifiers string identifying the ACES transform. Note Please see the ACES System Versioning Specification for more information on the format to use for TransformIDs. U \u00b6 Universal(ly) Unique Identifier ( UUID ) 128-bit label used for information in computer systems published in various standards including ISO /IEC 11578:1996 \"Information technology \u2013 Open Systems Interconnection \u2013 Remote Procedure Call (RPC)\" V \u00b6 W \u00b6 X \u00b6 Y \u00b6 Z \u00b6","title":"Glossary"},{"location":"glossary/#terms-and-definitions","text":"","title":"Terms and Definitions"},{"location":"glossary/#a","text":"Academy Color Encoding Specification ( ACES ) RGB color encoding for exchange of image data that have not been color rendered, between and throughout production and postproduction, within the Academy Color Encoding System. ACES is specified in SMPTE ST 2065-1. ACES RGB relative exposure values Relative responses to light of the ACES Reference Image Capture Device, determined by the integrated spectral responsivities of its color channels and the spectral radiances of scene stimuli. ACES unity neutral A triplet of ACES RGB relative exposure values all of which have unity magnitude. ACES Metadata File ( AMF ) Metadata \u201csidecar\u201d XML -based file that contains information describing a collection of image files color-managed using the Academy Color Encoding System ( ACES ). ACES Encodings Color encoding specifications specified as part of the Academy Color Encoding System, e.g., ACES2065-1, ACEScc, etc. ACES File Formats Digital data containers specified as part of the Academy Color Encoding System, e.g., ACES Metadata Files, ACES Image Container ( SMPTE ST2065-4), etc. ACES Product Partners Companies that integrate ACES concepts and components into their products and/or services. ACES System Complete set of components that comprise the Academy Color Encoding System. ACES System Release Published ACES System. ACES Transforms Color transformations specified as part of the Academy Color Encoding System, e.g., Reference Rendering Transform ( RRT ), Output Device Transforms ( ODT ), etc. ACES Viewing Transform Combined RRT and ACES Output Device Transform.","title":"A"},{"location":"glossary/#b","text":"","title":"B"},{"location":"glossary/#c","text":"chromatic adaptation process by which the visual mechanism adjusts in response to the radiant energy to which the eyes are exposed. chromaticity property of a color stimulus defined by the ratios of each tristimulus value of the color stimulus to their sum. Color Transform Langage ( CTL ) small open-source programming language, consisting of an interpreter and one or more CLT modules, that has been designed to serve as a building block for digital color management systems. CTL modules (files) files containing Color Transformation Language code. Note: CTL files are the primary documentation for ACES transforms.","title":"C"},{"location":"glossary/#d","text":"DateTime (reference: ISO 8601:2004 ) timestamp format The DateTime is specified in the following form YYYY-MM-DDThh:mm:ss{offset} where: YYYY indicates the year MM indicates the month DD indicates the day T indicates the start of the required time section hh indicates the hour mm indicates the minute ss indicates the second {offset} time zone offset from UTC Note All components are required. Example 2014-11-20T12:24:13-8:00","title":"D"},{"location":"glossary/#e","text":"Edit Decision List ( EDL ) list used in the post-production process of film editing and video editing containing an ordered sequence of reel and timecode data representing where each video clip can be obtained in order to conform to the final cut. Extensible Markup Language ( XML ) a markup language and file format for storing, transmitting, and reconstructing arbitrary data. It defines a set of rules for encoding documents in a format that is both human-readable and machine-readable","title":"E"},{"location":"glossary/#f","text":"","title":"F"},{"location":"glossary/#g","text":"","title":"G"},{"location":"glossary/#h","text":"","title":"H"},{"location":"glossary/#i","text":"Implementation Transforms ACES System transforms implemented by ACES Product Partners, likely as a Color Look-up Table or as GPU or CPU code. Internet Engineering Task Force ( IETF ) an open standards organization, which develops and promotes voluntary Internet standards, in particular the technical standards that comprise the Internet protocol suite (TCP/IP).","title":"I"},{"location":"glossary/#j","text":"","title":"J"},{"location":"glossary/#k","text":"","title":"K"},{"location":"glossary/#l","text":"Look Transform ( LMT ) Look Modification Transform ( deprecated term ) ACES transform which applies a global look or other modification to scene-referred image data.","title":"L"},{"location":"glossary/#m","text":"","title":"M"},{"location":"glossary/#n","text":"","title":"N"},{"location":"glossary/#o","text":"","title":"O"},{"location":"glossary/#p","text":"","title":"P"},{"location":"glossary/#q","text":"","title":"Q"},{"location":"glossary/#r","text":"Reference Gamut Compression ( RGC ) ACES LMT which compresses scene-referred image data to within the AP1 gamut. Reference Rendering Transform ( RRT ) Core ACES transform that converts scene-referred image data that conforms to SMPTE ST 2065-1:2012 to output-referred image data. RFN technical specification or organizational note published by the Internet Engineering Task Force ( IETF )","title":"R"},{"location":"glossary/#s","text":"","title":"S"},{"location":"glossary/#t","text":"TransformIDs Transform Identifiers string identifying the ACES transform. Note Please see the ACES System Versioning Specification for more information on the format to use for TransformIDs.","title":"T"},{"location":"glossary/#u","text":"Universal(ly) Unique Identifier ( UUID ) 128-bit label used for information in computer systems published in various standards including ISO /IEC 11578:1996 \"Information technology \u2013 Open Systems Interconnection \u2013 Remote Procedure Call (RPC)\"","title":"U"},{"location":"glossary/#v","text":"","title":"V"},{"location":"glossary/#w","text":"","title":"W"},{"location":"glossary/#x","text":"","title":"X"},{"location":"glossary/#y","text":"","title":"Y"},{"location":"glossary/#z","text":"","title":"Z"},{"location":"guides/amf/","text":"ACES Metadata File Implementation Guidelines and Best Practices \u00b6 Scope \u00b6 This document is a guide that recommends implementation guidelines and best practices related to the usage of the ACES Metadata File ( AMF ) in various workflows. These workflows may involve one or more tools that support the AMF specification and this guide attempts to help both implementers and users in order to facilitate interoperability. References \u00b6 The following standards, specifications, articles, presentations, and texts are referenced in this text: Academy S-2019-001, ACES Metadata File ( AMF ) IETF RFC 4122, A Universally Unique IDentifier ( UUID ) URN Namespace Introduction \u00b6 The Academy Color Encoding System ( ACES ) is a color processing framework that enables the mix of various sources within a standardized color space in order to produce one or more outputs. While ACES is a living framework and is actively developed and adopted, it also comes with various points that can be configured. These points of configuration are either related to the sources used (Input Transforms), a creative look (Look Transforms), the desired outputs (Output Transforms), or the Version Number (i.e. ACES v1.1) of the core transforms built into the ACES system. ACES does not specify these configuration points directly or associate them with actual images or shots during production, and this is the very reason why AMF exists. AMF is the configuration file that allows a precise setup for an ACES pipeline. Besides this basic goal, AMF is also the tool of choice to transmit and exchange configuration parameters in order to ensure consistency within a workflow and across the entire ecosystem of tools that are used within that workflow. Target Audience \u00b6 AMF is a sidecar file specified using the XML markup language, and as such it can be processed by machines and at the same time created/modified by users. This document targets both AMF users and AMF implementers because both groups need the same level of understanding in order to design AMF -enabled workflows and tools that support those workflows. What is AMF \u00b6 AMF is an XML specification that describes the configuration of an ACES color pipeline, together with the various input transforms, look transforms and output transforms. AMF is a \"sidecar\" element, usually accompanying some visual material such as a video file, a sequence of frames, or a whole timeline. In the case of a timeline, more than one AMF file can be used if the timeline requires different configurations of the ACES pipeline. It is also worth mentioning that several AMF files can reference the same visual material. The opposite is equally true as all these visual elements can share a single AMF file or a whole set of them. This of course is entirely dependent on the workflow, and tools implementing AMF should be prepared to deal with this flexibility. In general, the relationship between the visual elements and the AMF files can be described as a \"many to many\" relationship. Why is AMF needed \u00b6 The ACES framework is expanding and becoming richer in terms of input, look, and output transforms. AMF describes the exact list of these different transforms, in the order in which they have been or should be applied to obtain the desired result. graph LR A1[Input Media] --> B(Input Transform) subgraph AMF Complete Processing Path Description B --> C1(Look Transform) C1 --> D1(Output Transform) end A2[ACES Material] ---> C2(Look Transform) subgraph AMF Partial Processing Path Description C2 --> D2(Output Transform) end AMF Processing Path Description This is a powerful feature because it can describe both configurations that must be used to create a specific output, or configurations that have been used to create a specific output. graph TB B1 --> A1(AMF <br/>Look Modification Transform <br/> Chain) B2 --> A1 B3 --> A1 subgraph B1(\"ASC-CDL<br/>or<br/>External LMT<br/>(active)\") B2(\"ASC-CDL<br/>or<br/>External LMT<br/>(disabled)\") B3(\"ASC-CDL<br/>or<br/>External LMT<br/>(active)\") end classDef disabled opacity: 0.5 class B2 disabled Each block in the chain can be an ASC-CDL or an external LUT. Blocks can be enabled or disabled Finally, another feature of AMF is the ability to document a \"change log\" in an ACES color pipeline. This is called the \"archived pipeline\" and will be discussed later in the document. The \u201capplied\u201d attribute \u00b6 Each transform in an AMF can be tagged with the attribute called applied - which indicates whether a transform has already been applied ( applied=true ), in which case the transform has already been baked into the image, or if the transform has not been applied ( applied=false ), in which case the transform should be loaded as part of the viewing pipeline. One use case of this might be when using the ACES Gamut Compression transform, which may be baked into SMPTE ST 2065-1 ACES image data, and it is essential to communicate to downstream software that it has already been applied, as to not double-apply the transform, or invert it if necessary. Lifecycle of AMF \u00b6 This section describes the life cycle of an AMF and how it could be used within each production stage. Camera \u00b6 While on set, AMF could be imported in-camera and used to apply color pipeline settings for video and file output, or exported to a camera card when using a camera\u2019s ACES viewing pipeline. See section 7 for more on cameras reading/writing AMF . Monitor \u00b6 Some professional monitors allow import of LUTs to apply looks in-device. AMF could replace proprietary or uncommon LUT formats for improved interoperability. On-set live grading \u00b6 An AMF may be read by on-set live grading software for the purpose of on-set monitoring and color grading within ACES . If anything is altered within the domain of the pipeline defined in the AMF , a new AMF is created to reflect those modifications. For example, an ACES pipeline is established in an AMF before production, then CDL adjustments are created during production to create an updated AMF accordingly. Dailies \u00b6 In a dailies tool, a pre-created AMF could be read and associated with OCF (Original Camera Files) to apply pipeline settings (for viewing and rendering). This could be done either by manual association or automatically. In the process of creating the dailies, the color pipeline coming from an existing AMF may be modified and updated. AMFs are written out with media to be passed to editorial software. Commonly used interchange files (e.g. EDL or ALE ) can be used to conform AMF files with OCF , see below for more details. Editorial \u00b6 Editorial software can apply pipeline settings provided by AMF (s) when importing media to automatically set up viewing and rendering. VFX \u00b6 Read AMF (s) when importing plates into VFX software and apply pipeline settings for viewing. Given the prevalence of OpenColorIO across VFX software, it is likely that a translation from AMF to OpenColorIO ( OCIO ) would be required. Color Grading \u00b6 When in color grading, AMF could be conformed to a timeline and associated with OCF to apply pipeline settings (for viewing and rendering). These applications should also allow for look development in ACES and subsequent exporting of AMF . Review \u00b6 Review software could automatically apply ACES pipeline settings for viewing purposes by reading AMF (s) when importing media or by manually applying AMF (s) to imported media. Mastering and Archiving \u00b6 Read AMF (s) when importing media and apply pipeline settings for viewing. Consolidate AMF (s) to meet specific archival delivery requirements. Considerations on reading/writing AMF \u00b6 This section outlines various scenarios related to the reading and writing of AMF files. Scenario Read - An AMF is read when importing media and used to populate a color pipeline for viewing and rendering. Write - A new AMF is written in order to be passed along to the next production stage. If a new AMF is done from a previous AMF , the previous pipeline might be archived in the section. RAW Clips AMF does not include any metadata for demosaic settings. Implementations need to ensure that the image is demosaicked to the appropriate color space before the Input Transform defined in the AMF is applied. User input may be required. If software chooses to directly demosaic a RAW image to ACES , the Input Transform defined in the AMF must be ignored. n/a Input Transform Conflict A clip has already been loaded into the software, and an Input Transform is already applied. Default behaviour should be to override that Input Transform with what\u2019s specified in the AMF , but the user should be prompted. n/a Output Transform Conflict If the AMF specifies an Output Transform that is in conflict with the respective shot\u2019s Output Transform, then this conflict must be handled. The default behaviour should be to stick with the project-wide Output Transform, but it may be useful to indicate a conflict to the user. Example: An AMF is generated from a software platform that uses the Rec709_100nits transform, and is then read by a software platform that is using an HDR Output Transform. The Output Transform that was indeed used for viewing should be specified in the AMF . Manual AMF Batch Import/Export Consider the use of commonly used interchange files (e.g. EDL or ALE ) to batch import AMF \u2019s to a timeline. Ideally, the software would allow for a partial import of only the Input, Look, or Output Transforms of a given AMF . When exporting a batch of AMF \u2019s for an entire timeline, consider exporting commonly used interchange files (e.g. EDL or ALE ) to create an association between Clips and the exported AMF files. Inter- AMF Output Transform Conflict If AMF \u2019s are batch imported into a single timeline, and at least two of them have different Output Transforms defined, consider prompting the user if this inconsistency exists, and provide appropriate options to address. This has the assumption that the user will only be using one Output Transform at a time for an entire timeline. n/a Pipeline Override If an AMF has already been applied to a shot, or if project/timeline settings apply, and a subsequent AMF is read for that shot, consider prompting the user before overriding pipeline. Ideally, the software would allow for a partial import of only the Input, Look, or Output Transforms of a given AMF . Consider including multiple AMF transform pipelines by making use of AMF \u2019s aces:archivedPipeline element. Updating Look Transforms n/a Local changes to transforms in the AMF should not affect any other transforms if the pipeline structure doesn\u2019t change, e.g. when only updating CDL values, but none of the other transforms change, the AMF structure should not be changed and only the CDL values should be updated. Any changes to the transform pipeline will result in a new AMF and global values, e.g. the dateTime element, are therefore expected to change. If CLF (s) are used in the pipeline, consider using CLF UUID and/or its hash to make sure that the CLF has not changed. Look Transform Support If an AMF references a Look Transform with a format that the application does not support reading, consider notifying the user that the format is unsupported, so it is clear the error is unrelated to the AMF itself. When producing a new Look Transform for an AMF export, consider defaulting to CLF , a format that ensures high interoperability,, especially for any operations other than ASC CDL . It\u2019s important to consider what to do when using CDL operations vs other grading operations and how these should be reflected in the AMF document: in elaborated pipeline where CDL are \u201cin between\u201d other more sophisticated grading operations, it might be required to let the user identify and decide over what CDL operations should be treated as such and which ones can be baked with other operations into a consolidated CLF Cameras Import AMF in-camera and apply pipeline settings for video and file output. An AMF loaded in camera could specify over SDI how to treat the incoming signal (ie Output Transform) There are reasonable expectations that any in-camera processing, for the foreseeable future, will be done utilizing small 3D LUTs at the highest complexity. Therefore, applications of an ACES pipeline in-camera may be limited in precision. When should a camera generate an AMF ? If a camera generates an AMF , where should it be written? #1 Preferred Method: Embedded in the OCF , e.g.REDCODE RAW R3D #2 Preferred Method: AMF should live in the same directory as its associated clip #3 Preferred Method: * A single folder with all AMF files Metadata Population Parse the AMF for its filename and aces:uuid and write these to the appropriate metadata fields for each clip. If the AMF associated with a clip changes, the value relative to the AMF metadata fields within the editorial software should change and adopt the new values. So when writing commonly used interchange files (e.g. EDL or ALE ) the correspondent values are correct. Applied Tag When reading an AMF file that has the applied=true attribute for a specific transform, the software should NOT apply the transform to the file, since it has already been applied to the image itself. Consider reporting it to the user if applicable (e.g. a \u201chistory\u201d log of the transforms is accessible for each clip) When exporting AMF \u2019s from a timeline of clips that have not been rendered yet, each transform in the AMF should be tagged as applied=false . However, when rendering new files, consider having the ability to export new AMF \u2019s files simultaneously as part of the same deliverable and, in this case, each transform that is actually baked in should be tagged as applied=true in the AMF (e.g. the Input Transform if rendering OpenEXR ACES 2065-1 VFX pulls, or everything when exporting 709 proxies for editorial). Archived Pipelines Consider allowing the user to toggle between different ACES pipelines that are recorded in the aces:archivedPipeline element. Otherwise, aces:archivedPipeline elements should be preserved for any new AMF \u2019s subsequently created for the same shots. If the software is updating a pre-existing AMF , the written AMF should include the appropriate aces:archivedPipeline element. Structure of AMF \u00b6 AMF is a specification based on the XML markup language. It is fully described in Academy Specification S-2019-001 . The specification also comes with an XML Schema that can be used to validate the AMF documents. The XML Schema is publicly available here: https://github.com/ampas/aces-dev/tree/master/formats/amf The guidelines and best practices in this document are provided to help both implementers and users to take full advantage of AMF . It is strongly recommended to use the specification as a reference in order to better understand the concepts described here. AMF document sections \u00b6 AMF documents are mainly divided in 3 sections: aces:amfInfo - this section provides descriptive information about the AMF itself. aces:clipId - this section provides a reference to the visual material ( OCF or rendered images) that this AMF is applicable for. aces:pipeline - this section describes the ACES pipeline configuration. General descriptive information \u00b6 The aces:amfInfo element contains various sub-elements that provide descriptive information about the AMF document but also a mechanism to help identification. More specifically two sub-elements deserve some consideration: aces:dateTime aces:uuid The mandatory aces:dateTime element contains the creation and modification date. The aces:uuid element is optional and is designed to carry a Universally Unique Identifier (also known as Globally Unique Identifier, or GUID on some systems). The Universally Unique Identifier is specified in IETF RFC 4122 as well as other ISO and ITU documents. Both aces:dateTime and aces:uuid elements are not filled in by a human operator but rather automatically generated by the tool used to create the AMF document. AMF naming and identification \u00b6 In general, the most common method that everyone uses to distinguish between two files is by comparing file names and/or their creation and/or modification date in the file system. However, this method quickly reveals itself ineffective when files are exchanged between various computers and operating systems because these file properties can easily be changed without any sort of warning. As explained above, AMF files usually come in large numbers and are moved across various systems and processed by various tools during their life cycle. Because of this situation, a better approach is to make good use of the information contained in the document itself. However, to avoid common pitfalls like overwriting files, the following file naming convention is recommended: AMF files should conform to the following file naming convention: <description>_<date>_<time>.amf <description> should describe the following, if applicable: Purpose: the use case of the AMF file (eg. \u201cdailies\u201d, \u201cSDR_709\u201d, \u201c VFX -Pull\u201d) Clip: Clip ID as in the AMF specification Show Name: Title or other identifiers of the associated show Author: Author of the AMF <date> is the date of creation, using the format YYYY-MM-DD <time> is the time of creation, using the format HHMMSSZ (trailing \u201cZ\u201d indicating \u201cZulu\u201d time, see below) Values for <date> and <time> are determined at the start of the operation that results in the creation of the AMF file and the values are represented using the Coordinated Universal Time ( UTC ) standard. Example: Dailies_ShowName_A002R2EC_2019-01-07_080228Z.amf Using date and time mechanism \u00b6 As mentioned above, the aces:dateTime is a mandatory element and it is defined using the standard XML type xs:dateTime. Because this definition is very flexible, it is strongly recommended for the tools to always use the most explicit form that includes the year, month and day, the time of the day in hours, minutes and seconds as well as the time zone. This practice ensures that the creation and modification dates and times are giving a good indication on the location where the document was created/modified. Using the unique identifier mechanism \u00b6 A more elaborate identification mechanism can also be used, by taking advantage of the aces:uuid element. Since this element is optional, one cannot count on its presence, however it is strongly recommended to use it. When doing so, the UUID becomes a much safer tool to distinguish between to AMF documents. UUIDs are automatically generated and they shall never be hand-crafted. Combining several identification mechanisms \u00b6 In order to improve the identification mechanism, one can combine both the UUID checks and creation/modification times. This might be helpful if two AMF documents contain the same UUID but have different creation/modification dates. In practice, when using dedicated tools to create and manage AMF files, such situations should not occur, but AMF files can still be manually altered. If this is the case, further inspection of the AMF documents can help to distinguish them. Such advanced methods will be discussed later in the document. It is worth mentioning here that there are situations where two or more AMF documents can have the same unique identifier but have different creation dates and time. It is then recommended that tools encountering this situation switch to the most recent version of the AMF document based on the date and time. Informing the user and logging conflicts \u00b6 Because of the large number of AMF documents involved in a workflow, it might not be practical to inform the user of every error encountered. However these errors should be logged by the tools using AMF and options should be offered to select the various identification rules, e.g. unique identifier first (if available), then the creation date and time. Clip information and association \u00b6 As described in the previous sections, AMF can be used with different targets, i.e. single file video clips, image sequences, compositions, etc. This flexibility implies that the AMF specification does not prescribe a specific way to create the connection with the target material. Instead, the specification offers different connection mechanisms via the aces:clipId, an optional structure that in turn contains child elements to help with the handling of the various situations. The first important observation to make is that the aces:clipId element itself is defined as optional. In this context, optional does not mean that the presence or absence of the aces:clipId element does not affect the workflow and how tools that support AMF behave. The term optional must be understood as a switch between two categories of workflow: the first does not connect an AMF file to a specific visual material and the second does connect an AMF file to a specific visual material. Depending on the workflow in use, an implementation must handle the presence or absence correctly and report errors if necessary. Typically, the XML validation only will not be enough to distinguish between a valid AMF file and an invalid one, since the aces:clipId element is optional. In other words, the aces:clipId does not dictate how the AMF document is handled. It is the workflow that dictates the behavior. aces:clipId is not present \u00b6 The absence of the aces:clipId element is important when the connection between the AMF document and the visual material is handled by a higher level protocol. The simplest higher level protocol that comes immediately to mind is the use of the file system and some sort of naming convention. For instance, a folder can contain a video clip and the related AMF file like this: ./myVideoClip.mxf ./myVideoClip.amf In this simple situation, an implementation that can read the the myVideoClip file could also look for a secondary file named myVideoClip.amf and if it is present and if it is a valid AMF document consider that there is a \"connection\" between the two files and act accordingly. While this seems to be a natural thing to do, it is certainly something to avoid. First of all, this kind of \"connection\" would work in a limited number of situations and then it would also prevent more elaborated workflows from existing. Consider the following modified example: ./myVideoClip.mxf ./myVideoClip.mov ./myVideoClip.amf In this variant, it's impossible to guess if myVideoClip.amf is related to myVideoClip.mxf or to myVideoClip.mov or to both files. To solve this problem, the aces:clipId element must be used to establish the desired connection between the AMF document and the correct targeted visual material. A single AMF document can be \"shared\" by multiple video clips or image sequences or even compositions. While it's certainly possible to invent a solution based on the file system naming capabilities via a fixed folder/file structure and naming convention, it is not recommended. In practice, workflows that involve multiple visual material elements, and one or more AMF documents, shared or not, make use of a control file that acts like a database, describing the complex relationships that may exist. This handbook defines the use of AMF in conjunction with some popular commonly used interchange files: Avid Log Exchange ( ALE ) CMX3600 Edit Decision List ( EDL ) The AMF Implementation Group explored the use of AMF with higher level protocols as well and those will eventually be described in a future version of this handbook. A future version may also describe the use of AMF with OpenTimelineIO. aces:clipId is present \u00b6 As briefly described before, the aces:clipId is a complex element, containing the following sub-elements: aces:clipName and one of the following: aces:file aces:sequence aces:uuid All these sub-elements are mandatory when aces:clipId is used, but it's important to remember that aces:sequence, aces:file and aces:uuid cannot coexist. They are mutually excluding each other and therefore are used for specific variants in a workflow. aces:clipName \u00b6 The aces:clipName is used to carry the name of the target visual material element, but not the file name of that element. Typically aces:clipName is the same as the file name but without the file extension or the frame number digits in the case of a file sequence. aces:file \u00b6 The aces:file element is used to carry the actual file name of the target visual material element. It can carry the full absolute path and the file name, a relative path and the file name or simply the file name (base name and extension) of the target visual material element. As it is the case with file names in general, path information and special characters supported or not supported by various file systems must be taken into account. The goal here is not to describe all the possibilities, but rather to recommend some best practices: * If the path (absolute or relative) is used in the file name, it should be limited to cases when the AMF document is only used within a closed system where the rules can be clearly defined. * Special characters or Unicode names can be used, but in general they might be a source of problems. While not forbidden, their use should be tested in the context of the desired workflow to ensure that all the tools and operating systems involved correctly support the selected convention. A good practice however would be to stick with ASCII characters only and avoid using path-like structures in file names. aces:sequence \u00b6 The aces:sequence is similar to aces:file, however it is primarily designed to handle image sequences. Image sequences usually follow a file name pattern and the only difference between two files of the same sequence, is a number which indicates the file's position in the sequence. Moreover, the number is using a fixed number of digits where the unused digits are replaced with zeroes. aces:sequence requires three different attributes to fully define a sequence of files: idx : a special character that the filename pattern uses to represent digits (e.g.#) min : a number that represents the first file in the sequence max : a number that represents the last file in the sequence In other words, min and max define a range of frame numbers and they are both part of the sequence (included). aces:uuid \u00b6 The last method for connecting the AMF document to a visual material element is by using aces:uuid. In this particular case, the connection between the AMF document and the actual visual material element is clearly handled elsewhere and not at the file system level. Various workflows will be described later that make use of the aces:uuid instead of aces:file or aces:sequence. However it's important to note that using UUID is probably the safest method , especially when the workflow is distributed across multiple tools, operating systems and even geographic locations. ACES pipeline configuration \u00b6 The ACES pipeline section is a list of ordered elements that define various steps of the ACES color pipeline. The pipeline is described by the aces:pipeline element. In turn, this element contains a list of sub-elements that describe the configuration of the various color processing stages that exist in the ACES color processing framework. Below is the list of sub-elements that can be found in the aces:pipeline element: aces:pipelineInfo aces:inputTransform aces:lookTransform aces:outputTransform These elements must appear in this exact order. Although these steps are described separately, this does not imply that a system has to process all pixels in a frame of visual material one step at a time. Some systems might do it while some others might need to crunch the various processing steps into a single transform, typically a 3D Lookup Table (3D LUT ). Moreover a system may choose to optimize the processing of the various steps, depending on the given situation. The only constraint is that the color processing must follow the steps in the order described above. aces:pipelineInfo \u00b6 The aces:pipelineInfo element extends the set of properties found in the AMF document identification by adding an element to define the ACES system version. The role of this element is to specify the ACES system version targeted by this AMF file in order to produce the correct output. The system version is a crucial piece of information as it allows us to achieve interoperability and archivability. The aces:pipelineInfo element can (and should) be used to validate the AMF document itself. The following sections that describe the use of the input transforms, look transforms and output transforms mention the use of transform identifiers. Transform identifiers are also \"tagged\" with the ACES system version to ensure a match between the pipeline system version and the various transform identifiers. The validity of transform identifiers within the scope of a given ACES system version will be described later in a dedicated section. aces:inputTransform \u00b6 This element defines the input transform that is optionally applied to the source material referenced by aces:clipId. The input transforms can be either standard transforms defined within the ACES framework or custom transforms. Custom transforms can be referenced by their transform ID or referenced as external files/resources. Standard transforms can only be referenced by their transform ID. graph BT B1(ACES Input Transform Identifier) --> A1(AMF Input Transform) B2(Custom Input Transform Identifier) --> A1 B3(\"External Input Transform (e.g. CLF)\") --> A1 AMF Input Transform Support AMF can describe one Input Transform as an identifier or external reference An important observation must be made here: the aces:inputTransform is entirely optional. This implies that an AMF document can work in different environments, i.e with sources made of raw material, color pre-processed material and ACES only material. These different use cases will be discussed later in this document. If an aces:inputTransform element is present, then it must also define the \"applied\" attribute that will allow an AMF -aware tool to know if the input transform is provided for information purposes only or if it needs to be executed. aces:lookTransform \u00b6 This element is repeated for every step that defines a custom color processing in the ACES color space (e.g. color grading). There are 3 kinds of look transforms: Standard transforms defined within the ACES framework (such as Gamut Compression) \u25cb Standard transforms can only be referenced by their transform id. Embedded ASC - CDL transforms Embedded ASC - CDL transforms carry their parameters within the file and do not rely on any external information. External transforms stored in various formats ( ASC CDL XML , CLF , etc) External transforms can be referenced by either a unique ID or by a file name, described later in this document. aces:lookTransform elements are optional, and therefore AMF documents do not mandate any color processing beyond the processing provided by the ACES color processing framework. If an aces:lookTransform element is present, then it must also define the \"applied\" attribute that will allow an AMF -aware tool to know if the look transform is provided for information purposes only or if it needs to be executed. aces:outputTransform \u00b6 Finally, this element closes the list and defines both the RRT and ODT (or a combined Output Transform) to use in order to produce a presentable result. The RRT and ODT can be either specified independently of each other: <aces:outputTransform> <aces:referenceRenderingTransform> <aces:transformId>urn:ampas:aces:transformId:v1.5:RRT.a1.0.3</aces:transformId> </aces:referenceRenderingTransform> <aces:outputDeviceTransform> <aces:transformId>urn:ampas:aces:transformId:v1.5:ODT.Academy.P3D60_48nits.a1.0.3</aces:transformId> </aces:outputDeviceTransform> </aces:outputTransform> or combined: <aces:outputTransform> <aces:transformId>urn:ampas:aces:transformId:v1.5:RRTODT.Academy.Rec2020_1000nits_15nits_ST2084.a1.1.0</aces:transformId> </aces:outputTransform> The RRT and ODT (as well as the combined versions) are standard color transforms defined within the ACES framework. AMF & external LMT referencing rules \u00b6 Using <aces:file> \u00b6 The simplest way to reference external LMTs is to use the aces:file element. However, some care must be taken, depending on the workflow and also on the system or device generating the AMF document. The aces:file element is defined as an XML standard type called xs:anyURI. This type allows a very large set of possibilities by using the Uniform Resource Identifier (URI) syntax: file access on a local or remote file system, HTTP or FTP access and much more. All of these possibilities are identified by a scheme, which is a predefined syntax to allow unambiguous interpretation of the URI. Although there are situations where this might not be possible.This document will mainly focus on the file access on computer file systems or embedded file systems (e.g. in-camera). File access is accomplished by the use of the file:// scheme as a prefix to the file location. It is assumed that in a file system centric workflow, the omission of the file:// scheme means that the URI is the actual file name of the external resource, i.e. the LMT . This is probably the most common use. Resolving the file location by the means of the file name may still be problematic, especially because of how various file systems identify disks or volumes. In order to simplify the file name resolution, the following rules are recommended: Avoid the use absolute file names, i.e. file names that contain the full path from the root of the disk or volume Avoid using external LMTs in folders that exist at a higher level in the file system hierarchy than the location of the AMF document Avoid the use of \"current path\" and \"one level up\" path segments as they might not be interpreted correctly by the systems and/or devices that need to work with the AMF document and its externally referenced resources. Example: For an AMF file with the following location: C:\\MyAMFDocuments\\myAMF.amf The external resources, i.e. LMTs, should be located either at the same level, like this: C:\\MyAMFDocuments\\myAMF.amf C:\\MyAMFDocuments\\myLookTransform.clf or in a sub-folder like this: C:\\MyAMFDocuments\\myAMF.amf C:\\MyAMFDocuments\\myAMFLooks\\myLookTransform_First.clf C:\\MyAMFDocuments\\myAMFLooks\\myLookTransform_Second.clf In addition to the recommendations listed above, it is also highly recommended to avoid deep hierarchies for the sub-folders as these can easily cause trouble when the files are moved to a file system with limitations on the file path length. If the external resources cannot be stored in the same folder as the AMF document or in sub-folders relative to the AMF document's location, then the system/device working with the AMF document should provide some user interface means to allow the selection of the location. If automation, without user intervention, is desired, the system/device should provide a configuration file to specify the location. File name characters \u00b6 As stated before, modern file systems are very permissive in terms of file naming. Moreover, most systems have either no limit on the file name length or a very large limit that exceeds easily most of the use cases. Taking advantage of these file system features might not be a good practice though. These limitations differ among the file systems in use and migrating files from one file system to another might result in errors or even truncated file names. In order to avoid problems at the file system level, consider following these rules: Keep files name lengths under 128 characters, file name extension included Restrict the file name extension to 3 characters Use only alphabetical characters for the file name extension Use the native or recommended file name extension for the external resource (e.g. CLF or clf for the Common LUT Format) File naming conventions \u00b6 AMF does not impose a strict file naming convention on the external resources. However it is also highly recommended that a proper and meaningful one is adopted when naming those resources. Proper file naming conventions not only ease the inspection of the files in a file system but also can provide a better reading when displayed in the graphical user interface of the system/device used to manage them. Since these systems/devices can have a limited display room, short names should be considered. Retrieving external LMTs via HTTP \u00b6 The resources identified by a URI using the \"http\" or \"https\" schemes can be retrieved as the response to a GET request to the URI. When working with CLF -based LMTs, care must be taken to clearly indicate the content type in the HTTP headers. For instance AMF and CLF are XML -based specifications and HTTP allows the content type to signal XML in many different ways. Two popular ones are: text/xml application/xml These should be preferred in a HTTP transaction when working with AMF and CLF . HTTP transactions can require authentication in order to access the AMF and the LMTs. Authentication and encryption topics are outside the scope of this document. Nevertheless it's important to consider these issues in a workflow that is distributed around various locations as not all systems/devices support the HTTP security features Using <aces:uuid> \u00b6 CLF ProcessList root element shall have the id attribute set with the sameUUID, e.g: AMF <aces:uuid>urn:uuid:1258F89C-0ED7-4A79-0E2-36F97E8FF9F1</aces:uuid> CLF <ProcessList xmlns=\"urn:AMPAS:CLF:v3.0\" id=\"urn:uuid:1258F89C-0ED7-4A79-B0E2-36F97E8FF9F1\" compCLFversion=\"3.0\"> </ProcessList> The CLF files can be located anywhere and the product supporting AMF + CLF must provide the configuration options to locate the CLFassets, or,search for the CLF files in the local folder for the corresponding CLF files\u2022recursive search in subfolders should be supported (option) Annex \u00b6 Avid Log Exchange ( ALE ) support \u00b6 The Avid Log Exchange ( ALE ) format supports custom metadata elements through the definition of dedicated columns in the ALE table. In order to support AMF linkage through ALE , the following columns are defined: AMF_UUID AMF_NAME These two columns enable the linkage of AMF files, independently for every clip listed in the ALE file. Both AMF_UUID and AMF_NAME are defined as optional. The linkage rules are described below. AMF_UUID \u00b6 The AMF_UUID column shall be used to convey the AMF UUID from the amf:Info/uuid element. The format of the column entries must use the canonical textual representation, the 16 octets of a UUID are represented as 32 hexadecimal (base-16) digits, displayed in 5 groups separated by hyphens, in the form 8-4-4-4-12 for a total of 36 characters (32 alphanumeric characters and 4 hyphens): afe122be-59d3-4360-ad69-33c10108fa7a The AMF_UUID column is optional. AMF_NAME \u00b6 AMF_NAME shall be used to convey the AMF file name located in the same folder as the .ale source file: clip_001.amf The AMF_NAME is optional. When present, it should indicate the file name of the AMF document related to the clip. The AMF file must reside locally in the same folder as the ALE file. No sub-folder structure is permitted. While AMF files can have any name, it is recommended to follow the restrictions imposed by the ALE Specification, i.e. to use the UNC Path syntax. Linkage Rules \u00b6 Since both AMF_UUID and AMF_NAME are optional, there are four possible combinations that can occur: AMF_UUID and AMF_NAME are both absent: In this case, no AMF file can be associated with the clip and is treated like a regular ALE file AMF_UUID is present and AMF_NAME is absent: In this case the host product must look for the corresponding AMF files into a database, using the UUID as a key to match the AMF file and the corresponding clip. Please note that the word \"database\" does not imply any specific implementation. This feature many not be supported by the host product AMF_UUID is absent and AMF_NAME is present: In this case, the AMF_NAME column contains file names for AMF files that should be located at the same level in the file system (i.e. same folder) as the ALE file, or in a subfolder. The linkage is based on the file name and the UUID of the AMF files (if present) is ignored AMF_UUID and AMF_NAME are both present: In this case, the host product can select between the methods described in 2) and 3). However, it is recommended to rely on the UUID in priority. The host product can provide an option to select the matching rule ( UUID or file name). It is desirable to also provide a matching rule that checks both the UUID and file name. Remarks \u00b6 Since the ALE file can reference a large number of clips, it is recommended that the host product presents the issues encountered during the linkage and validation process as a log. ALE files can carry inline ASC parameters. When using AMF with ALEs, the inline ASC parameters should be absent to avoid confusion, or ignored if present. AMF files can have an optional aces:clipId element that is used to identify the clip that the AMF is related to. The aces:clipId element can carry a reference using different methods (e.g. file name, UUID , etc). It is strongly recommended that the clip identification method used in AMF correlates with the method used in the ALE files (e.g. file name). If the same AMF file is shared by multiple clips, it is recommended to avoid the use of aces:clipId or ignore it. A validation process can log any differences and present the results to the user of the product/tool processing the ALE + AMF files Edit Decision List ( EDL ) support \u00b6 The CMX3600 Edit Decision List ( EDL ) format supports custom extensions through the definition of dedicated directives following the edit statements in the decision list. In order to support AMF linkage through EDL , the following directives are defined: AMF_UUID AMF_NAME These two directives enable the linkage of AMF files, independently for every clip listed in the EDL file. Both AMF_UUID and AMF_NAME are defined as optional. The linkage rules are described below. AMF_UUID \u00b6 The AMF_UUID column shall be used to convey the AMF UUID from the amf:Info/uuid element. The format of the column entries must use the canonical textual representation, the 16 octets of a UUID are represented as 32 hexadecimal (base-16) digits, displayed in 5 groups separated by hyphens, in the form 8-4-4-4-12 for a total of 36 characters (32 alphanumeric characters and 4 hyphens): afe122be-59d3-4360-ad69-33c10108fa7a The AMF_UUID column is optional. When present, it should indicate a path to the AMF file that is relative to the folder where the ALE file is located. The path hierarchy MUST not contain the parent folder or local folder distinguished values, i.e. \"..\" and \".\" to avoid any confusion. The path and AMF file name must use characters from the set a-z, A-Z, 0-9, - (dash), _ (underscore) and \".\". No path segment shall use more than 128 characters and the total length shall not exceed 1024 characters. AMF_NAME \u00b6 AMF_NAME shall be used to convey the AMF file name located in the same folder as the .edl source file: clip_001.amf The AMF_NAME is optional. When present, it should indicate the file name of the AMF document related to the clip. The AMF file must reside locally in the same folder as the EDL file. No sub-folder structure is permitted. While AMF file can have any name, it is recommended to use the same base name as the clip file that the AMF document relates to. Moreover to ensure portability across file systems and operating systems it is recommended to use characters from the set a-z, A-Z, 0-9, - (dash), _ (underscore) and \".\". The AMF file name should use no more than 1024 characters. Linkage Rules \u00b6 Since both AMF_UUID and AMF_NAME are optional, there are four possible combinations that can occur: AMF_UUID and AMF_NAME are both absent In this case, no AMF file can be associated with the clip AMF_UUID is present and AMF_NAME is absent In this case the host product must look for the corresponding AMF files into a database, using the UUID as a key to match the AMF file and the corresponding clip. Please note that the word \"database\" does not imply any specific implementation. This feature many not be supported by the host product AMF_UUID is absent and AMF_NAME is present In this case, the AMF_NAME column contains file names for AMF files that should be located at the same level in the file system (i.e. same folder) as the EDL file, or in a subfolder. The linkage is based on the file name and the UUID of the AMF files (if present) is ignored AMF_UUID and AMF_NAME are both present In this case, the host product can select between the methods described in 2) and 3). However, it is recommended to rely on the UUID in priority. The host product can provide an option to select the matching rule ( UUID or file name). It is desirable to also provide a matching rule that checks both the UUID and file name. EDL event example \u00b6 ... 010 Clip1 V C 05:40:12:18 05:40:14:09 01:00:29:16 01:00:31:07 * AMF_NAME clip_001.amf * AMF_UUID afe122be-59d3-4360-ad69-33c10108fa7a ... Remarks \u00b6 Since each entry in the EDL file can use any of the combinations of AMF_UUID and AMF_NAME described above, it is recommended that the host product presents the issues encountered during the linkage and validation process as a log. EDL files can carry inline ASC parameters. When using AMF with EDLs, the inline ASC parameters should be absent to avoid confusion, or ignored if present. AMF files can have an optional aces:clipId element that is used to identify the clip that the AMF is related to. The aces:clipId element can carry a reference using different methods (e.g. file name, UUID , etc). It is strongly recommended that the clip identification method used in AMF correlates with the method used in the EDL files (e.g. file name). If the same AMF file is shared by multiple clips, it is recommended to avoid the use of aces:clipId or ignore it. A validation process can log any differences and present the results to the user of the product/tool processing the EDL + AMF files. @import \"../../stylesheets/sections.css\"","title":"ACES Metadata File (AMF) Implementation Guide"},{"location":"guides/amf/#aces-metadata-file-implementation-guidelines-and-best-practices","text":"","title":"ACES Metadata File Implementation Guidelines and Best Practices"},{"location":"guides/amf/#scope","text":"This document is a guide that recommends implementation guidelines and best practices related to the usage of the ACES Metadata File ( AMF ) in various workflows. These workflows may involve one or more tools that support the AMF specification and this guide attempts to help both implementers and users in order to facilitate interoperability.","title":"Scope"},{"location":"guides/amf/#references","text":"The following standards, specifications, articles, presentations, and texts are referenced in this text: Academy S-2019-001, ACES Metadata File ( AMF ) IETF RFC 4122, A Universally Unique IDentifier ( UUID ) URN Namespace","title":"References"},{"location":"guides/amf/#introduction","text":"The Academy Color Encoding System ( ACES ) is a color processing framework that enables the mix of various sources within a standardized color space in order to produce one or more outputs. While ACES is a living framework and is actively developed and adopted, it also comes with various points that can be configured. These points of configuration are either related to the sources used (Input Transforms), a creative look (Look Transforms), the desired outputs (Output Transforms), or the Version Number (i.e. ACES v1.1) of the core transforms built into the ACES system. ACES does not specify these configuration points directly or associate them with actual images or shots during production, and this is the very reason why AMF exists. AMF is the configuration file that allows a precise setup for an ACES pipeline. Besides this basic goal, AMF is also the tool of choice to transmit and exchange configuration parameters in order to ensure consistency within a workflow and across the entire ecosystem of tools that are used within that workflow.","title":"Introduction"},{"location":"guides/amf/#target-audience","text":"AMF is a sidecar file specified using the XML markup language, and as such it can be processed by machines and at the same time created/modified by users. This document targets both AMF users and AMF implementers because both groups need the same level of understanding in order to design AMF -enabled workflows and tools that support those workflows.","title":"Target Audience"},{"location":"guides/amf/#what-is-amf","text":"AMF is an XML specification that describes the configuration of an ACES color pipeline, together with the various input transforms, look transforms and output transforms. AMF is a \"sidecar\" element, usually accompanying some visual material such as a video file, a sequence of frames, or a whole timeline. In the case of a timeline, more than one AMF file can be used if the timeline requires different configurations of the ACES pipeline. It is also worth mentioning that several AMF files can reference the same visual material. The opposite is equally true as all these visual elements can share a single AMF file or a whole set of them. This of course is entirely dependent on the workflow, and tools implementing AMF should be prepared to deal with this flexibility. In general, the relationship between the visual elements and the AMF files can be described as a \"many to many\" relationship.","title":"What is AMF"},{"location":"guides/amf/#why-is-amf-needed","text":"The ACES framework is expanding and becoming richer in terms of input, look, and output transforms. AMF describes the exact list of these different transforms, in the order in which they have been or should be applied to obtain the desired result. graph LR A1[Input Media] --> B(Input Transform) subgraph AMF Complete Processing Path Description B --> C1(Look Transform) C1 --> D1(Output Transform) end A2[ACES Material] ---> C2(Look Transform) subgraph AMF Partial Processing Path Description C2 --> D2(Output Transform) end AMF Processing Path Description This is a powerful feature because it can describe both configurations that must be used to create a specific output, or configurations that have been used to create a specific output. graph TB B1 --> A1(AMF <br/>Look Modification Transform <br/> Chain) B2 --> A1 B3 --> A1 subgraph B1(\"ASC-CDL<br/>or<br/>External LMT<br/>(active)\") B2(\"ASC-CDL<br/>or<br/>External LMT<br/>(disabled)\") B3(\"ASC-CDL<br/>or<br/>External LMT<br/>(active)\") end classDef disabled opacity: 0.5 class B2 disabled Each block in the chain can be an ASC-CDL or an external LUT. Blocks can be enabled or disabled Finally, another feature of AMF is the ability to document a \"change log\" in an ACES color pipeline. This is called the \"archived pipeline\" and will be discussed later in the document.","title":"Why is AMF needed"},{"location":"guides/amf/#the-applied-attribute","text":"Each transform in an AMF can be tagged with the attribute called applied - which indicates whether a transform has already been applied ( applied=true ), in which case the transform has already been baked into the image, or if the transform has not been applied ( applied=false ), in which case the transform should be loaded as part of the viewing pipeline. One use case of this might be when using the ACES Gamut Compression transform, which may be baked into SMPTE ST 2065-1 ACES image data, and it is essential to communicate to downstream software that it has already been applied, as to not double-apply the transform, or invert it if necessary.","title":"The \u201capplied\u201d attribute"},{"location":"guides/amf/#lifecycle-of-amf","text":"This section describes the life cycle of an AMF and how it could be used within each production stage.","title":"Lifecycle of AMF"},{"location":"guides/amf/#camera","text":"While on set, AMF could be imported in-camera and used to apply color pipeline settings for video and file output, or exported to a camera card when using a camera\u2019s ACES viewing pipeline. See section 7 for more on cameras reading/writing AMF .","title":"Camera"},{"location":"guides/amf/#monitor","text":"Some professional monitors allow import of LUTs to apply looks in-device. AMF could replace proprietary or uncommon LUT formats for improved interoperability.","title":"Monitor"},{"location":"guides/amf/#on-set-live-grading","text":"An AMF may be read by on-set live grading software for the purpose of on-set monitoring and color grading within ACES . If anything is altered within the domain of the pipeline defined in the AMF , a new AMF is created to reflect those modifications. For example, an ACES pipeline is established in an AMF before production, then CDL adjustments are created during production to create an updated AMF accordingly.","title":"On-set live grading"},{"location":"guides/amf/#dailies","text":"In a dailies tool, a pre-created AMF could be read and associated with OCF (Original Camera Files) to apply pipeline settings (for viewing and rendering). This could be done either by manual association or automatically. In the process of creating the dailies, the color pipeline coming from an existing AMF may be modified and updated. AMFs are written out with media to be passed to editorial software. Commonly used interchange files (e.g. EDL or ALE ) can be used to conform AMF files with OCF , see below for more details.","title":"Dailies"},{"location":"guides/amf/#editorial","text":"Editorial software can apply pipeline settings provided by AMF (s) when importing media to automatically set up viewing and rendering.","title":"Editorial"},{"location":"guides/amf/#vfx","text":"Read AMF (s) when importing plates into VFX software and apply pipeline settings for viewing. Given the prevalence of OpenColorIO across VFX software, it is likely that a translation from AMF to OpenColorIO ( OCIO ) would be required.","title":"VFX"},{"location":"guides/amf/#color-grading","text":"When in color grading, AMF could be conformed to a timeline and associated with OCF to apply pipeline settings (for viewing and rendering). These applications should also allow for look development in ACES and subsequent exporting of AMF .","title":"Color Grading"},{"location":"guides/amf/#review","text":"Review software could automatically apply ACES pipeline settings for viewing purposes by reading AMF (s) when importing media or by manually applying AMF (s) to imported media.","title":"Review"},{"location":"guides/amf/#mastering-and-archiving","text":"Read AMF (s) when importing media and apply pipeline settings for viewing. Consolidate AMF (s) to meet specific archival delivery requirements.","title":"Mastering and Archiving"},{"location":"guides/amf/#considerations-on-readingwriting-amf","text":"This section outlines various scenarios related to the reading and writing of AMF files. Scenario Read - An AMF is read when importing media and used to populate a color pipeline for viewing and rendering. Write - A new AMF is written in order to be passed along to the next production stage. If a new AMF is done from a previous AMF , the previous pipeline might be archived in the section. RAW Clips AMF does not include any metadata for demosaic settings. Implementations need to ensure that the image is demosaicked to the appropriate color space before the Input Transform defined in the AMF is applied. User input may be required. If software chooses to directly demosaic a RAW image to ACES , the Input Transform defined in the AMF must be ignored. n/a Input Transform Conflict A clip has already been loaded into the software, and an Input Transform is already applied. Default behaviour should be to override that Input Transform with what\u2019s specified in the AMF , but the user should be prompted. n/a Output Transform Conflict If the AMF specifies an Output Transform that is in conflict with the respective shot\u2019s Output Transform, then this conflict must be handled. The default behaviour should be to stick with the project-wide Output Transform, but it may be useful to indicate a conflict to the user. Example: An AMF is generated from a software platform that uses the Rec709_100nits transform, and is then read by a software platform that is using an HDR Output Transform. The Output Transform that was indeed used for viewing should be specified in the AMF . Manual AMF Batch Import/Export Consider the use of commonly used interchange files (e.g. EDL or ALE ) to batch import AMF \u2019s to a timeline. Ideally, the software would allow for a partial import of only the Input, Look, or Output Transforms of a given AMF . When exporting a batch of AMF \u2019s for an entire timeline, consider exporting commonly used interchange files (e.g. EDL or ALE ) to create an association between Clips and the exported AMF files. Inter- AMF Output Transform Conflict If AMF \u2019s are batch imported into a single timeline, and at least two of them have different Output Transforms defined, consider prompting the user if this inconsistency exists, and provide appropriate options to address. This has the assumption that the user will only be using one Output Transform at a time for an entire timeline. n/a Pipeline Override If an AMF has already been applied to a shot, or if project/timeline settings apply, and a subsequent AMF is read for that shot, consider prompting the user before overriding pipeline. Ideally, the software would allow for a partial import of only the Input, Look, or Output Transforms of a given AMF . Consider including multiple AMF transform pipelines by making use of AMF \u2019s aces:archivedPipeline element. Updating Look Transforms n/a Local changes to transforms in the AMF should not affect any other transforms if the pipeline structure doesn\u2019t change, e.g. when only updating CDL values, but none of the other transforms change, the AMF structure should not be changed and only the CDL values should be updated. Any changes to the transform pipeline will result in a new AMF and global values, e.g. the dateTime element, are therefore expected to change. If CLF (s) are used in the pipeline, consider using CLF UUID and/or its hash to make sure that the CLF has not changed. Look Transform Support If an AMF references a Look Transform with a format that the application does not support reading, consider notifying the user that the format is unsupported, so it is clear the error is unrelated to the AMF itself. When producing a new Look Transform for an AMF export, consider defaulting to CLF , a format that ensures high interoperability,, especially for any operations other than ASC CDL . It\u2019s important to consider what to do when using CDL operations vs other grading operations and how these should be reflected in the AMF document: in elaborated pipeline where CDL are \u201cin between\u201d other more sophisticated grading operations, it might be required to let the user identify and decide over what CDL operations should be treated as such and which ones can be baked with other operations into a consolidated CLF Cameras Import AMF in-camera and apply pipeline settings for video and file output. An AMF loaded in camera could specify over SDI how to treat the incoming signal (ie Output Transform) There are reasonable expectations that any in-camera processing, for the foreseeable future, will be done utilizing small 3D LUTs at the highest complexity. Therefore, applications of an ACES pipeline in-camera may be limited in precision. When should a camera generate an AMF ? If a camera generates an AMF , where should it be written? #1 Preferred Method: Embedded in the OCF , e.g.REDCODE RAW R3D #2 Preferred Method: AMF should live in the same directory as its associated clip #3 Preferred Method: * A single folder with all AMF files Metadata Population Parse the AMF for its filename and aces:uuid and write these to the appropriate metadata fields for each clip. If the AMF associated with a clip changes, the value relative to the AMF metadata fields within the editorial software should change and adopt the new values. So when writing commonly used interchange files (e.g. EDL or ALE ) the correspondent values are correct. Applied Tag When reading an AMF file that has the applied=true attribute for a specific transform, the software should NOT apply the transform to the file, since it has already been applied to the image itself. Consider reporting it to the user if applicable (e.g. a \u201chistory\u201d log of the transforms is accessible for each clip) When exporting AMF \u2019s from a timeline of clips that have not been rendered yet, each transform in the AMF should be tagged as applied=false . However, when rendering new files, consider having the ability to export new AMF \u2019s files simultaneously as part of the same deliverable and, in this case, each transform that is actually baked in should be tagged as applied=true in the AMF (e.g. the Input Transform if rendering OpenEXR ACES 2065-1 VFX pulls, or everything when exporting 709 proxies for editorial). Archived Pipelines Consider allowing the user to toggle between different ACES pipelines that are recorded in the aces:archivedPipeline element. Otherwise, aces:archivedPipeline elements should be preserved for any new AMF \u2019s subsequently created for the same shots. If the software is updating a pre-existing AMF , the written AMF should include the appropriate aces:archivedPipeline element.","title":"Considerations on reading/writing AMF"},{"location":"guides/amf/#structure-of-amf","text":"AMF is a specification based on the XML markup language. It is fully described in Academy Specification S-2019-001 . The specification also comes with an XML Schema that can be used to validate the AMF documents. The XML Schema is publicly available here: https://github.com/ampas/aces-dev/tree/master/formats/amf The guidelines and best practices in this document are provided to help both implementers and users to take full advantage of AMF . It is strongly recommended to use the specification as a reference in order to better understand the concepts described here.","title":"Structure of AMF"},{"location":"guides/amf/#amf-document-sections","text":"AMF documents are mainly divided in 3 sections: aces:amfInfo - this section provides descriptive information about the AMF itself. aces:clipId - this section provides a reference to the visual material ( OCF or rendered images) that this AMF is applicable for. aces:pipeline - this section describes the ACES pipeline configuration.","title":"AMF document sections"},{"location":"guides/amf/#general-descriptive-information","text":"The aces:amfInfo element contains various sub-elements that provide descriptive information about the AMF document but also a mechanism to help identification. More specifically two sub-elements deserve some consideration: aces:dateTime aces:uuid The mandatory aces:dateTime element contains the creation and modification date. The aces:uuid element is optional and is designed to carry a Universally Unique Identifier (also known as Globally Unique Identifier, or GUID on some systems). The Universally Unique Identifier is specified in IETF RFC 4122 as well as other ISO and ITU documents. Both aces:dateTime and aces:uuid elements are not filled in by a human operator but rather automatically generated by the tool used to create the AMF document.","title":"General descriptive information"},{"location":"guides/amf/#clip-information-and-association","text":"As described in the previous sections, AMF can be used with different targets, i.e. single file video clips, image sequences, compositions, etc. This flexibility implies that the AMF specification does not prescribe a specific way to create the connection with the target material. Instead, the specification offers different connection mechanisms via the aces:clipId, an optional structure that in turn contains child elements to help with the handling of the various situations. The first important observation to make is that the aces:clipId element itself is defined as optional. In this context, optional does not mean that the presence or absence of the aces:clipId element does not affect the workflow and how tools that support AMF behave. The term optional must be understood as a switch between two categories of workflow: the first does not connect an AMF file to a specific visual material and the second does connect an AMF file to a specific visual material. Depending on the workflow in use, an implementation must handle the presence or absence correctly and report errors if necessary. Typically, the XML validation only will not be enough to distinguish between a valid AMF file and an invalid one, since the aces:clipId element is optional. In other words, the aces:clipId does not dictate how the AMF document is handled. It is the workflow that dictates the behavior.","title":"Clip information and association"},{"location":"guides/amf/#aces-pipeline-configuration","text":"The ACES pipeline section is a list of ordered elements that define various steps of the ACES color pipeline. The pipeline is described by the aces:pipeline element. In turn, this element contains a list of sub-elements that describe the configuration of the various color processing stages that exist in the ACES color processing framework. Below is the list of sub-elements that can be found in the aces:pipeline element: aces:pipelineInfo aces:inputTransform aces:lookTransform aces:outputTransform These elements must appear in this exact order. Although these steps are described separately, this does not imply that a system has to process all pixels in a frame of visual material one step at a time. Some systems might do it while some others might need to crunch the various processing steps into a single transform, typically a 3D Lookup Table (3D LUT ). Moreover a system may choose to optimize the processing of the various steps, depending on the given situation. The only constraint is that the color processing must follow the steps in the order described above.","title":"ACES pipeline configuration"},{"location":"guides/amf/#amf-external-lmt-referencing-rules","text":"","title":"AMF &amp; external LMT referencing rules"},{"location":"guides/amf/#using-acesfile","text":"The simplest way to reference external LMTs is to use the aces:file element. However, some care must be taken, depending on the workflow and also on the system or device generating the AMF document. The aces:file element is defined as an XML standard type called xs:anyURI. This type allows a very large set of possibilities by using the Uniform Resource Identifier (URI) syntax: file access on a local or remote file system, HTTP or FTP access and much more. All of these possibilities are identified by a scheme, which is a predefined syntax to allow unambiguous interpretation of the URI. Although there are situations where this might not be possible.This document will mainly focus on the file access on computer file systems or embedded file systems (e.g. in-camera). File access is accomplished by the use of the file:// scheme as a prefix to the file location. It is assumed that in a file system centric workflow, the omission of the file:// scheme means that the URI is the actual file name of the external resource, i.e. the LMT . This is probably the most common use. Resolving the file location by the means of the file name may still be problematic, especially because of how various file systems identify disks or volumes. In order to simplify the file name resolution, the following rules are recommended: Avoid the use absolute file names, i.e. file names that contain the full path from the root of the disk or volume Avoid using external LMTs in folders that exist at a higher level in the file system hierarchy than the location of the AMF document Avoid the use of \"current path\" and \"one level up\" path segments as they might not be interpreted correctly by the systems and/or devices that need to work with the AMF document and its externally referenced resources. Example: For an AMF file with the following location: C:\\MyAMFDocuments\\myAMF.amf The external resources, i.e. LMTs, should be located either at the same level, like this: C:\\MyAMFDocuments\\myAMF.amf C:\\MyAMFDocuments\\myLookTransform.clf or in a sub-folder like this: C:\\MyAMFDocuments\\myAMF.amf C:\\MyAMFDocuments\\myAMFLooks\\myLookTransform_First.clf C:\\MyAMFDocuments\\myAMFLooks\\myLookTransform_Second.clf In addition to the recommendations listed above, it is also highly recommended to avoid deep hierarchies for the sub-folders as these can easily cause trouble when the files are moved to a file system with limitations on the file path length. If the external resources cannot be stored in the same folder as the AMF document or in sub-folders relative to the AMF document's location, then the system/device working with the AMF document should provide some user interface means to allow the selection of the location. If automation, without user intervention, is desired, the system/device should provide a configuration file to specify the location.","title":"Using &lt;aces:file&gt;"},{"location":"guides/amf/#file-name-characters","text":"As stated before, modern file systems are very permissive in terms of file naming. Moreover, most systems have either no limit on the file name length or a very large limit that exceeds easily most of the use cases. Taking advantage of these file system features might not be a good practice though. These limitations differ among the file systems in use and migrating files from one file system to another might result in errors or even truncated file names. In order to avoid problems at the file system level, consider following these rules: Keep files name lengths under 128 characters, file name extension included Restrict the file name extension to 3 characters Use only alphabetical characters for the file name extension Use the native or recommended file name extension for the external resource (e.g. CLF or clf for the Common LUT Format)","title":"File name characters"},{"location":"guides/amf/#file-naming-conventions","text":"AMF does not impose a strict file naming convention on the external resources. However it is also highly recommended that a proper and meaningful one is adopted when naming those resources. Proper file naming conventions not only ease the inspection of the files in a file system but also can provide a better reading when displayed in the graphical user interface of the system/device used to manage them. Since these systems/devices can have a limited display room, short names should be considered.","title":"File naming conventions"},{"location":"guides/amf/#retrieving-external-lmts-via-http","text":"The resources identified by a URI using the \"http\" or \"https\" schemes can be retrieved as the response to a GET request to the URI. When working with CLF -based LMTs, care must be taken to clearly indicate the content type in the HTTP headers. For instance AMF and CLF are XML -based specifications and HTTP allows the content type to signal XML in many different ways. Two popular ones are: text/xml application/xml These should be preferred in a HTTP transaction when working with AMF and CLF . HTTP transactions can require authentication in order to access the AMF and the LMTs. Authentication and encryption topics are outside the scope of this document. Nevertheless it's important to consider these issues in a workflow that is distributed around various locations as not all systems/devices support the HTTP security features","title":"Retrieving external LMTs via HTTP"},{"location":"guides/amf/#using-acesuuid","text":"CLF ProcessList root element shall have the id attribute set with the sameUUID, e.g: AMF <aces:uuid>urn:uuid:1258F89C-0ED7-4A79-0E2-36F97E8FF9F1</aces:uuid> CLF <ProcessList xmlns=\"urn:AMPAS:CLF:v3.0\" id=\"urn:uuid:1258F89C-0ED7-4A79-B0E2-36F97E8FF9F1\" compCLFversion=\"3.0\"> </ProcessList> The CLF files can be located anywhere and the product supporting AMF + CLF must provide the configuration options to locate the CLFassets, or,search for the CLF files in the local folder for the corresponding CLF files\u2022recursive search in subfolders should be supported (option)","title":"Using &lt;aces:uuid&gt;"},{"location":"guides/amf/#annex","text":"","title":"Annex"},{"location":"guides/amf/#avid-log-exchange-ale-support","text":"The Avid Log Exchange ( ALE ) format supports custom metadata elements through the definition of dedicated columns in the ALE table. In order to support AMF linkage through ALE , the following columns are defined: AMF_UUID AMF_NAME These two columns enable the linkage of AMF files, independently for every clip listed in the ALE file. Both AMF_UUID and AMF_NAME are defined as optional. The linkage rules are described below.","title":"Avid Log Exchange (ALE) support"},{"location":"guides/amf/#edit-decision-list-edl-support","text":"The CMX3600 Edit Decision List ( EDL ) format supports custom extensions through the definition of dedicated directives following the edit statements in the decision list. In order to support AMF linkage through EDL , the following directives are defined: AMF_UUID AMF_NAME These two directives enable the linkage of AMF files, independently for every clip listed in the EDL file. Both AMF_UUID and AMF_NAME are defined as optional. The linkage rules are described below.","title":"Edit Decision List (EDL) support"},{"location":"guides/clf/","text":"@import \"../../stylesheets/sections.css\" Common LUT Format ( CLF ) Implementation Guide \u00b6 Introduction \u00b6 Look-up tables, or LUTs , are a common method for communicating color transformations. Many software and hardware providers develop LUT formats uniquely designed for use in their systems. Since these formats were designed to work in specific use cases, they often prove inadequate for interchangeability between applications or systems. To further complicate matters, some LUT formats use the same file extensions which make them appear to be compatible when they are not. If there are already a dozen or more confusing LUT formats, why should you as a developer consider adding support for yet another one? While the myriad LUT formats already available are fundamentally useful in theory, each lacks one or more features that can be critical in meeting the demands of today\u2019s sophisticated workflows. Existing formats can lack the quality, versatility, and metadata required to meet the demands of modern systems. The Common LUT Format ( CLF ) provides flexibility to enclose transforms from simple to complex. Due to a lack of interchangeability of color transforms between tools, LUTs are frequently abused as a catch-all. Even simple color-space transformations, such as the application of a matrix or a logarithmic shaper function are often \u201cbaked\u201d to crude LUT formats resulting in unfortunate losses in precision. As a solution, CLF allows for a range of common mathematical operators to be specified precisely, in addition to supporting traditional 1D- and 3D- LUTs in the file. Because CLF files are floating-point capable, extremely flexible, and well documented, they are an excellent candidate for use in modern workflows. CLFs are also ideal for archival purposes because the format is well-specified and documented. There is also a high-quality, open source implementation freely available on GitHub. Format Comparison Table \u00b6 Features/Formats CLF 3dl Adobe (Iridas) cube Resolve cube Truelight cube Cinespace cube ASC CDL Imageworks spi3d ICC Profile Provider Academy / ASC Discreet Adobe Blackmagic Filmlight Rising Sun ASC Imageworks ICC Maintained public documentation \u2705 \u274c \u2705 \u2705 \u2705 \u274c \u2705 \u274c \u2705 Implementation guide \u2705 \u274c \u274c \u274c \u274c \u274c \u2705 \u274c \u2705 Allows shaper LUT \u2705 \u274c \u274c \u2705 \u2705 \u2705 \u274c \u274c \u2705 Is not limited to log or video data on input \u2705 \u274c \u274c \u2705 \u2705 \u2705 \u274c \u274c \u274c Unconstrained ordering of processing elements \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u274c Floating-point table values \u2705 \u274c \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 Rich metadata \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u2705 Test suite provided \u2705 \u274c \u274c \u274c \u274c \u274c \u2705 \u274c \u2705 Text-based \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u274c Can define operations in linear floating-point space \u2705 \u274c \u274c \u274c \u274c \u274c \u2705 \u274c \u2705 GUID support \u2705 \u274c \u274c \u274c \u274c \u274c \u2705 \u274c \u2705 Supports mathematical operators \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u274c Target Audience \u00b6 This document is primarily intended for application developers who want to add CLF support to their product. It defines requirements, tests, and provides recommendations that, if followed, will lead to robust support for CLF . Implementers who follow the guidance in this document can have confidence that their product is implementing the specification correctly. The document may also be of interest to those using CLF to author transforms and who want to understand how the CLFs will be used by applications. This guide should be read in conjunction with the CLF specification (v 3.0). The CLF spec may be downloaded from: http://j.mp/S-2014-006 . Note: Although the spec has \"2014\" in the name, the document has been updated more recently than that. Version 3 of CLF was introduced with the release of ACES 1.2 in 2020 and the most recent editorial updates were in 2021. A Quick Introduction to CLF \u00b6 Below is a basic example of a simple CLF file. Despite the word ' LUT ' in the name of the format, these very simple examples do not contain any type of LUT whatsoever. Instead, the CLF is being used to communicate a set of ASC CDL adjustments ( Example 1 ), and encapsulate a YCbCr to RGB conversion ( Example 2 ). There are a few key points that these examples demonstrate: CLF is an XML document and therefore conforms to the requirements of any XML document. There is one ProcessList , which can contain any number of ProcessNodes . (A ProcessNode is an operator such as a Matrix or LUT3D .) A CLF may or may not contain \u201c LUTs \u201d (despite the name). Some parts are optional and others are required. CLF provides a richer metadata model than other LUT formats - it\u2019s not just numbers. Good metadata is highly encouraged and helps make the CLF file self-documenting. Every CLF must have a unique id attribute. The bit-depth attributes control formatting but not precision. Color coding: red is required, blue is optional, green are comments. Example 1: ASC CDL Implementation \u00b6 <?xml version=\"1.0\" encoding=\"UTF-8\"?> <!-- Required: XML Version and Encoding declaration --> <!-- Required: ProcessList element with \u2018id\u2019 and \u2018compCLFversion\u2019 --> <!-- name and xmlns are optional --> <ProcessList compCLFversion= \"3.0\" id= \"b4cca59a-9428-49c0-8e91-868718c4e526\" name= \"FwdNoClamp style\" xmlns= \"urn:AMPAS:CLF:v3.0\" > <Description> CDL with FwdNoClamp style </Description> <ASC_CDL id= \"clf/ctf no-clamp fwd\" inBitDepth= \"10i\" outBitDepth= \"8i\" style= \"FwdNoClamp\" > <SOPNode> <Slope> 1.000000 1.000000 0.800000 </Slope> <Offset> -0.020000 0.000000 0.150000 </Offset> <Power> 1.050000 1.150000 1.400000 </Power> </SOPNode> <SatNode> <Saturation> 0.750000 </Saturation> </SatNode> </ASC_CDL> </ProcessList> Example 2: BT.709 YCbCr ( SMPTE /legal range) to RGB (full range) \u00b6 <?xml version=\"1.0\" encoding=\"UTF-8\"?> <!-- Line above is required: XML Version and Encoding declaration --> <!-- Required: ProcessList element with \u2018id\u2019 and \u2018compCLFversion\u2019 --> <ProcessList id= \"0befc138-3757-45f0-a080-83bebb77baf2\" compCLFversion= \"3.0\" > <!-- Optional: ProcessList Description --> <Description> BT.709 YCbCr (legal) to RGB (full) </Description> <!-- Optional: InputDescriptor / OutputDescriptor --> <InputDescriptor> YCbCr </InputDescriptor> <OutputDescriptor> RGB </OutputDescriptor> <!-- Required: One or more ProcessNode elements --> <!-- inBitDepth and OutBitDepth are required, id is optional --> <!-- If in/outBitDepth values are different, the scale factor between them must also be applied to the matrix coefficients! --> <Matrix id= \"815ebbac-550a-453b-a1e6-bf93779fc9c8\" inBitDepth= \"32f\" outBitDepth= \"32f\" > <!-- Optional: ProcessNode description --> <Description> Input offsets for legal range luma and color difference channels </Description> <!-- White space formatting is recommended, but optional --> <!-- Array element is required for a Matrix ProcessNode --> <Array dim= \"3 4\" > <!-- when dim=\u201d3 4\u201d, the 4th column is offset terms --> 1.0 0.0 0.0 -0.0625 0.0 1.0 0.0 -0.5 0.0 0.0 1.0 -0.5 </Array> </Matrix> <!-- Additional ProcessNodes are applied in order --> <Matrix id= \"deceda6e-8fee-471a-8599-fa513c17f3cf\" inBitDepth= \"32f\" outBitDepth= \"32f\" > <Description> BT.709 YCbCr to RGB matrix </Description> <Array dim= \"3 3\" > 1.16893193493151 0.000000000000000 1.799743966238840 1.16893193493151 -0.214081616673236 -0.534991005624129 1.16893193493151 2.120653355189730 -0.000000000000000 </Array> </Matrix> </ProcessList> Open Source Example Implemention \u00b6 As you explore CLF and work to implement it into your product(s), it may be helpful to refer to some existing tools that already provide full CLF functionality. The tools described here are included in the open source project OpenColorIO ( OCIO ) v2. More details and the full installation process for OCIO can be found at https://www.opencolorio.org . ociochecklut \u00b6 The command-line utility ociochecklut can be used to load a CLF file and process an RGB triplet through the CLF file. It will report any errors that are encountered in parsing the file. If no RGB triplet is provided to process through the CLF file, then a list of the ProcessNodes contained in the LUT are returned. This tool is installed as part of OCIO v2. Here is sample output using the CLF in the example section (assuming it is saved as a file called 709_ycbcr-to-rgb.clf ): Summarizing the contents of the CLF : $ ociochecklut 709_ycbcr-to-rgb.clf Transform operators: <MatrixTransform direction=forward, fileindepth=32f, fileoutdepth=32f, matrix=1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1, offset=-0.0625 -0.5 -0.5 0> <MatrixTransform direction=forward, fileindepth=32f, fileoutdepth=32f, matrix=1.16893193493151 0 1.79974396623884 0 1.16893193493151 -0.214081616673236 -0.534991005624129 0 1.16893193493151 2.12065335518973 -0 0 0 0 0 1, offset=0 0 0 0> Evaluating the RGB value [0.5, 0.4, 0.3]: $ ociochecklut 709_ycbcr-to-rgb.clf 0.5 0.4 0.3 0.1514589 0.6398141 0.2993424 ocioconvert \u00b6 The command-line utility ocioconvert can be used to apply a CLF file to an image. To apply a CLF file, use the --lut option. A variety of image file formats are supported. This tool is installed as a part of OCIO v2, although it first requires installation of OpenImageIO. Processing the input image syntheticChart.01.exr to the output image output_image.exr through the CLF from the previous example: $ ocioconvert --lut 709_ycbcr-to-rgb.clf syntheticChart.01.exr output_image.exr ociomakeclf \u00b6 The command-line utility ociomakeclf will convert any LUT format supported by OpenColorIO into CLF format. The --csc option may be used to create an ACES Look Transform that is compatible with the ACES Metadata File ( AMF ). This tool is installed as a part of OCIO v2. Convert the LUT oldLUT.3dl to CLF format: $ ociomakeclf oldLUT.3dl oldLUT.clf Convert the look LUT acescctLUT.3dl that expects and produces ACEScct values to an ACES Look Transform in CLF format that expects and produces ACES2065-1 values: $ ociomakeclf acescctLUT.3dl LMT.clf --csc ACEScct Minimum Requirements \u00b6 Introduction \u00b6 The products anticipated to implement CLF can be categorized into two broad categories: one for final production-level finished images and one for preview/proxy images. Due to the fundamental differences in the products, different requirements are provided for the two categories. Finishing Tier \u00b6 The primary category of products, dubbed the Finishing Tier , includes software implementations that have the logic and processing power available to parse and apply ProcessNode operations using floating-point calculations and in sequential order. Finishing Tier products provide the highest quality image processing and have the tightest tolerances, prioritizing accuracy in computation results. Finishing Tier products should be used to create images when the highest image fidelity is required in pipelines utilizing CLF files. Minimum Requirements \u00b6 Products in the Finishing Tier category shall: Pass all the Read Tests Pass the Finishing Tier Apply Tests In addition to the minimum requirements, Finishing Tier products should review the \" Writing CLFs \" section and conform their CLF implementation to those recommendations wherever possible. Preview Tier \u00b6 The second category of implementations are described as Preview Tier devices. These are products that, due to limited processing power or technical constraints, cannot implement a CLF ProcessList exactly and instead require that CLF files be \u201dbaked\u201d or collapsed into a simpler representation (for example, a single 3D- LUT ). Hardware devices such as on-set LUT boxes would be an example of devices that might fall into this category. As the name implies, Preview Tier products are suitable for creating images such as for on-set viewing, where the requirements for accuracy and/or flexibility are lower than for the Finishing Tier. CLF is designed as a modern LUT format that can handle floating-point input and output pixels. However, the current ecosystem of devices still includes many products that work primarily on integer-encoded signals (e.g. HD-SDI and HDMI video) and do not support floating-point image data, including scene-linear encodings such as ACES2065-1. These types of devices would fall in the Preview Tier and CLF may be used to encapsulate any of the LUTs that are currently used in such devices. But there is no expectation that these devices will be able to accurately process other CLFs that contain transforms expecting scene-linear inputs or outputs. Note that although the processing requirements are lower for the Preview Tier, the read requirements are not. In other words, even Preview Tier devices must be able to read all of the files in the test suite. But as described in the section \" Applying CLFs \", if a Preview Tier device detects ProcessNodes that it does not support, there are two options: Inform the user of this situation and do not attempt to process the file. Attempt to bake the CLF down into a representation supported by the device. The user should be given some indication that they are seeing an approximation of the original CLF . Minimum Requirements \u00b6 Products in the Preview Tier category shall: Pass all the Read Tests Pass the Preview Tier Apply test Reading CLFs \u00b6 This section describes the general requirements for parsing CLF files, the provided test suite, and the steps for validating an implementation using the test suite. General Parsing Requirements \u00b6 Requirements: \u00b6 Version Support Implementations are expected to support v3 of the CLF specification. Backwards compatibility for versions prior to v3 is optional. Error Handling An implementation must check that a file is valid, and if not, issue an error or warning to the user hinting at what the problem is. The tool ociochecklut ( described above ) provides good examples of the types of errors that could be issued when illegal syntax is detected. Metadata reading An implementation must (at a minimum) be able to display to the user the contents of these key metadata fields: Top-level ProcessList Description elements InputDescriptor , OutputDescriptor Precision and formatting of numeric values Implementations must be able to read at least 32-bit float precision, though 64-bit precision is desirable for ProcessNodes other than LUT1D and LUT3D . Note that the specification defines the numeric values as \u201cxs:float\u201d type, that is, XML Schema floats. Parsers should be able to handle all of the details of this format (e.g., integers without a decimal point, missing leading 0 on decimal values, the presence of a leading \u201c+\u201d, etc.). Note that an integer is a legal xs:float. Recommendations \u00b6 XML is designed to be extensible, and XML files often contain data that was not defined in the specification. However, the desire for extensibility must be balanced against the need to detect erroneous content. On occasion, unrecognized XML elements may be detected. In those instances, the following logic is recommended: If the unrecognized element is at the ProcessNode level (in other words, the top level of the ProcessList ), it should produce an error, or at least a warning. If the unrecognized element is within a ProcessNode , a warning should be issued. If the unrecognized element is within the Info block, it may be ignored. CLF File Test Suite \u00b6 A number of test files are provided for implementers to test their system and demonstrate that their implementation can robustly handle all features of CLF v3. The tests provided in the OpenColorIO repository on Github include both legal and illegal test files. The file name and description in each file identifies what the file is testing. The test files confirm that each ProcessNode is functioning per the specification. For ProcessNodes that allow for different styles or parameters, either separate test files or single test files with multiple ProcessNode variations are provided to check that all styles and parameters are functional. Standard files are expected to be processed without error. A number of \"illegal\" test files with various syntax errors are also provided to test the error handling capability of implementations. Illegal files should not be processed and the system should generate an appropriate error message. Test Procedure \u00b6 Download the OpenColorIO repository from GitHub at the URL: https://github.com/AcademySoftwareFoundation/OpenColorIO If you are not familiar with Git, that\u2019s fine. Simply click on the green button that says Code and select \u201cDownload ZIP\u201d. Unzip this file on your computer and you will have all of the test files. The test files are in the directory: OpenColorIO/tests/data/files/clf You may refer to a description of each test file in Annex B . For each legal test file: Read the file into your product and verify that it loads successfully. For each illegal test file (these are the files in the clf/illegal subdirectory): Read the file into your product and ensure that the user is notified that it is not a legal CLF file. Ideally, the nature of the problem should be communicated to the user. Verify that none of these files load successfully. They should not result in a processed image. If an implementation needs to pass through the unprocessed image, it should communicate clearly to the user in some other way that there was an error. Applying CLFs \u00b6 General \u00b6 For CLF to be useful, it is important that different products output the same results when applying the same CLF to the same input. This section describes the different expectations for Finishing Tier and Preview Tier products. Each category has their own metric and defined tolerances. Finishing Tier \u00b6 Tolerances \u00b6 The Finishing Tier is intended to cover software-based implementations such as products for tasks including color correction and compositing. It is expected that these implementations will use floating-point math to apply the contents of the CLF , without converting it into a significantly different representation. Hence fairly tight tolerances may be expected. A CLF may be used to apply arbitrary color space conversions and so the input and output images may be in arbitrary color spaces, including video, logarithmic, and scene-linear color encodings. Both integer and wide-range floating-point pixel values are expected. Video and logarithmic encodings are typically sufficiently perceptually uniform that a simple absolute error metric such as (actual \u2013 aim) may be used. However, scene-linear encodings require a tolerance that is tighter for dark colors and looser for bright colors - in other words, a relative rather than absolute metric. This is due to the approximately logarithmic nature of human color perception (although the metric is actually computed per channel). When comparing an aim and actual value, a basic relative error metric has the form: (actual \u2013 aim) / aim However this can become overly sensitive when the values being compared become very small. In the limit, when the aim value is zero, the result is either infinity or NaN. Therefore it is useful to use a \u201csafe-guarded relative error metric\u201d that places a lower bound on the denominator: actual \u2013 aim) / max(aim, lower_bound) . This effectively transitions the error metric from being a relative error metric for bright and normal colors to an absolute error metric when approaching a certain noise floor determined by the lower_bound constant. A reasonable lower_bound constant for images in ACES2065-1 color space would be 0.1. It is also necessary to handle the case where the aim value may be negative, in which case the final error metric becomes: abs(actual \u2013 aim) / max(abs(aim), 0.1) <= 0.002 This is essentially a relative tolerance of +/\u2013 one part in 500 above 0.1 and an absolute tolerance of +/\u2013 0.0002 below 0.1. It is expected that implementations in the Finishing Tier will be using floating-point software calculations and the processing will be applied this way regardless of whether the color encodings involved are video, logarithmic, or scene-linear. Since relative tolerances are well-suited to verifying floating-point math, the safe-guarded relative error metric will be used for all Finishing Tier tolerances even though this may be perceptually either too tight or too loose when processing video or logarithmic pixel values. Above the lower bound transition, the tolerance for implementations in the Finishing Tier is a relative error of plus or minus one part in 500. For comparison, half-float numbers are spaced at a relative distance of one part in 1024. (In the literature on the subject of floating-point math, this distance is called a \u201cunit of least precision,\u201d or ULP.) So the tolerance for the metric is only slightly more loose than the precision imposed by the storage of images as half-float OpenEXR files. To validate the tolerance, testing was conducted using various processing modes in OpenColorIO. For example, various forms of CPU optimization were applied and the results were compared to the unoptimized reference version. These included optimizations such as concatenating adjacent matrices and approximating standard library logarithm and power functions with faster but less precise versions. Likewise, processing on the GPU was compared to the CPU reference version. The test image that was used is the one described in Annex A, so it sampled the full range of half-float numbers. The fact that all of these processing variations passed the specified error tolerance indicates that it should be an achievable performance level for a wide range of products. Test Procedure \u00b6 The collection of test CLF files are included in the OpenColorIO repository, as described in Annex B . Process the source image (whose contents are described in Annex A ) through your implementation for each of the CLFs described in Annex C . The processed reference frames to be used for comparison may be downloaded as described in Annex C , or you may generate them yourself using the steps described in Annex K The command-line application oiiotool , which is installed as a component of OpenImageIO, can be used to compare pixels between two images and evaluate the metric specified in this section. A Python script for doing this is provided with OpenColorIO. Here are the steps for how to install and run it: Install OpenImageIO. Download the OpenColorIO source code from the URL: https://github.com/AcademySoftwareFoundation/OpenColorIO Unzip the downloaded source code package. In a shell, cd to the directory where the OpenColorIO source code was unzipped, and then cd into the sub-directory share/clf . This directory contains the Python script. In the shell, type: $ python compare_clf_test_frames.py <PATH-TO-REFERENCE-IMAGES> <PATH-TO-ACTUAL-IMAGES> replacing the two items in brackets with the path to the downloaded reference images and the path to your implementation's actual images. The script iterates over the images in the directory and prints the oiiotool command being run. It will then print either 'Test passed' or 'Test failed' after each command and then at the end will summarize with 'All tests passed' or 'These tests failed' with a list of the failed images. Alternate Test Procedure \u00b6 Implementers may also choose to use other tools or implement their own tools to compare pixel values and calculate the metrics. In that case, proceed as follows to compare your actual images to the aim reference images described in Annex C : For each CLF identified in the Finishing Tier test list in Annex C : Use your implementation to process the test frame through each legal CLF file. Calculate the error metric: abs(actual \u2013 aim) / max(abs(aim), 0.1) Verify that: max error <= 0.002 no Infinity or NaN values are created Preview Tier \u00b6 LUT Baking \u00b6 Preview Tier devices/implementations typically are not able to handle the full flexibility of the CLF processing model. If the contents of the CLF correspond to what the device may natively apply, then it is reasonable to expect fairly tight processing tolerances. However, if the CLF contains many ops that must be converted (or \"baked\") into some other representation in order to be applied in device hardware, then it may be unreasonable to demand the same level of performance. Different tolerances would need to be established for each CLF in the test suite depending on the contents and complexity of each CLF and on the details of how it is baked. Therefore, the current version of this guide only tests the ability to process a single LUT3D (e.g. a baked result, not the baking process itself). So all Preview Tier devices must at least handle the LUT3D apply test but implementers will need to decide how to handle CLFs that are more complicated. One approach is to simply inform the user that the CLF contains operators that cannot be processed by that implementation. Another approach is to attempt to bake the CLF into a form that the implementation is able to process. Annex E provides an introduction to the topic of baking. Implementations should notify users if their CLF is being baked into a significantly different structure in order to be processed by the device. (Simple adjustments such as concatenating adjacent matrices into a single matrix do not fall into this category, but combining multiple operators into a single LUT3D certainly does.) Implementers are strongly advised to document the CLF structures that they are able to apply exactly, without need of baking. This would allow users to plan their processing accordingly in order to make best use of the device. Advanced users will be able to generate CLFs in order to obtain the best accuracy possible, given the restrictions. Tolerances \u00b6 The Preview Tier is intended to cover devices such as on set LUT boxes that work on live SDI video signals. These devices are intended to process video or logarithmic encodings and typically do not handle floating-point pixel values. Therefore, a simple absolute error metric may be used. Integer values should be normalized to [0,1] by dividing by the maximum integer value (e.g., 1023, 4095, 65535), yielding an absolute error metric applied to normalized values: \\[ {\\text{abs}(actual \u2013 aim) <= 0.002} \\] This is essentially a tolerance of +/\u2013 two 10-bit code values, if applied to a 10-bit signal, or equivalently +/\u2013 eight 12-bit code values, if applied to a 12-bit signal, etc. Test Procedure \u00b6 The process of verification for the Preview Tier is to check for correct implementation of a LUT3D with tetrahedral interpolation using an integer test image. For the CLF identified in the Preview Tier test list in Annex D : Use your implementation to process the Preview Tier DPX source image (see Annex D ) and produce an integer DPX result. Compare your result to the DPX reference frame provided (see Annex D ), and calculate the error metric described in the preceding paragraphs: If using OpenImageIO, the command would be: $ oiiotool <aim-image> <actual-image> --absdiff --rangecheck 0,0,0 .002,.002,.002 -o /tmp/tmp.dpx This command will print something like this: 0 < 0,0,0 0 > .002,.002,.002 1048576 within range If the second line of the result indicates that there are 0 pixels greater than 0.002, then the test passed. (Note that oiiotool works in normalized units, so 0.002 is actually equivalent to 0.002 x 1023 = 2.046 10-bit code values.) Writing CLFs \u00b6 Not all products must support writing CLFs, depending on the way they are used. If your product supports the writing of CLF files, it must adhere to the CLF specification. Some important highlights and recommendations for implementation default behavior, or for users authoring CLFs by hand, are described in the following sections. File Extension \u00b6 The extension used for CLF files should be a .clf at the end of the file name. Indentation \u00b6 CLF files may be opened and read by users during troubleshooting, so readability is desirable. In particular, the following formatting is recommended for indentation: Use 2-4 spaces to indent relative to a parent item. A new indented line should be used after the starting element tag for complex XML types. For compactness, simple XML types may be placed on a single line. Arrays (contained in Matrix , LUT1D , LUT3D ) should use line breaks to present data visually (e.g., by aligning columns of R, G, B). Large blocks of lines of numbers do not need to be indented since they are already visually distinct and there is no point adding spaces in front of thousands of lines (e.g., in the case of large LUTs ). Long text strings (e.g. in a Description tag) should not contain embedded wrapping and indentation. It is better to let the application software determine where to wrap long lines of text in order to present them best in its own user interface. Indentation example (using made-up element names): \u00b6 <aTag> <simpleType>This does not require a line break.</simpleType> <complexType> <simpleType>This is a simpleType in a complexType.</simpleType> <simpleType>Here's a long text line that shouldn't be wrapped in the CLF since the app will decide where to wrap it.</simpleType> </complexType> <simpleTypeWithParam param=0.5 /> <Array dim=\"3 4\"> 1.0 0.0 0.0 -0.3 0.0 1.0 0.0 -0.5 0.0 0.0 1.0 -0.5 </Array> </aTag> Use of XML Comments \u00b6 CLF authors should avoid using XML comments to encapsulate metadata or important information. Most parsers ignore comments, so if a CLF gets read and rewritten, comments that were previously there may go missing. Any important information should be enclosed in provided metadata XML elements and attributes (e.g., the ProcessList's Info element). Discrete Operations \u00b6 Finishing Tier products should, whenever possible, encapsulate discrete math operations with one or more ProcessNodes in a ProcessList rather than simply exporting a 1D- and/or 3D- LUT . For example, a common color space conversion should use discrete Log and Matrix nodes, where appropriate, rather than a single LUT3D . Precision and Range of Numeric Values \u00b6 Ensure your implementation writes a sufficient number of digits. Even though image processing will typically be done at 32-bit floating-point precision, intermediate calculations (for example, combining matrices) may be done at higher precision. Also, take note that the bit-depth attributes do not impose range or quantization limits. Hence you should not impose these limits unnecessarily. For example, for a LUT1D with an outBitDepth of 10i , the normal range would be expected to be 0 to 1023. However, it is legal to exceed this range and also to use fractional values. Thus, values such as [-10.5, 0.01, 1055.2] could be legal values. Please refer to Section 5.1 of the specification for more detail. The id Attribute \u00b6 Every CLF is required to have an id attribute at the ProcessList level. The specification does not impose any restrictions on the formatting of this attribute. However, it should be noted that an ACES Metadata File that references a CLF file prefers that the id attribute contains a UUID object according to RFC 4122. Therefore, it is recommended that implementations use a UUID to fill the id attribute when writing new CLF files. Note that the id attribute is optional at the ProcessNode level. Storage of Proprietary Metadata \u00b6 If an application wants to store \"dark metadata\" that is meaningful only for a special purpose within proprietary products or workflows, this is easily accomplished. Indeed this is one of the frequently cited benefits of the XML encoding. However, it is important that CLF writers are respectful of certain guidelines to ensure the CLF file remains usable by other readers. If you need to add proprietary metadata, please respect the following: Check the CLF spec to see if there is already an element whose purpose matches what you are trying to store. If not, you may create a custom XML element to store your metadata. As described in the spec, this should typically be placed within the Info block. You may add additional custom elements and attributes under your main element as needed in order to easily represent your information. Avoid using the standard existing elements such as Description in a way that is inconsistent with their purpose. Avoid placing custom elements at the ProcessNode level since that would make it an illegal file that most parsers will reject. Other Metadata Considerations \u00b6 Inaccurate metadata is worse than no metadata. Implementers should make it as regular and easy as possible for the user to set required CLF metadata when writing a file. Accurate metadata is critical for other users to be able to understand the intended usage of the CLF file, especially the Description , InputDescriptor , and OutputDescriptor tags. If known by the application, the application should fill in the InputDescriptor and OutputDescriptor tags automatically. At this time, no standard list of values (i.e., text strings) for color spaces or other common settings is defined. When writing a CLF to represent an ACES Look Transform, the CLF should adhere to the structure and metadata described in Annex F . If translating an ACES CTL (Color Transformation Language) file into CLF , set the ACESTransformID and ACESUserName (under the Info block of metadata) using the corresponding strings from the CTL header. [Examples 13] and [14] in [section 6] of the specification show CLFs using this feature. Helpful Hints for a Successful Implementation \u00b6 Matrix Order \u00b6 Take note that the order of coefficients in the Matrix ProcessNode follows the usual convention in color science but that this is the transposition of both the order sometimes used in computer graphics and the order used in CTL . [Section 4.4.4] of the specification clearly documents the ordering of matrix coefficients that must be used. Also, note that the 3x4 matrix includes an offset value after each of the three matrix values. LUT3D Serialization Order \u00b6 As described in [Section 4.4.3] of the CLF Specification, take note that the LUT3D ProcessNode serializes the LUT entries in blue-fastest order. This is a commonly used ordering (for example it is used by the common .3dl format) but some other formats use red-fastest ordering (e.g., .cube format). Gamma Polarity \u00b6 As described in [Section 4.4.7] of the spec, take note that the Exponent ProcessNode uses the specified parameter directly in the power function for the forward direction. This is the same usage as in an ASC CDL power. But take care since often \"gamma\" operators in color processing software apply the inverse of the power for the forward direction. Bit-Depth Attributes Don't Affect Processing Precision \u00b6 As called out in the CLF specification, the inBitDepth and outBitDepth attributes of ProcessNodes are not intended to control the processing precision, which should normally be 32-bit floating-point. Rather, these attributes simply determine the scaling of various parameter values such as matrix and LUT entries. Please refer to section 5.1 of the [ CLF specification] for the details. Conversion Between Bit-Depths \u00b6 When interpreting the inBitDepth and outBitDepth attributes, conversions happen using \"power of two minus 1\" scaling rather than \"power of 2\" scaling. Please refer to section 5.1.4 of the [ CLF Specification] for the details. Appendices \u00b6 Annex A: Test Image \u00b6 A 16-bit OpenEXR test image was designed with many ramps and other values which should be useful for testing any CLF and/or CLF implementation. The image includes: 33x33 cube spanning -1.0 to 1.0 33x33 cube spanning -65504 to 65504 an ACES2065-1 ColorChecker chart 0-1 grayscale ramps ColorChecker values and primaries/secondaries ramped in \u00bd stop increments a set of ramps designed to generate a spiderweb when viewed on a vectorscope extents lattice ramps designed to produce a bounding box around all possible normal positive and negative values when viewed in 3D Specific details for each of the image subsections can be found in the README at https://github.com/alexfry/CLFTestImage The test image (named CLF_Finishing_SourceImage_v008.exr ) is included along with the processed reference images in the download referenced in Annex C and D . Annex B: CLF Test Suite Listing \u00b6 These test files may be found in the OpenColorIO repository on GitHub: https://github.com/AcademySoftwareFoundation/OpenColorIO The files are in the sub-directory: OpenColorIO/tests/data/files/clf Note: Some of the test files intentionally use unusual or difficult syntax to give a thorough test for parsers. They are not all intended as \"best practice\" examples. Legal test files \u00b6 An implementation should be able to load and process these files successfully. Index Filename Ops tested Description Notes 0010 aces_to_video_with_look.clf Matrix, Log, CDL , Lut3D ACES2065-1 to ACEScct, CDL , then ACES Output Transform Interpolation=tetrahedral 0020 cdl_all_styles.clf CDL One ASC CDL of each style 0030 cdl_clamp_fwd.clf CDL Basic single CDL Has newlines in Slope element 0040 cdl_missing_sat.clf CDL Basic single CDL without SatNode 0050 cdl_missing_sop.clf CDL Basic single CDL without SOPNode 0060 cdl_missing_style.clf CDL Basic single CDL , relying on default style 0070 difficult_syntax.clf Matrix, Lut1D Legal file with lots of unusual formatting to stress parsers 0080 exponent_all_styles.clf Exponent, Range One Exponent of each style 0090 info_example.clf Matrix Info metadata element with app-specific elements 0100 inverseOf_id_test.clf Lut1D Example of inverseOf ProcessList attribute 0110 log_all_styles.clf Log, Range At least one Log op of each style and LogParams usage 0120 lut1d_32f_example.clf Lut1D Basic 65x1 32f/32f Lut1D Array is monotonic decreasing 0130 lut1d_comp.clf Lut1D Two Lut1D ops, 2x1 8i/8i and 32x3 8i/32f Channels of the 32x3 are unequal 0140 lut1d_example.clf Lut1D Basic 65x1 8i/12i Lut1D Array values exceed nominal 12i range and must not be clamped 0150 lut1d_half_domain_raw_half_set.clf Lut1D Lut1D 65536x1 16f/16f using halfDomain and rawHalfs 0160 lut1d_long.clf Lut1D Lut1D 131072x1 32f/16f Array contains occasional duplicate/quantized values 0170 lut3d_17x17x17_10i_12i.clf Lut3D Typical Lut3D 17x17x17 10i/12i No interpolation set (should use trilinear) 0180 lut3d_bizarre.clf Lut3D Unusual 3x3x3 10i/10i Lut3D, interpolation=tetrahedral Array values exceed nominal 10i range and must not be clamped 0190 lut3d_identity_12i_16f.clf Lut3D Basic identity 2x2x2 12i/16f Lut3D Interpolation=tetrahedral 0200 lut3d_preview_tier_test.clf Lut3D Typical Lut3D 33x33x33 32f/10i, tetrahedral This is the file used for the Preview-tier processing test. Values clamped to [4,1019]. 0210 matrix_3x4_example.clf Matrix Matrix 3x4 10i/12i, includes \"+\" and \"e-1\" in Array The 10i/12i depths requires normalizing the Array values by 1023/4095 0220 matrix_example_utf8.clf Matrix Matrix 3x3 32f/32f Matrix Description uses non-ASCII characters 0230 matrix_example.clf Matrix Matrix 3x3 32f/32f Uses the legal dim=\"3 3 3\" syntax allowed for CLF v2 compatibility 0240 matrix_no_newlines.clf Matrix Matrix 3x4 10i/10i, compact formatting with no newlines 0250 matrix_windows.clf Matrix Identity Matrix 3x3 16f/12i, Windows line-endings Per section 3.2.6 of the spec, Linux newlines should be used. But for maximum robustness, ideally other line-endings should be tolerated 0260 multiple_ops.clf All ops Tests at least one of all ops 0270 range_test1_clamp.clf Range Range 8i/32f with Clamp style The 8i minIn/maxIn values require normalizing by 1/255 0280 range_test1_noclamp.clf Range Range 8i/32f with noClamp style 0290 range_test2.clf Range Range 32f/16f, minValue only, with Clamp style 0300 range.clf Range Range 16i/16i, relying on default style (Clamp) The 16i values require normalizing by 1/65535 0310 tabulation_support.clf Lut3D Lut3D 3x3x3 10i/10i, interpolation=tetrahedral The Array RGB values are only separated by tabs 0320 xyz_to_rgb.clf Matrix, Range, Lut1D Matrix 3x3 32f/32f, Range, and Lut1D 128x3 32f/32f The Lut1D Array columns are unequal Illegal test files \u00b6 These files should not load successfully and the implementation should indicate that it is not a legal file. The files are in the directory: OpenColorIO/tests/data/files/clf/illegal Index Filename Ops tested Description Notes 0010 array_bad_dimension.clf Matrix Array dim attribute has 10 numbers 0020 array_bad_value.clf Matrix Array has \"P\" for the 4th value rather than a number 0030 array_missing_values.clf Matrix Array has 3 values instead of 9 0040 array_too_many_values.clf Matrix Array has 18 values instead of 9 0050 cdl_bad_power.clf CDL One of the power values is 0 0060 cdl_bad_sat.clf CDL Saturation has 2 values instead of 1 0070 cdl_bad_slope.clf CDL Slope has 2 values rather than 3 0080 cdl_bad_style.clf CDL Style is \"invalid_cdl_style\" 0090 cdl_missing_offset.clf CDL The SOPNode is missing the Offset element 0100 cdl_missing_power.clf CDL The SOPNode is missing the Power element 0110 cdl_missing_slope.clf CDL The SOPNode is missing the Slope element 0120 exponent_bad_param.clf Exponent The basicFwd style may not use the offset attribute 0130 exponent_bad_value.clf Exponent The monCurveFwd style requires exponent to be >= 1 0140 image_png.clf None File is a binary PNG image, not actually a CLF file 0150 indexMap_test2.clf Lut3D The IndexMap element is no longer allowed in CLF v3 0160 log_bad_param.clf Log The linToLog style may not contain the linSideBreak parameter 0170 log_bad_style.clf Log Style is \"invalidStyle\" 0180 log_bad_version.clf Log The compCLFversion = 2.0, Log was introduced in v3 0190 log_missing_breakpnt.clf Log The cameraLogToLin style must have the linSideBreak parameter 0200 lut1d_half_domain_missing_values.clf Lut1D A half-domain LUT must have 65536 values 0210 lut1d_half_domain_set_false.clf Lut1D The halfDomain attribute may only have the value \"true\" 0220 lut1d_raw_half_set_false.clf Lut1D The rawHalfs attribute may only have the value \"true\" 0230 lut3d_unequal_size.clf Lut3D The Array dimension is 2x2x3x3 0240 matrix_end_missing.clf Matrix There is no element 0250 process_list_bad_version.clf Matrix The compCLFversion = \"three\" 0260 process_list_higher_version.clf Matrix The compCLFversion = \"3.2\" 0270 process_list_missing.clf Matrix The ProcessList element is missing 0280 range_bad_noclamp.clf Range The noClamp style must have both min and max values 0290 range_bad_values.clf Range The minInValue must be less than the maxInValue 0300 range_empty.clf Range The Range element must have at least min or max values 0310 range_nonmatching_clamp.clf Range A one-sided Range must use the same normalized value for in and out Because the bit-depths differ, the values are not actually the same 0320 transform_bad_outdepth.clf Matrix The outBitDepth is \"16d\" 0330 transform_bitdepth_mismatch.clf Matrix, Lut1D The inBitDepth does not match the previous outBitDepth Also missing the XML header (though this is legal) 0340 transform_corrupted_tag.clf Matrix The closing ProcessList element is incorrect 0350 transform_element_end_missing.clf Matrix The closing ProcessList element is missing 0360 transform_empty.clf None The ProcessList must have at least one ProcessNode operator 0370 transform_id_empty.clf Log The ProcessList id attribute must not be empty 0380 transform_missing_id.clf Log The ProcessList id attribute must be present 0390 transform_missing_inbitdepth.clf Lut1D The inBitDepth attribute is missing 0400 transform_missing_outbitdepth.clf Lu1D The outBitDepth attribute is missing 0410 transform_missing.clf None There is nothing except the XML header 0420 unknown_elements.clf Matrix, Lut1D, Lut3D The ProcessList contains unknown elements outside the Info element Annex C: Finishing Tier Apply Test CLF List \u00b6 The list of CLF files for the Finishing Tier apply test is the complete list of legal files in Annex B . Processed reference images may be downloaded from here: CLF Apply Test Images Annex D: Preview Tier Apply Test CLF List \u00b6 The CLF file for the Preview Tier apply test is simply: lut3d_preview_tier_test.clf Processed reference images may be downloaded from here: CLF Apply Test Images Annex E: Baking a CLF for Preview Tier Implementation \u00b6 Because CLF allows a fairly powerful set of processing operators that may be assembled into pipelines of any ordering and any length, it will not be possible to exactly evaluate all CLFs on hardware or software that has a fixed processing pipeline. (In other words, the implementation must allow the CLF file itself to specify the pipeline of operators for a given color transform.) Converting color transforms into a simpler structure to make them simpler to evaluate is known as baking . This is often done to meet the needs of a particular hardware implementation. There are a number of factors that make the process of accurately baking color transforms a difficult and complicated subject: CLF is intended to support the needs of floating-point scene-linear color spaces and therefore the range of possible input and output values extends from very small to very large numbers (both positive and negative). A given CLF may expect virtually any color space (scene-linear, camera log, video, etc.) on input and another completely different space on output. The flexible nature of CLF and the way a chain of operators is built up makes it fairly easy for the function to have abrupt changes in slope. For example, at the edge of a gamut boundary, or due to a conversion into an internal working space for a look transform. These slope changes are usually not captured accurately when the transform is baked. The human visual system is often able to detect fairly small errors in color reproduction, particularly in dark colors. All of that said, there are many successful products that have used a baking process. For example, this technique is often used in products designed for on-set production monitoring involving look transforms. So it is highly likely that baking of CLFs could be a successful strategy for Preview Tier products. The key will be to clearly document the types of color transforms that may be successfully baked and those that the user should avoid. Integer-based implementations in the Preview Tier will typically be processing video or logarithmic color space encodings. So for example, if the documentation suggests avoiding use of CLFs expecting scene-linear color spaces on input, that is probably fine since (hopefully!) no one will be trying to send raw scene-linear values through an integer connection such as SDI video. The accuracy of the baking process may be judged by sending images through both the original CLF and the baked CLF and comparing them. OpenColorIO or any product that passes the Finishing Tier tests could be used for this type of comparison. But keep in mind that the result will depend on many factors, including the input and output color spaces and the internal structure of the original CLF . So even though one CLF may bake accurately through a given baking process, it certainly does not mean that all of them will. Testing with a range of user transforms is essential. OpenColorIO may be used to experiment with baking CLFs using the command-line tool ociobakelut . For example, here is a command that takes an original CLF named complicated.clf and bakes it into a single LUT3D with a cube dimension of 33x33x33 called simple.clf : $ ociobakelut --lut complicated.clf --cubesize 33 --format \"Academy/ASC Common LUT Format\" --v simple.clf You may edit the resulting CLF XML file in a text editor to add the interpolation=\"tetrahedral\" attribute to the LUT3D and any desired metadata. For CLFs that convert from one perceptually uniform color space to another (i.e., between most logarithmic and video color spaces), this will often be reasonably accurate for Preview Tier devices. Increasing the cube size will improve accuracy (the default cubesize is 64x64x64). However, this would not work well for baking a CLF that expects a scene-linear color space on input. In those situations, the usual technique is to add some kind of a \"shaper\" LUT1D or other non-linear transform in front of the LUT3D that will convert the linear values into something more perceptually uniform. A more modern and compact technique that takes advantage of the CLF capabilities would be to insert a Log ProcessNode rather than a LUT1D , but the most appropriate technique would be based on the needs of the given implementation. The ociobakelut tool is able to bake with shaper LUTs , but it requires an OCIO config file to define the input, output, and shaper spaces. But for the use-case here, the input is just a single CLF file, so there is no OCIO config file to use. OpenColorIO could still be used to do these more advanced types of baking, but it would require some scripting. One approach would be to create a config file that references the original CLF as a file transform and includes an appropriate shaper space. Another approach would be to just use the OCIO API directly to write your own baking tool, using the ociobakelut code for inspiration. (And if so, we encourage you to contribute it back to the OCIO project!) The ociobakelut command supports many arguments; use the -h argument for a summary. For example, note that you may supply many --lut arguments on the command line and they will all be baked together into the result. You may also consult the Baking LUT \u2019s section of the OCIO documentation for a tutorial on using ociobakelut . Annex F: Using CLF to represent ACES Look Transforms \u00b6 Historically, look workflows have been based on applying a look in some kind of logarithmic color space, for example, a camera log space. This is partly because the existing infrastructure was built for integer pixel formats and did not support floating-point pixel formats. (The Preview Tier described above is an attempt to define requirements for these integer-based devices.) And until CLF , previous LUT formats did not support scene-linear color spaces well. However, the input values and output values of ACES Look Transforms (also known as \"LMTs\") must be ACES2065-1. This is to maintain universality of Look Transforms and not link them to project-specific working spaces. Look Transforms may then convert ACES2065-1 to some other working space internally (e.g., a camera log space) for look application. This is the vision for the future and the ACES Metadata File ( AMF ) format expects implementations to work this way. As an aside, it is recommended that the InputDescriptor and OutputDescriptor be set to ACES2065-1 when authoring Look Transforms as CLFs so it is always clear what the expected input and output color spaces are. The Description tag and other metadata may also be used to provide a more complete description of the look. When look operations are to be performed in a working space other than ACES2065-1, then appropriate conversions to and from the required working space can be prepended and appended within a CLF to communicate the transform. For accuracy, whenever possible, these conversions should be implemented using discrete operations such as Log and Matrix ProcessNodes rather than LUT1D or LUT3D . By using ProcessNodes such as Log and Matrix , a CLF author makes it easier for an implementation to detect and remove any unnecessary conversions when applying the CLF . For example, OpenColorIO will do this when optimizing transform chains. The OCIO tool ociomakeclf can create an ACES Look Transform by prepending and appending the appropriate color space conversions to an existing look LUT file. For example, if an existing look LUT expects ACEScct input and outputs ACEScct, the --csc ACEScct option will add appropriate conversions from ACES2065-1 to ACEScct at the beginning and from ACEScct back to ACES2065-1 at the end. Example: Convert the look CDL cdl_test2.cc that expects and produces ACEScct values to an ACES Look Transform in CLF format that expects and produces ACES2065-1 values: $ ociomakeclf OpenColorIO/tests/data/files/cdl_test2.cc LMT.clf --csc ACEScct This generates the following CLF : <?xml version=\"1.0\" encoding=\"UTF-8\"?> <ProcessList compCLFversion= \"3\" id= \"669980ac1ecd97ab18c1707250a13d20\" > <!-- Header metadata --> <Description> ACES LMT transform built from a look LUT expecting color space: ACEScct </Description> <Description> Original LUT name: OpenColorIO/tests/data/files/cdl_test2.cc </Description> <InputDescriptor> ACES2065-1 </InputDescriptor> <OutputDescriptor> ACES2065-1 </OutputDescriptor> <!-- Convert from ACES2065-1 to ACEScct --> <Matrix inBitDepth= \"32f\" outBitDepth= \"32f\" > <Array dim= \"3 3\" > 1.45143931614567 -0.23651074689374 -0.214928569251925 -0.0765537733960206 1.17622969983357 -0.0996759264375522 0.00831614842569772 -0.00603244979102103 0.997716301365323 </Array> </Matrix> <Log inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"cameraLinToLog\" > <LogParams base= \"2\" linSideSlope= \"1\" linSideOffset= \"0\" logSideSlope= \"0.0570776255707763\" logSideOffset= \"0.554794520547945\" linSideBreak= \"0.0078125\" /> </Log> <!-- Apply the user's CDL look in the ACEScct working space --> <ASC_CDL id= \"cc0001\" inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"FwdNoClamp\" > <SOPNode> <Slope> 1.0 1.0 0.9 </Slope> <Offset> -0.03 -0.02 0.0 </Offset> <Power> 1.25 1.0 1.0 </Power> </SOPNode> <SatNode> <Saturation> 1.7 </Saturation> </SatNode> </ASC_CDL> <!-- Convert from ACEScct back to ACES2065-1 --> <Log inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"cameraLogToLin\" > <LogParams base= \"2\" linSideSlope= \"1\" linSideOffset= \"0\" logSideSlope= \"0.0570776255707763\" logSideOffset= \"0.554794520547945\" linSideBreak= \"0.0078125\" /> </Log> <Matrix inBitDepth= \"32f\" outBitDepth= \"32f\" > <Array dim= \"3 3\" > 0.695452241357452 0.140678696470294 0.163869062172254 0.0447945633720377 0.859671118456422 0.0955343181715404 -0.00552588255811354 0.00402521030597866 1.00150067225213 </Array> </Matrix> </ProcessList> Note that an ACES Look Transform is usually just one component in a larger pipeline of transforms. For example, Preview Tier implementations involving on-set LUT boxes will typically incorporate the Look Transform into a chain of transforms that expect a camera log color space on input and produce a video color space on output. As noted above, the use of explicit Log and Matrix ProcessNodes in a CLF transform allows an implementation to detect unnecessary operations. For example, if an ACES Input Transform were added in front of an ACES Look Transform that begins with the inverse of that Input Transform, the redundant operations could be optimized out for efficiency. Though in some implementations, this will all be baked into a single LUT3D , making such optimizations less necessary. Annex G: Using CLF with AMF \u00b6 The ACES Metadata File ( AMF ) is a \"sidecar\" XML file designed to encapsulate the metadata required to recreate ACES viewing pipelines. An AMF can carry references to one or more CLF files as external ACES Look Transform files. When using a CLF file for ACES applications and especially when in conjunction with AMF , it is recommended that the CLF id attribute of the ProcessList be populated with a uuid . Multiple CLFs can be included by using multiple lookTransform elements in the AMF file. The CLFs are applied in the order in which they appear in the AMF . See the AMF Handbook for more details. Annex H: Identity (no-op) CLF example \u00b6 To avoid doubt in cases where CLF files are exchanged as \u201csidecar\u201d files to batches of media, it may be desirable to use a standard CLF form even when no transform or color modification has been assigned to certain media clips / files. In these cases it may be useful that a \u201cNo-Op\u201d CLF file be included as the associated sidecar file to communicate to downstream users that no transform is assigned. This may be preferred to not providing a sidecar CLF file, as the absence of CLF files for a subset of a larger media batch often raises questions in certain workflows about whether an expected file is missing. For this situation, implementers may generate a minimal CLF file like that shown below, where the ProcessList has a single ProcessNode of the Matrix type with a 3x3 identity matrix. (Implementers do not need to copy this exactly, for example there are other operators that also give an identity and details like the id string will differ.) <?xml version=\"1.0\" encoding=\"UTF-8\"?> <ProcessList id= \"37efa85b-5bc8-40dc-8ffe-b488a3c013ea\" name= \"No-Op\" compCLFversion= \"3.0\" > <Description> No-Op CLF </Description> <Matrix name= \"identity matrix\" inBitDepth= \"32f\" outBitDepth= \"32f\" > <Array dim= \"3 3\" > 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 </Array> </Matrix> </ProcessList> Annex I: Infinity and NaN handling \u00b6 The CLFs used for the apply tests were specially chosen to avoid floating-point overflows that could turn pixels in the test target image into infinity or NaN. However, with other CLFs, the comparison script described in the other sections may fail if the resulting images have infinity or NaN pixels. The handling of infinity and NaN is challenging in a number of regards. For example: There is not always consensus on what the ideal behavior is. For example, should overflows be clamped to a large finite value or allowed to produce an infinity. There are sometimes performance penalties to be extra rigorous about the handling which are not always warranted. The handling on GPUs tends to vary a lot and often does not match the CPU (where there are clearer specs for what is supposed to happen). Once these values get into a chain of color processing, there can be somewhat unexpected results. For example, (Inf \u2013 Inf) is NaN, likewise, (0 x Inf) is NaN, so quite often an infinity going into a matrix or other operator that mixes the channels results in NaNs coming out. Due to issues such as these, neither the Academy reference CTL for ACES transforms nor OpenColorIO have ideal behavior with respect to the handling of floating-point infinity and NaN. We expect this is true of most other practical implementations and so this initial version of the Implementation Guide does not attempt to validate handling of these values. Annex J: Python code for creating the Preview Tier test LUT \u00b6 Here is some Python code that uses OCIO to create the test LUT for the Preview Tier. # This script builds the file for the Preview Tier test from the CLF test suite. import PyOpenColorIO as ocio import numpy as np v = np . linspace ( 0 , 1 , 33 ) # v = # array([ 0. , 0.03125, 0.0625 , 0.09375, 0.125 , 0.15625, # 0.1875 , 0.21875, 0.25 , 0.28125, 0.3125 , 0.34375, # 0.375 , 0.40625, 0.4375 , 0.46875, 0.5 , 0.53125, # 0.5625 , 0.59375, 0.625 , 0.65625, 0.6875 , 0.71875, # 0.75 , 0.78125, 0.8125 , 0.84375, 0.875 , 0.90625, # 0.9375 , 0.96875, 1. ]) # Convert the vector into the values for a Lut3D. Uses blue-fastest order. a1 , a2 , a3 = np . meshgrid ( v , v , v ) gr = np . column_stack (( a2 . ravel (), a1 . ravel (), a3 . ravel ())) # At this point, gr is a 35937 x 3 array with min=0 and max=1. # Build transforms to convert from ACEScct to Rec.709 using an ACES Output Transform. bt1 = ocio . BuiltinTransform ( style = 'ACEScct_to_ACES2065-1' ) bt2 = ocio . BuiltinTransform ( style = 'ACES-OUTPUT - ACES2065-1_to_CIE-XYZ-D65 - SDR-VIDEO_1.0' ) bt3 = ocio . BuiltinTransform ( style = 'DISPLAY - CIE-XYZ-D65_to_REC.1886-REC.709' ) dvt = ocio . GroupTransform ( [ bt1 , bt2 , bt3 ] ) # Set up an OCIO Processor and process the values. config = ocio . Config . CreateRaw () proc = config . getProcessor ( dvt ) cpu = proc . getDefaultCPUProcessor () tmp = gr . astype ( np . float32 ) cpu . applyRGB ( tmp ) # replaces tmp with output # For this example, the goal was to quantize to 10-bits and clamp to [4,1019] # since hardware involving SDI video may not be able to process these values. vals = np . round ( tmp * 1023 ) # vals[0:10,:] = # array([[ 0., 0., 0.], # [ 0., 0., 0.], # [ 0., 0., 0.], # [ 0., 0., 0.], # [ 0., 0., 35.], # [ 0., 0., 52.], # [ 0., 0., 68.], # [ 0., 0., 88.], # [ 0., 0., 114.], # [ 0., 0., 148.]], dtype=float32) vals2 = vals . clip ( 4 , 1019 ) # Now renormalize to [0,1], vectorize, and set the data into a Lut3D. vals2 = vals2 / 1023. lut = ocio . Lut3DTransform () lut . setData ( vals2 . ravel ()) # Set some LUT attributes. lut . setFileOutputBitDepth ( ocio . BIT_DEPTH_UINT10 ) lut . setInterpolation ( ocio . INTERP_TETRAHEDRAL ) fmd = lut . getFormatMetadata () fmd . addChildElement ( 'Description' , 'This LUT is an ACEScct to Rec.709 Output Transform, clamped to [4,1019]' ) # print(lut) # <Lut3DTransform direction=forward, fileoutdepth=10ui, interpolation=tetrahedral, # gridSize=33, minrgb=[0.00391007 0.00391007 0.00391007], maxrgb=[0.99609 0.99609 # 0.99609]> # Add the LUT to a GroupTransform, set the metadata and write. grp = ocio . GroupTransform () grp . appendTransform ( lut ) fmdg = grp . getFormatMetadata () fmdg . setID ( '00001' ) fmdg . setName ( 'Preview-tier Lut3D test' ) fmdg . addChildElement ( 'Description' , 'Test LUT for Preview-tier CLF validation test suite' ) fmdg . addChildElement ( 'InputDescriptor' , 'ACEScct' ) fmdg . addChildElement ( 'OutputDescriptor' , 'Rec.1886 / Rec.709 video' ) # print(grp) # <GroupTransform direction=forward, transforms= # <Lut3DTransform direction=forward, fileoutdepth=10ui, interpolation=tetrahedral, # gridSize=33, minrgb=[0.00391007 0.00391007 0.00391007], # maxrgb=[0.99609 0.99609 0.99609]>> grp . write ( formatName = 'Academy/ASC Common LUT Format' , config = config , fileName = '/tmp/lut3d_preview_tier_test.clf' ) Annex K: Generation of the reference images \u00b6 The processed reference images may be downloaded from the URL provided in Annex C and D above. This section documents how those images were generated. Finishing Tier Reference Images \u00b6 Since OpenColorIO is an actively maintained open source implementation of CLF , it has been used to generate the processed reference images. There is a Python script in the OCIO repository that may be run to generate these images. The script is run as follows (these steps assume a Linux or Mac platform but could also be done on Windows): Install OpenImageIO Install OpenColorIO from source, following the instructions in the OCIO documentation available from opencolorio.org. Given that OIIO was installed in step 1, this should build the ocioconvert command-line tool, which is needed by the Python script. In a shell, cd to the directory where OpenColorIO was installed and then cd into the sub-directory share/clf. This directory contains the Python script as well as a copy of the source target image described in Annex A . In the shell, type: $ python process_clf_test_frames.py <OUTPUT-DIR> replacing <OUTPUT-DIR> with a directory that you want to write the images to. (There are also some other optional arguments that are described if you run the script with just a \"-h\" option, but these are not necessary to generate the reference image set.) Preview Tier Source Image \u00b6 The Preview Tier test uses an integer source image in DPX format. That image was generated from the main Finishing Tier floating-point source image by applying a conversion from ACES2065-1 to ACEScct. It may be generated using the command-line tool oiiotool that is included with OpenImageIO using the following steps (these steps assume a Linux or Mac platform but could also be done on Windows): Install a recent version of OpenImageIO and oiiotool , compiled with OpenColorIO support. Download the OpenColorIO source code, which contains an OCIO config file to use with oiiotool . In a shell, cd to the directory where OpenColorIO was installed and then cd into the sub-directory share/clf . This directory contains a copy of the source target image described in Annex A . Set the OCIO environment variable to point to the following config file in the OCIO repository: docs/configurations/ocio-v2_demo.ocio Run the command: $ oiiotool CLF_Finishing_SourceImage_v008.exr --colorconvert ACES2065-1 ACEScct -d uint10 -o CLF_Preview_SourceImage_v008.dpx Preview Tier Reference Image \u00b6 The Preview Tier reference image may then be generated as follows: Follow steps 1-5 in the previous section. At this point the current directory will be the share/clf sub-directory of the OpenColorIO source code. Run the command: $ oiiotool CLF_Preview_SourceImage_v008.dpx --ociofiletransform ../../tests/data/files/clf/lut3d_preview_tier_test.clf -d uint10 -o lut3d_preview_tier_test.dpx","title":"Common LUT Format (CLF) Implementation Guide"},{"location":"guides/clf/#common-lut-format-clf-implementation-guide","text":"","title":"Common LUT Format (CLF) Implementation Guide"},{"location":"guides/clf/#introduction","text":"Look-up tables, or LUTs , are a common method for communicating color transformations. Many software and hardware providers develop LUT formats uniquely designed for use in their systems. Since these formats were designed to work in specific use cases, they often prove inadequate for interchangeability between applications or systems. To further complicate matters, some LUT formats use the same file extensions which make them appear to be compatible when they are not. If there are already a dozen or more confusing LUT formats, why should you as a developer consider adding support for yet another one? While the myriad LUT formats already available are fundamentally useful in theory, each lacks one or more features that can be critical in meeting the demands of today\u2019s sophisticated workflows. Existing formats can lack the quality, versatility, and metadata required to meet the demands of modern systems. The Common LUT Format ( CLF ) provides flexibility to enclose transforms from simple to complex. Due to a lack of interchangeability of color transforms between tools, LUTs are frequently abused as a catch-all. Even simple color-space transformations, such as the application of a matrix or a logarithmic shaper function are often \u201cbaked\u201d to crude LUT formats resulting in unfortunate losses in precision. As a solution, CLF allows for a range of common mathematical operators to be specified precisely, in addition to supporting traditional 1D- and 3D- LUTs in the file. Because CLF files are floating-point capable, extremely flexible, and well documented, they are an excellent candidate for use in modern workflows. CLFs are also ideal for archival purposes because the format is well-specified and documented. There is also a high-quality, open source implementation freely available on GitHub.","title":"Introduction"},{"location":"guides/clf/#format-comparison-table","text":"Features/Formats CLF 3dl Adobe (Iridas) cube Resolve cube Truelight cube Cinespace cube ASC CDL Imageworks spi3d ICC Profile Provider Academy / ASC Discreet Adobe Blackmagic Filmlight Rising Sun ASC Imageworks ICC Maintained public documentation \u2705 \u274c \u2705 \u2705 \u2705 \u274c \u2705 \u274c \u2705 Implementation guide \u2705 \u274c \u274c \u274c \u274c \u274c \u2705 \u274c \u2705 Allows shaper LUT \u2705 \u274c \u274c \u2705 \u2705 \u2705 \u274c \u274c \u2705 Is not limited to log or video data on input \u2705 \u274c \u274c \u2705 \u2705 \u2705 \u274c \u274c \u274c Unconstrained ordering of processing elements \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u274c Floating-point table values \u2705 \u274c \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 Rich metadata \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u2705 Test suite provided \u2705 \u274c \u274c \u274c \u274c \u274c \u2705 \u274c \u2705 Text-based \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u274c Can define operations in linear floating-point space \u2705 \u274c \u274c \u274c \u274c \u274c \u2705 \u274c \u2705 GUID support \u2705 \u274c \u274c \u274c \u274c \u274c \u2705 \u274c \u2705 Supports mathematical operators \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u274c","title":"Format Comparison Table"},{"location":"guides/clf/#target-audience","text":"This document is primarily intended for application developers who want to add CLF support to their product. It defines requirements, tests, and provides recommendations that, if followed, will lead to robust support for CLF . Implementers who follow the guidance in this document can have confidence that their product is implementing the specification correctly. The document may also be of interest to those using CLF to author transforms and who want to understand how the CLFs will be used by applications. This guide should be read in conjunction with the CLF specification (v 3.0). The CLF spec may be downloaded from: http://j.mp/S-2014-006 . Note: Although the spec has \"2014\" in the name, the document has been updated more recently than that. Version 3 of CLF was introduced with the release of ACES 1.2 in 2020 and the most recent editorial updates were in 2021.","title":"Target Audience"},{"location":"guides/clf/#a-quick-introduction-to-clf","text":"Below is a basic example of a simple CLF file. Despite the word ' LUT ' in the name of the format, these very simple examples do not contain any type of LUT whatsoever. Instead, the CLF is being used to communicate a set of ASC CDL adjustments ( Example 1 ), and encapsulate a YCbCr to RGB conversion ( Example 2 ). There are a few key points that these examples demonstrate: CLF is an XML document and therefore conforms to the requirements of any XML document. There is one ProcessList , which can contain any number of ProcessNodes . (A ProcessNode is an operator such as a Matrix or LUT3D .) A CLF may or may not contain \u201c LUTs \u201d (despite the name). Some parts are optional and others are required. CLF provides a richer metadata model than other LUT formats - it\u2019s not just numbers. Good metadata is highly encouraged and helps make the CLF file self-documenting. Every CLF must have a unique id attribute. The bit-depth attributes control formatting but not precision. Color coding: red is required, blue is optional, green are comments.","title":"A Quick Introduction to CLF"},{"location":"guides/clf/#open-source-example-implemention","text":"As you explore CLF and work to implement it into your product(s), it may be helpful to refer to some existing tools that already provide full CLF functionality. The tools described here are included in the open source project OpenColorIO ( OCIO ) v2. More details and the full installation process for OCIO can be found at https://www.opencolorio.org .","title":"Open Source Example Implemention"},{"location":"guides/clf/#ociochecklut","text":"The command-line utility ociochecklut can be used to load a CLF file and process an RGB triplet through the CLF file. It will report any errors that are encountered in parsing the file. If no RGB triplet is provided to process through the CLF file, then a list of the ProcessNodes contained in the LUT are returned. This tool is installed as part of OCIO v2. Here is sample output using the CLF in the example section (assuming it is saved as a file called 709_ycbcr-to-rgb.clf ): Summarizing the contents of the CLF : $ ociochecklut 709_ycbcr-to-rgb.clf Transform operators: <MatrixTransform direction=forward, fileindepth=32f, fileoutdepth=32f, matrix=1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1, offset=-0.0625 -0.5 -0.5 0> <MatrixTransform direction=forward, fileindepth=32f, fileoutdepth=32f, matrix=1.16893193493151 0 1.79974396623884 0 1.16893193493151 -0.214081616673236 -0.534991005624129 0 1.16893193493151 2.12065335518973 -0 0 0 0 0 1, offset=0 0 0 0> Evaluating the RGB value [0.5, 0.4, 0.3]: $ ociochecklut 709_ycbcr-to-rgb.clf 0.5 0.4 0.3 0.1514589 0.6398141 0.2993424","title":"ociochecklut"},{"location":"guides/clf/#ocioconvert","text":"The command-line utility ocioconvert can be used to apply a CLF file to an image. To apply a CLF file, use the --lut option. A variety of image file formats are supported. This tool is installed as a part of OCIO v2, although it first requires installation of OpenImageIO. Processing the input image syntheticChart.01.exr to the output image output_image.exr through the CLF from the previous example: $ ocioconvert --lut 709_ycbcr-to-rgb.clf syntheticChart.01.exr output_image.exr","title":"ocioconvert"},{"location":"guides/clf/#ociomakeclf","text":"The command-line utility ociomakeclf will convert any LUT format supported by OpenColorIO into CLF format. The --csc option may be used to create an ACES Look Transform that is compatible with the ACES Metadata File ( AMF ). This tool is installed as a part of OCIO v2. Convert the LUT oldLUT.3dl to CLF format: $ ociomakeclf oldLUT.3dl oldLUT.clf Convert the look LUT acescctLUT.3dl that expects and produces ACEScct values to an ACES Look Transform in CLF format that expects and produces ACES2065-1 values: $ ociomakeclf acescctLUT.3dl LMT.clf --csc ACEScct","title":"ociomakeclf"},{"location":"guides/clf/#minimum-requirements","text":"","title":"Minimum Requirements"},{"location":"guides/clf/#introduction_1","text":"The products anticipated to implement CLF can be categorized into two broad categories: one for final production-level finished images and one for preview/proxy images. Due to the fundamental differences in the products, different requirements are provided for the two categories.","title":"Introduction"},{"location":"guides/clf/#finishing-tier","text":"The primary category of products, dubbed the Finishing Tier , includes software implementations that have the logic and processing power available to parse and apply ProcessNode operations using floating-point calculations and in sequential order. Finishing Tier products provide the highest quality image processing and have the tightest tolerances, prioritizing accuracy in computation results. Finishing Tier products should be used to create images when the highest image fidelity is required in pipelines utilizing CLF files.","title":"Finishing Tier"},{"location":"guides/clf/#preview-tier","text":"The second category of implementations are described as Preview Tier devices. These are products that, due to limited processing power or technical constraints, cannot implement a CLF ProcessList exactly and instead require that CLF files be \u201dbaked\u201d or collapsed into a simpler representation (for example, a single 3D- LUT ). Hardware devices such as on-set LUT boxes would be an example of devices that might fall into this category. As the name implies, Preview Tier products are suitable for creating images such as for on-set viewing, where the requirements for accuracy and/or flexibility are lower than for the Finishing Tier. CLF is designed as a modern LUT format that can handle floating-point input and output pixels. However, the current ecosystem of devices still includes many products that work primarily on integer-encoded signals (e.g. HD-SDI and HDMI video) and do not support floating-point image data, including scene-linear encodings such as ACES2065-1. These types of devices would fall in the Preview Tier and CLF may be used to encapsulate any of the LUTs that are currently used in such devices. But there is no expectation that these devices will be able to accurately process other CLFs that contain transforms expecting scene-linear inputs or outputs. Note that although the processing requirements are lower for the Preview Tier, the read requirements are not. In other words, even Preview Tier devices must be able to read all of the files in the test suite. But as described in the section \" Applying CLFs \", if a Preview Tier device detects ProcessNodes that it does not support, there are two options: Inform the user of this situation and do not attempt to process the file. Attempt to bake the CLF down into a representation supported by the device. The user should be given some indication that they are seeing an approximation of the original CLF .","title":"Preview Tier"},{"location":"guides/clf/#reading-clfs","text":"This section describes the general requirements for parsing CLF files, the provided test suite, and the steps for validating an implementation using the test suite.","title":"Reading CLFs"},{"location":"guides/clf/#general-parsing-requirements","text":"","title":"General Parsing Requirements"},{"location":"guides/clf/#clf-file-test-suite","text":"A number of test files are provided for implementers to test their system and demonstrate that their implementation can robustly handle all features of CLF v3. The tests provided in the OpenColorIO repository on Github include both legal and illegal test files. The file name and description in each file identifies what the file is testing. The test files confirm that each ProcessNode is functioning per the specification. For ProcessNodes that allow for different styles or parameters, either separate test files or single test files with multiple ProcessNode variations are provided to check that all styles and parameters are functional. Standard files are expected to be processed without error. A number of \"illegal\" test files with various syntax errors are also provided to test the error handling capability of implementations. Illegal files should not be processed and the system should generate an appropriate error message.","title":"CLF File Test Suite"},{"location":"guides/clf/#test-procedure","text":"Download the OpenColorIO repository from GitHub at the URL: https://github.com/AcademySoftwareFoundation/OpenColorIO If you are not familiar with Git, that\u2019s fine. Simply click on the green button that says Code and select \u201cDownload ZIP\u201d. Unzip this file on your computer and you will have all of the test files. The test files are in the directory: OpenColorIO/tests/data/files/clf You may refer to a description of each test file in Annex B . For each legal test file: Read the file into your product and verify that it loads successfully. For each illegal test file (these are the files in the clf/illegal subdirectory): Read the file into your product and ensure that the user is notified that it is not a legal CLF file. Ideally, the nature of the problem should be communicated to the user. Verify that none of these files load successfully. They should not result in a processed image. If an implementation needs to pass through the unprocessed image, it should communicate clearly to the user in some other way that there was an error.","title":"Test Procedure"},{"location":"guides/clf/#applying","text":"","title":"Applying CLFs"},{"location":"guides/clf/#general","text":"For CLF to be useful, it is important that different products output the same results when applying the same CLF to the same input. This section describes the different expectations for Finishing Tier and Preview Tier products. Each category has their own metric and defined tolerances.","title":"General"},{"location":"guides/clf/#finishing-tier_1","text":"","title":"Finishing Tier"},{"location":"guides/clf/#preview-tier_1","text":"","title":"Preview Tier"},{"location":"guides/clf/#writing","text":"Not all products must support writing CLFs, depending on the way they are used. If your product supports the writing of CLF files, it must adhere to the CLF specification. Some important highlights and recommendations for implementation default behavior, or for users authoring CLFs by hand, are described in the following sections.","title":"Writing CLFs"},{"location":"guides/clf/#file-extension","text":"The extension used for CLF files should be a .clf at the end of the file name.","title":"File Extension"},{"location":"guides/clf/#indentation","text":"CLF files may be opened and read by users during troubleshooting, so readability is desirable. In particular, the following formatting is recommended for indentation: Use 2-4 spaces to indent relative to a parent item. A new indented line should be used after the starting element tag for complex XML types. For compactness, simple XML types may be placed on a single line. Arrays (contained in Matrix , LUT1D , LUT3D ) should use line breaks to present data visually (e.g., by aligning columns of R, G, B). Large blocks of lines of numbers do not need to be indented since they are already visually distinct and there is no point adding spaces in front of thousands of lines (e.g., in the case of large LUTs ). Long text strings (e.g. in a Description tag) should not contain embedded wrapping and indentation. It is better to let the application software determine where to wrap long lines of text in order to present them best in its own user interface.","title":"Indentation"},{"location":"guides/clf/#use-of-xml-comments","text":"CLF authors should avoid using XML comments to encapsulate metadata or important information. Most parsers ignore comments, so if a CLF gets read and rewritten, comments that were previously there may go missing. Any important information should be enclosed in provided metadata XML elements and attributes (e.g., the ProcessList's Info element).","title":"Use of XML Comments"},{"location":"guides/clf/#discrete-operations","text":"Finishing Tier products should, whenever possible, encapsulate discrete math operations with one or more ProcessNodes in a ProcessList rather than simply exporting a 1D- and/or 3D- LUT . For example, a common color space conversion should use discrete Log and Matrix nodes, where appropriate, rather than a single LUT3D .","title":"Discrete Operations"},{"location":"guides/clf/#precision-and-range-of-numeric-values","text":"Ensure your implementation writes a sufficient number of digits. Even though image processing will typically be done at 32-bit floating-point precision, intermediate calculations (for example, combining matrices) may be done at higher precision. Also, take note that the bit-depth attributes do not impose range or quantization limits. Hence you should not impose these limits unnecessarily. For example, for a LUT1D with an outBitDepth of 10i , the normal range would be expected to be 0 to 1023. However, it is legal to exceed this range and also to use fractional values. Thus, values such as [-10.5, 0.01, 1055.2] could be legal values. Please refer to Section 5.1 of the specification for more detail.","title":"Precision and Range of Numeric Values"},{"location":"guides/clf/#the-id-attribute","text":"Every CLF is required to have an id attribute at the ProcessList level. The specification does not impose any restrictions on the formatting of this attribute. However, it should be noted that an ACES Metadata File that references a CLF file prefers that the id attribute contains a UUID object according to RFC 4122. Therefore, it is recommended that implementations use a UUID to fill the id attribute when writing new CLF files. Note that the id attribute is optional at the ProcessNode level.","title":"The id Attribute"},{"location":"guides/clf/#storage-of-proprietary-metadata","text":"If an application wants to store \"dark metadata\" that is meaningful only for a special purpose within proprietary products or workflows, this is easily accomplished. Indeed this is one of the frequently cited benefits of the XML encoding. However, it is important that CLF writers are respectful of certain guidelines to ensure the CLF file remains usable by other readers. If you need to add proprietary metadata, please respect the following: Check the CLF spec to see if there is already an element whose purpose matches what you are trying to store. If not, you may create a custom XML element to store your metadata. As described in the spec, this should typically be placed within the Info block. You may add additional custom elements and attributes under your main element as needed in order to easily represent your information. Avoid using the standard existing elements such as Description in a way that is inconsistent with their purpose. Avoid placing custom elements at the ProcessNode level since that would make it an illegal file that most parsers will reject.","title":"Storage of Proprietary Metadata"},{"location":"guides/clf/#other-metadata-considerations","text":"Inaccurate metadata is worse than no metadata. Implementers should make it as regular and easy as possible for the user to set required CLF metadata when writing a file. Accurate metadata is critical for other users to be able to understand the intended usage of the CLF file, especially the Description , InputDescriptor , and OutputDescriptor tags. If known by the application, the application should fill in the InputDescriptor and OutputDescriptor tags automatically. At this time, no standard list of values (i.e., text strings) for color spaces or other common settings is defined. When writing a CLF to represent an ACES Look Transform, the CLF should adhere to the structure and metadata described in Annex F . If translating an ACES CTL (Color Transformation Language) file into CLF , set the ACESTransformID and ACESUserName (under the Info block of metadata) using the corresponding strings from the CTL header. [Examples 13] and [14] in [section 6] of the specification show CLFs using this feature.","title":"Other Metadata Considerations"},{"location":"guides/clf/#helpful-hints-for-a-successful-implementation","text":"","title":"Helpful Hints for a Successful Implementation"},{"location":"guides/clf/#matrix-order","text":"Take note that the order of coefficients in the Matrix ProcessNode follows the usual convention in color science but that this is the transposition of both the order sometimes used in computer graphics and the order used in CTL . [Section 4.4.4] of the specification clearly documents the ordering of matrix coefficients that must be used. Also, note that the 3x4 matrix includes an offset value after each of the three matrix values.","title":"Matrix Order"},{"location":"guides/clf/#lut3d-serialization-order","text":"As described in [Section 4.4.3] of the CLF Specification, take note that the LUT3D ProcessNode serializes the LUT entries in blue-fastest order. This is a commonly used ordering (for example it is used by the common .3dl format) but some other formats use red-fastest ordering (e.g., .cube format).","title":"LUT3D Serialization Order"},{"location":"guides/clf/#gamma-polarity","text":"As described in [Section 4.4.7] of the spec, take note that the Exponent ProcessNode uses the specified parameter directly in the power function for the forward direction. This is the same usage as in an ASC CDL power. But take care since often \"gamma\" operators in color processing software apply the inverse of the power for the forward direction.","title":"Gamma Polarity"},{"location":"guides/clf/#bit-depth-attributes-dont-affect-processing-precision","text":"As called out in the CLF specification, the inBitDepth and outBitDepth attributes of ProcessNodes are not intended to control the processing precision, which should normally be 32-bit floating-point. Rather, these attributes simply determine the scaling of various parameter values such as matrix and LUT entries. Please refer to section 5.1 of the [ CLF specification] for the details.","title":"Bit-Depth Attributes Don't Affect Processing Precision"},{"location":"guides/clf/#conversion-between-bit-depths","text":"When interpreting the inBitDepth and outBitDepth attributes, conversions happen using \"power of two minus 1\" scaling rather than \"power of 2\" scaling. Please refer to section 5.1.4 of the [ CLF Specification] for the details.","title":"Conversion Between Bit-Depths"},{"location":"guides/clf/#appendices","text":"","title":"Appendices"},{"location":"guides/clf/#annexA","text":"A 16-bit OpenEXR test image was designed with many ramps and other values which should be useful for testing any CLF and/or CLF implementation. The image includes: 33x33 cube spanning -1.0 to 1.0 33x33 cube spanning -65504 to 65504 an ACES2065-1 ColorChecker chart 0-1 grayscale ramps ColorChecker values and primaries/secondaries ramped in \u00bd stop increments a set of ramps designed to generate a spiderweb when viewed on a vectorscope extents lattice ramps designed to produce a bounding box around all possible normal positive and negative values when viewed in 3D Specific details for each of the image subsections can be found in the README at https://github.com/alexfry/CLFTestImage The test image (named CLF_Finishing_SourceImage_v008.exr ) is included along with the processed reference images in the download referenced in Annex C and D .","title":"Annex A: Test Image"},{"location":"guides/clf/#annexB","text":"These test files may be found in the OpenColorIO repository on GitHub: https://github.com/AcademySoftwareFoundation/OpenColorIO The files are in the sub-directory: OpenColorIO/tests/data/files/clf Note: Some of the test files intentionally use unusual or difficult syntax to give a thorough test for parsers. They are not all intended as \"best practice\" examples.","title":"Annex B: CLF Test Suite Listing"},{"location":"guides/clf/#annexC","text":"The list of CLF files for the Finishing Tier apply test is the complete list of legal files in Annex B . Processed reference images may be downloaded from here: CLF Apply Test Images","title":"Annex C: Finishing Tier Apply Test CLF List"},{"location":"guides/clf/#annexD","text":"The CLF file for the Preview Tier apply test is simply: lut3d_preview_tier_test.clf Processed reference images may be downloaded from here: CLF Apply Test Images","title":"Annex D: Preview Tier Apply Test CLF List"},{"location":"guides/clf/#annexE","text":"Because CLF allows a fairly powerful set of processing operators that may be assembled into pipelines of any ordering and any length, it will not be possible to exactly evaluate all CLFs on hardware or software that has a fixed processing pipeline. (In other words, the implementation must allow the CLF file itself to specify the pipeline of operators for a given color transform.) Converting color transforms into a simpler structure to make them simpler to evaluate is known as baking . This is often done to meet the needs of a particular hardware implementation. There are a number of factors that make the process of accurately baking color transforms a difficult and complicated subject: CLF is intended to support the needs of floating-point scene-linear color spaces and therefore the range of possible input and output values extends from very small to very large numbers (both positive and negative). A given CLF may expect virtually any color space (scene-linear, camera log, video, etc.) on input and another completely different space on output. The flexible nature of CLF and the way a chain of operators is built up makes it fairly easy for the function to have abrupt changes in slope. For example, at the edge of a gamut boundary, or due to a conversion into an internal working space for a look transform. These slope changes are usually not captured accurately when the transform is baked. The human visual system is often able to detect fairly small errors in color reproduction, particularly in dark colors. All of that said, there are many successful products that have used a baking process. For example, this technique is often used in products designed for on-set production monitoring involving look transforms. So it is highly likely that baking of CLFs could be a successful strategy for Preview Tier products. The key will be to clearly document the types of color transforms that may be successfully baked and those that the user should avoid. Integer-based implementations in the Preview Tier will typically be processing video or logarithmic color space encodings. So for example, if the documentation suggests avoiding use of CLFs expecting scene-linear color spaces on input, that is probably fine since (hopefully!) no one will be trying to send raw scene-linear values through an integer connection such as SDI video. The accuracy of the baking process may be judged by sending images through both the original CLF and the baked CLF and comparing them. OpenColorIO or any product that passes the Finishing Tier tests could be used for this type of comparison. But keep in mind that the result will depend on many factors, including the input and output color spaces and the internal structure of the original CLF . So even though one CLF may bake accurately through a given baking process, it certainly does not mean that all of them will. Testing with a range of user transforms is essential. OpenColorIO may be used to experiment with baking CLFs using the command-line tool ociobakelut . For example, here is a command that takes an original CLF named complicated.clf and bakes it into a single LUT3D with a cube dimension of 33x33x33 called simple.clf : $ ociobakelut --lut complicated.clf --cubesize 33 --format \"Academy/ASC Common LUT Format\" --v simple.clf You may edit the resulting CLF XML file in a text editor to add the interpolation=\"tetrahedral\" attribute to the LUT3D and any desired metadata. For CLFs that convert from one perceptually uniform color space to another (i.e., between most logarithmic and video color spaces), this will often be reasonably accurate for Preview Tier devices. Increasing the cube size will improve accuracy (the default cubesize is 64x64x64). However, this would not work well for baking a CLF that expects a scene-linear color space on input. In those situations, the usual technique is to add some kind of a \"shaper\" LUT1D or other non-linear transform in front of the LUT3D that will convert the linear values into something more perceptually uniform. A more modern and compact technique that takes advantage of the CLF capabilities would be to insert a Log ProcessNode rather than a LUT1D , but the most appropriate technique would be based on the needs of the given implementation. The ociobakelut tool is able to bake with shaper LUTs , but it requires an OCIO config file to define the input, output, and shaper spaces. But for the use-case here, the input is just a single CLF file, so there is no OCIO config file to use. OpenColorIO could still be used to do these more advanced types of baking, but it would require some scripting. One approach would be to create a config file that references the original CLF as a file transform and includes an appropriate shaper space. Another approach would be to just use the OCIO API directly to write your own baking tool, using the ociobakelut code for inspiration. (And if so, we encourage you to contribute it back to the OCIO project!) The ociobakelut command supports many arguments; use the -h argument for a summary. For example, note that you may supply many --lut arguments on the command line and they will all be baked together into the result. You may also consult the Baking LUT \u2019s section of the OCIO documentation for a tutorial on using ociobakelut .","title":"Annex E: Baking a CLF for Preview Tier Implementation"},{"location":"guides/clf/#annexF","text":"Historically, look workflows have been based on applying a look in some kind of logarithmic color space, for example, a camera log space. This is partly because the existing infrastructure was built for integer pixel formats and did not support floating-point pixel formats. (The Preview Tier described above is an attempt to define requirements for these integer-based devices.) And until CLF , previous LUT formats did not support scene-linear color spaces well. However, the input values and output values of ACES Look Transforms (also known as \"LMTs\") must be ACES2065-1. This is to maintain universality of Look Transforms and not link them to project-specific working spaces. Look Transforms may then convert ACES2065-1 to some other working space internally (e.g., a camera log space) for look application. This is the vision for the future and the ACES Metadata File ( AMF ) format expects implementations to work this way. As an aside, it is recommended that the InputDescriptor and OutputDescriptor be set to ACES2065-1 when authoring Look Transforms as CLFs so it is always clear what the expected input and output color spaces are. The Description tag and other metadata may also be used to provide a more complete description of the look. When look operations are to be performed in a working space other than ACES2065-1, then appropriate conversions to and from the required working space can be prepended and appended within a CLF to communicate the transform. For accuracy, whenever possible, these conversions should be implemented using discrete operations such as Log and Matrix ProcessNodes rather than LUT1D or LUT3D . By using ProcessNodes such as Log and Matrix , a CLF author makes it easier for an implementation to detect and remove any unnecessary conversions when applying the CLF . For example, OpenColorIO will do this when optimizing transform chains. The OCIO tool ociomakeclf can create an ACES Look Transform by prepending and appending the appropriate color space conversions to an existing look LUT file. For example, if an existing look LUT expects ACEScct input and outputs ACEScct, the --csc ACEScct option will add appropriate conversions from ACES2065-1 to ACEScct at the beginning and from ACEScct back to ACES2065-1 at the end. Example: Convert the look CDL cdl_test2.cc that expects and produces ACEScct values to an ACES Look Transform in CLF format that expects and produces ACES2065-1 values: $ ociomakeclf OpenColorIO/tests/data/files/cdl_test2.cc LMT.clf --csc ACEScct This generates the following CLF : <?xml version=\"1.0\" encoding=\"UTF-8\"?> <ProcessList compCLFversion= \"3\" id= \"669980ac1ecd97ab18c1707250a13d20\" > <!-- Header metadata --> <Description> ACES LMT transform built from a look LUT expecting color space: ACEScct </Description> <Description> Original LUT name: OpenColorIO/tests/data/files/cdl_test2.cc </Description> <InputDescriptor> ACES2065-1 </InputDescriptor> <OutputDescriptor> ACES2065-1 </OutputDescriptor> <!-- Convert from ACES2065-1 to ACEScct --> <Matrix inBitDepth= \"32f\" outBitDepth= \"32f\" > <Array dim= \"3 3\" > 1.45143931614567 -0.23651074689374 -0.214928569251925 -0.0765537733960206 1.17622969983357 -0.0996759264375522 0.00831614842569772 -0.00603244979102103 0.997716301365323 </Array> </Matrix> <Log inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"cameraLinToLog\" > <LogParams base= \"2\" linSideSlope= \"1\" linSideOffset= \"0\" logSideSlope= \"0.0570776255707763\" logSideOffset= \"0.554794520547945\" linSideBreak= \"0.0078125\" /> </Log> <!-- Apply the user's CDL look in the ACEScct working space --> <ASC_CDL id= \"cc0001\" inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"FwdNoClamp\" > <SOPNode> <Slope> 1.0 1.0 0.9 </Slope> <Offset> -0.03 -0.02 0.0 </Offset> <Power> 1.25 1.0 1.0 </Power> </SOPNode> <SatNode> <Saturation> 1.7 </Saturation> </SatNode> </ASC_CDL> <!-- Convert from ACEScct back to ACES2065-1 --> <Log inBitDepth= \"32f\" outBitDepth= \"32f\" style= \"cameraLogToLin\" > <LogParams base= \"2\" linSideSlope= \"1\" linSideOffset= \"0\" logSideSlope= \"0.0570776255707763\" logSideOffset= \"0.554794520547945\" linSideBreak= \"0.0078125\" /> </Log> <Matrix inBitDepth= \"32f\" outBitDepth= \"32f\" > <Array dim= \"3 3\" > 0.695452241357452 0.140678696470294 0.163869062172254 0.0447945633720377 0.859671118456422 0.0955343181715404 -0.00552588255811354 0.00402521030597866 1.00150067225213 </Array> </Matrix> </ProcessList> Note that an ACES Look Transform is usually just one component in a larger pipeline of transforms. For example, Preview Tier implementations involving on-set LUT boxes will typically incorporate the Look Transform into a chain of transforms that expect a camera log color space on input and produce a video color space on output. As noted above, the use of explicit Log and Matrix ProcessNodes in a CLF transform allows an implementation to detect unnecessary operations. For example, if an ACES Input Transform were added in front of an ACES Look Transform that begins with the inverse of that Input Transform, the redundant operations could be optimized out for efficiency. Though in some implementations, this will all be baked into a single LUT3D , making such optimizations less necessary.","title":"Annex F: Using CLF to represent ACES Look Transforms"},{"location":"guides/clf/#annexG","text":"The ACES Metadata File ( AMF ) is a \"sidecar\" XML file designed to encapsulate the metadata required to recreate ACES viewing pipelines. An AMF can carry references to one or more CLF files as external ACES Look Transform files. When using a CLF file for ACES applications and especially when in conjunction with AMF , it is recommended that the CLF id attribute of the ProcessList be populated with a uuid . Multiple CLFs can be included by using multiple lookTransform elements in the AMF file. The CLFs are applied in the order in which they appear in the AMF . See the AMF Handbook for more details.","title":"Annex G: Using CLF with AMF"},{"location":"guides/clf/#annexH","text":"To avoid doubt in cases where CLF files are exchanged as \u201csidecar\u201d files to batches of media, it may be desirable to use a standard CLF form even when no transform or color modification has been assigned to certain media clips / files. In these cases it may be useful that a \u201cNo-Op\u201d CLF file be included as the associated sidecar file to communicate to downstream users that no transform is assigned. This may be preferred to not providing a sidecar CLF file, as the absence of CLF files for a subset of a larger media batch often raises questions in certain workflows about whether an expected file is missing. For this situation, implementers may generate a minimal CLF file like that shown below, where the ProcessList has a single ProcessNode of the Matrix type with a 3x3 identity matrix. (Implementers do not need to copy this exactly, for example there are other operators that also give an identity and details like the id string will differ.) <?xml version=\"1.0\" encoding=\"UTF-8\"?> <ProcessList id= \"37efa85b-5bc8-40dc-8ffe-b488a3c013ea\" name= \"No-Op\" compCLFversion= \"3.0\" > <Description> No-Op CLF </Description> <Matrix name= \"identity matrix\" inBitDepth= \"32f\" outBitDepth= \"32f\" > <Array dim= \"3 3\" > 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 </Array> </Matrix> </ProcessList>","title":"Annex H: Identity (no-op) CLF example"},{"location":"guides/clf/#annexI","text":"The CLFs used for the apply tests were specially chosen to avoid floating-point overflows that could turn pixels in the test target image into infinity or NaN. However, with other CLFs, the comparison script described in the other sections may fail if the resulting images have infinity or NaN pixels. The handling of infinity and NaN is challenging in a number of regards. For example: There is not always consensus on what the ideal behavior is. For example, should overflows be clamped to a large finite value or allowed to produce an infinity. There are sometimes performance penalties to be extra rigorous about the handling which are not always warranted. The handling on GPUs tends to vary a lot and often does not match the CPU (where there are clearer specs for what is supposed to happen). Once these values get into a chain of color processing, there can be somewhat unexpected results. For example, (Inf \u2013 Inf) is NaN, likewise, (0 x Inf) is NaN, so quite often an infinity going into a matrix or other operator that mixes the channels results in NaNs coming out. Due to issues such as these, neither the Academy reference CTL for ACES transforms nor OpenColorIO have ideal behavior with respect to the handling of floating-point infinity and NaN. We expect this is true of most other practical implementations and so this initial version of the Implementation Guide does not attempt to validate handling of these values.","title":"Annex I: Infinity and NaN handling"},{"location":"guides/clf/#annexJ","text":"Here is some Python code that uses OCIO to create the test LUT for the Preview Tier. # This script builds the file for the Preview Tier test from the CLF test suite. import PyOpenColorIO as ocio import numpy as np v = np . linspace ( 0 , 1 , 33 ) # v = # array([ 0. , 0.03125, 0.0625 , 0.09375, 0.125 , 0.15625, # 0.1875 , 0.21875, 0.25 , 0.28125, 0.3125 , 0.34375, # 0.375 , 0.40625, 0.4375 , 0.46875, 0.5 , 0.53125, # 0.5625 , 0.59375, 0.625 , 0.65625, 0.6875 , 0.71875, # 0.75 , 0.78125, 0.8125 , 0.84375, 0.875 , 0.90625, # 0.9375 , 0.96875, 1. ]) # Convert the vector into the values for a Lut3D. Uses blue-fastest order. a1 , a2 , a3 = np . meshgrid ( v , v , v ) gr = np . column_stack (( a2 . ravel (), a1 . ravel (), a3 . ravel ())) # At this point, gr is a 35937 x 3 array with min=0 and max=1. # Build transforms to convert from ACEScct to Rec.709 using an ACES Output Transform. bt1 = ocio . BuiltinTransform ( style = 'ACEScct_to_ACES2065-1' ) bt2 = ocio . BuiltinTransform ( style = 'ACES-OUTPUT - ACES2065-1_to_CIE-XYZ-D65 - SDR-VIDEO_1.0' ) bt3 = ocio . BuiltinTransform ( style = 'DISPLAY - CIE-XYZ-D65_to_REC.1886-REC.709' ) dvt = ocio . GroupTransform ( [ bt1 , bt2 , bt3 ] ) # Set up an OCIO Processor and process the values. config = ocio . Config . CreateRaw () proc = config . getProcessor ( dvt ) cpu = proc . getDefaultCPUProcessor () tmp = gr . astype ( np . float32 ) cpu . applyRGB ( tmp ) # replaces tmp with output # For this example, the goal was to quantize to 10-bits and clamp to [4,1019] # since hardware involving SDI video may not be able to process these values. vals = np . round ( tmp * 1023 ) # vals[0:10,:] = # array([[ 0., 0., 0.], # [ 0., 0., 0.], # [ 0., 0., 0.], # [ 0., 0., 0.], # [ 0., 0., 35.], # [ 0., 0., 52.], # [ 0., 0., 68.], # [ 0., 0., 88.], # [ 0., 0., 114.], # [ 0., 0., 148.]], dtype=float32) vals2 = vals . clip ( 4 , 1019 ) # Now renormalize to [0,1], vectorize, and set the data into a Lut3D. vals2 = vals2 / 1023. lut = ocio . Lut3DTransform () lut . setData ( vals2 . ravel ()) # Set some LUT attributes. lut . setFileOutputBitDepth ( ocio . BIT_DEPTH_UINT10 ) lut . setInterpolation ( ocio . INTERP_TETRAHEDRAL ) fmd = lut . getFormatMetadata () fmd . addChildElement ( 'Description' , 'This LUT is an ACEScct to Rec.709 Output Transform, clamped to [4,1019]' ) # print(lut) # <Lut3DTransform direction=forward, fileoutdepth=10ui, interpolation=tetrahedral, # gridSize=33, minrgb=[0.00391007 0.00391007 0.00391007], maxrgb=[0.99609 0.99609 # 0.99609]> # Add the LUT to a GroupTransform, set the metadata and write. grp = ocio . GroupTransform () grp . appendTransform ( lut ) fmdg = grp . getFormatMetadata () fmdg . setID ( '00001' ) fmdg . setName ( 'Preview-tier Lut3D test' ) fmdg . addChildElement ( 'Description' , 'Test LUT for Preview-tier CLF validation test suite' ) fmdg . addChildElement ( 'InputDescriptor' , 'ACEScct' ) fmdg . addChildElement ( 'OutputDescriptor' , 'Rec.1886 / Rec.709 video' ) # print(grp) # <GroupTransform direction=forward, transforms= # <Lut3DTransform direction=forward, fileoutdepth=10ui, interpolation=tetrahedral, # gridSize=33, minrgb=[0.00391007 0.00391007 0.00391007], # maxrgb=[0.99609 0.99609 0.99609]>> grp . write ( formatName = 'Academy/ASC Common LUT Format' , config = config , fileName = '/tmp/lut3d_preview_tier_test.clf' )","title":"Annex J: Python code for creating the Preview Tier test LUT"},{"location":"guides/clf/#annexK","text":"The processed reference images may be downloaded from the URL provided in Annex C and D above. This section documents how those images were generated.","title":"Annex K: Generation of the reference images"},{"location":"guides/rgc-user/","text":"ACES Reference Gamut Compression User Guide \u00b6 Scope \u00b6 The purpose of this document is to elaborate on suggested user workflows for on set, dailies, visual effects, and finishing using the ACES Reference Gamut Compression ( RGC ). For detailed technical specifications, please refer to the ACES Gamut Mapping Architecture VWG - Technical Documentation. References \u00b6 The following standards, specifications, articles, presentations, and texts are referenced in this text: ACES Gamut Mapping Architecture VWG - Technical Documentation Deliverable Introduction \u00b6 A common complaint from users of ACES has been the artifacts resulting from out of gamut values in source images. These artifacts are most known for appearing in highly saturated, bright LED light sources such as police car lights, stoplights, etc - but also show up frequently in LED sources used to light scenes. In an ACES workflow, these artifacts appear at two stages - first in the conversion from camera raw RGB via an Input Transform ( IDT ) into ACES AP0 - and second in the conversion from ACES AP0 into ACES AP1 (ACEScg and ACEScct). These out of gamut pixel values are problematic when their negative components cause issues in compositing, and may also produce visual artifacts when viewed through an ACES Output Transform. A Look Modification Transform ( LMT ) referred to as the blue light artifact fix was created as a temporary solution, but this solution affected all pixels in the image, rather than just the problem areas. A new solution was needed which preserved colors within a \u201czone of trust\u201d, only altering the most saturated values. The Reference Gamut Compression algorithm published in ACES 1.3 is intended to replace and deprecate the Blue Light Artifact LMT . Various options were investigated, and the working group finally settled on a simple RGB ratio based algorithm which compresses values based on their distance from the neutral axis. This makes no attempt to ascertain the \u201ccorrect\u201d value for a pixel, since the nature of the problem means that these pixels may have no correct color. The algorithm is intended as a technical correction rather than an aesthetic look. It \u201cheals\u201d the problem pixels, to produce new RGB values which are less problematic when used in subsequent compositing or grading operations. Creative modifications are left for the user to apply as necessary downstream of the RGC . The ACES Reference Gamut Compression uses fixed values 1 for the thresholds where compression begins, and for the amount of compression. These values have been calculated such that the colors of the ColorChecker 24 will remain unchanged, and that any colors that are within the encoding gamuts of all the commonly used digital cinema cameras (those with official ACES IDTs) will be brought within AP1, thus ensuring positive ACEScg values. In most workflows, these constants will be invisible to the user, as demonstrated in the screenshots from Resolve 17.4 below - the user has the option to apply the RGC at a project or a clip level. Reference Gamut Compression enabled via Project Settings in DaVinci Resolve 17.4 Reference Gamut Compression individual clip settings in DaVinci Resolve 17.4 In the example below, artifacts such as the magenta solarization seen on the nose of the Okja toy are greatly reduced by application of the RGC . Without the RGC With the RGC applied Though the algorithm itself and application to an image is relatively simple, there are many considerations to discuss for overall workflows for an ACES project, from on set through to finishing. General Workflow \u00b6 As visualized in the flowchart above, it is recommended (in the current absence of AMF for tracking) that most productions utilize the gamut compression in every area - from on set all the way to finishing. This means that at this time, for simplicity, the the RGC is \u201calways on\u201d by default in any viewing pipeline. Following the general ACES workflow philosophy, the RGC is only baked in to image data at the appropriate stage in the pipeline - which varies based on the needs of your production, as outlined in the flow chart and explained below. On Set \u00b6 Live Grading \u00b6 If your production is utilizing an on set grading software, such as Pomfort Livegrade, use it to apply the Reference Gamut Compression. This will embed the RGC in the 3D LUT which is passed to the LUT box for viewing on a monitor. In-Camera \u00b6 The production can create a 3D LUT of the appropriate size (normally 33x33x33 max) with the Reference Gamut Compression added to the existing viewing pipeline to load into the camera. Dailies \u00b6 Use a dailies generation software, such as Colorfront or Resolve, to import the original camera footage, and apply the Reference Gamut Compression as a part of your viewing pipeline for export to desired media. Editorial \u00b6 Use media supplied from dailies, and back from VFX , to verify media as work progresses. As editorial is largely offline and based on proxy media, the RGC , as viewed on set, should be baked into the files sent to editorial. VFX \u00b6 Frame pulls for VFX should NOT have the Reference Gamut Compression baked in. The files should be debayered to AP0. VFX will have the flexibility to apply the RGC wherever is best for their compositing chain. This will often be the first node in the tree, but sometimes operations such as a despill on a bluescreen will need to be performed pre-gamut compression. Sending pulls to VFX in AP0 gives compositors the flexibility to fine tune and control their work. Once applied, the Reference Gamut compression should NOT be inverted before delivery. It is important that the RGC get applied to all WIP QT renders for review and editorial, so as to match dailies. Finishing \u00b6 Finishing software should have the ability to apply the RGC at a project, timeline, or clip level. This should give the colorist flexibility to choose what works best for the project. The RGC should be applied directly after the IDT , ideally before any scaling, grading, or other finishing work. In a pre-conformed timeline, apply the RGC as early as possible. If frames are coming back from VFX , it will be important to track those vs. non- VFX shots, so that the gamut compression is not applied twice. Production Realities \u00b6 Order of Operations \u00b6 The order in which the various operations are applied to an image has a significant impact on the end result. In particular, any scaling will produce a different result depending on whether it is done before or after the RGC , since its removal of negative values can reduce some scaling artifacts. Some applications may give the user detailed control over order of operations, but in others the underlying processes are hidden. This is an important consideration when planning workflows. In compositing in particular, there may be operations (edge despill in keying has been noted) where using the unmodified pixel values gives a preferable result. In these cases it may be necessary for the compositor to have access to both the original and gamut compressed image data in their node tree, choosing between them as necessary. For consistency, the RGC should still be applied at some other suitable point in the composite, such that the final renders delivered to DI still have the gamut compression applied as expected. Since normal practice in VFX is to return images with any pixel not touched by the compositing process unmodified from the original pulls, one might think that the RGC should be inverted for deliverables, as is done with CDL corrections, for example. However, it is better to think of the RGC more like a spill suppression, which is part of the composite, and would not be inverted out at the end. Inverting creates the possibility that elements added during compositing (CGI originally created in ACEScg, for example) which have not had the RGC applied may produce extreme values on inversion. An inverse mode is included in the algorithm, but is provided only for edge cases where it proves unavoidable. Some education of the various stakeholders may be required to establish why inverting is not preferable. Tracking \u00b6 In the long term, the expectation is that application of the RGC will be tracked using AMF (the ACES Metadata File). This will enable selective use of the algorithm, rather than the currently recommended default of \u201calways on\u201d. Since AMF is currently in development by the various software vendors, this will not be practical until AMF is widely implemented. Unless AMF can be relied upon to be correctly read and updated at every stage of the process, it will be of little use \u2013 incorrect metadata is worse that no metadata. The RGC is classed as an LMT (Look Modification Transform). But unlike most LMTs, it is applied first, immediately after the IDT , rather than last, just before the Output Transform. AMF can list multiple LMTs in its specification of the viewing pipeline for a shot, so will include one for the RGC as well as optionally one for a scene/show look. Compositing and grading work will be done between these two LMTs. LMT elements in an AMF include an applied attribute, so a shot which was previously viewed (e.g. on set) with the RGC enabled will include an LMT for the RGC , with the applied attribute set to false . If the shot is then passed through VFX , and the RGC is then baked in, the applied attribute should be set to true in the AMF returned with the shot to finishing. This will enable the finishing system to automatically apply the RGC to original footage, but disable it for shots from VFX . In the short term, manual tracking will be needed. This is the reason for the recommendation to have the RGC always enabled in the viewing pipeline (and therefore baked into any media which includes the Output Transform). A slight complexity is introduced by the requirement to apply the RGC before compositing work, and therefore bake it into any VFX renders. This means it is necessary for anybody working with a shot which has passed through VFX (including both colorists and VFX artists adding a secondary compositing pass) to take account of the fact that the RGC is already baked in, and not apply it a second time. Until AMF automates this process, careful communication, and agreement upon standard practices will be required. Please note that the workflows outlined in this guide are recommendations, but the needs may vary by facility and production. 3D LUT Implementation \u00b6 While it is generally recommended to use full precision CPU/GPU implementations of the ACES RGC transform some use cases may still require a 3D LUT based implementation instead. Examples for this include (but are not limited to): On-set monitoring of live camera feeds Implementations using legacy versions of OpenColorIO (v2.0 or earlier) Other DCC applications that do not yet support ACES v1.3 The two main considerations for a 3D LUT implementation of the ACES RGC are the LUT input color space and the transform precision. LUT Input Color Space: \u00b6 3D LUT input domains are usually in a 0.0 to 1.0 range (or equivalent integer ranges). Since out-of-gamut color samples have component values below zero an appropriate LUT input color space must be used in which all expected color samples map into the 0.0 to 1.0 range. For on-set monitoring, where the input gamut is known and fixed, such an input color space could be the camera\u2019s specific log-encoding (e.g. LogC3/ARRIWideGamut, Log3G10/REDWideGamutRGB). These encodings are optimized for the particular camera model and are expected to map all color samples into the 0.0\u21921.0 domain. Please note that ACEScct does not fulfill this requirement, even if it is available as a camera RAW development target, and is therefore not recommended to be used as an input encoding for a 3D LUT implementation of the RGC . So for visual effects, review or mastering applications that have to account for multiple input gamuts and are not able to rely on a specific camera vendor encoding an analytic implementation is required. LUT Precision: \u00b6 To achieve a reasonable approximation of the ACES RGC transform a 3D LUT implementation should use the highest practical resolution (e.g. 65x65x65) as well as tetrahedral interpolation. However, even with high resolution LUTs , the residual interpolation errors are significant enough to prevent accurate inversion of the transform, especially at the gamut boundaries. Therefore 3D LUT implementations of the RGC should be considered non-invertible. Implementation Guide \u00b6 If you are a software developer or engineer looking for technical implementation guidelines for integrating the ACES Reference Gamut Compression in software, please see our Implementation Guide . Appendix \u00b6 Before and after images, viewed through the Rec. 709 Output Transform @import \"../../stylesheets/sections.css\" Some implementations may also include a parametric version of the ACES gamut compression. If you choose to use this, it falls outside the scope of published ACES workflows, and therefore will need to be tracked manually. At that point it is simply another creative tool in the colorist\u2019s arsenal. \u21a9","title":"Reference Gamut Compression (RGC) User Guide"},{"location":"guides/rgc-user/#aces-reference-gamut-compression-user-guide","text":"","title":"ACES Reference Gamut Compression User Guide"},{"location":"guides/rgc-user/#scope","text":"The purpose of this document is to elaborate on suggested user workflows for on set, dailies, visual effects, and finishing using the ACES Reference Gamut Compression ( RGC ). For detailed technical specifications, please refer to the ACES Gamut Mapping Architecture VWG - Technical Documentation.","title":"Scope"},{"location":"guides/rgc-user/#references","text":"The following standards, specifications, articles, presentations, and texts are referenced in this text: ACES Gamut Mapping Architecture VWG - Technical Documentation Deliverable","title":"References"},{"location":"guides/rgc-user/#introduction","text":"A common complaint from users of ACES has been the artifacts resulting from out of gamut values in source images. These artifacts are most known for appearing in highly saturated, bright LED light sources such as police car lights, stoplights, etc - but also show up frequently in LED sources used to light scenes. In an ACES workflow, these artifacts appear at two stages - first in the conversion from camera raw RGB via an Input Transform ( IDT ) into ACES AP0 - and second in the conversion from ACES AP0 into ACES AP1 (ACEScg and ACEScct). These out of gamut pixel values are problematic when their negative components cause issues in compositing, and may also produce visual artifacts when viewed through an ACES Output Transform. A Look Modification Transform ( LMT ) referred to as the blue light artifact fix was created as a temporary solution, but this solution affected all pixels in the image, rather than just the problem areas. A new solution was needed which preserved colors within a \u201czone of trust\u201d, only altering the most saturated values. The Reference Gamut Compression algorithm published in ACES 1.3 is intended to replace and deprecate the Blue Light Artifact LMT . Various options were investigated, and the working group finally settled on a simple RGB ratio based algorithm which compresses values based on their distance from the neutral axis. This makes no attempt to ascertain the \u201ccorrect\u201d value for a pixel, since the nature of the problem means that these pixels may have no correct color. The algorithm is intended as a technical correction rather than an aesthetic look. It \u201cheals\u201d the problem pixels, to produce new RGB values which are less problematic when used in subsequent compositing or grading operations. Creative modifications are left for the user to apply as necessary downstream of the RGC . The ACES Reference Gamut Compression uses fixed values 1 for the thresholds where compression begins, and for the amount of compression. These values have been calculated such that the colors of the ColorChecker 24 will remain unchanged, and that any colors that are within the encoding gamuts of all the commonly used digital cinema cameras (those with official ACES IDTs) will be brought within AP1, thus ensuring positive ACEScg values. In most workflows, these constants will be invisible to the user, as demonstrated in the screenshots from Resolve 17.4 below - the user has the option to apply the RGC at a project or a clip level. Reference Gamut Compression enabled via Project Settings in DaVinci Resolve 17.4 Reference Gamut Compression individual clip settings in DaVinci Resolve 17.4 In the example below, artifacts such as the magenta solarization seen on the nose of the Okja toy are greatly reduced by application of the RGC . Without the RGC With the RGC applied Though the algorithm itself and application to an image is relatively simple, there are many considerations to discuss for overall workflows for an ACES project, from on set through to finishing.","title":"Introduction"},{"location":"guides/rgc-user/#general-workflow","text":"As visualized in the flowchart above, it is recommended (in the current absence of AMF for tracking) that most productions utilize the gamut compression in every area - from on set all the way to finishing. This means that at this time, for simplicity, the the RGC is \u201calways on\u201d by default in any viewing pipeline. Following the general ACES workflow philosophy, the RGC is only baked in to image data at the appropriate stage in the pipeline - which varies based on the needs of your production, as outlined in the flow chart and explained below.","title":"General Workflow"},{"location":"guides/rgc-user/#on-set","text":"","title":"On Set"},{"location":"guides/rgc-user/#dailies","text":"Use a dailies generation software, such as Colorfront or Resolve, to import the original camera footage, and apply the Reference Gamut Compression as a part of your viewing pipeline for export to desired media.","title":"Dailies"},{"location":"guides/rgc-user/#editorial","text":"Use media supplied from dailies, and back from VFX , to verify media as work progresses. As editorial is largely offline and based on proxy media, the RGC , as viewed on set, should be baked into the files sent to editorial.","title":"Editorial"},{"location":"guides/rgc-user/#vfx","text":"Frame pulls for VFX should NOT have the Reference Gamut Compression baked in. The files should be debayered to AP0. VFX will have the flexibility to apply the RGC wherever is best for their compositing chain. This will often be the first node in the tree, but sometimes operations such as a despill on a bluescreen will need to be performed pre-gamut compression. Sending pulls to VFX in AP0 gives compositors the flexibility to fine tune and control their work. Once applied, the Reference Gamut compression should NOT be inverted before delivery. It is important that the RGC get applied to all WIP QT renders for review and editorial, so as to match dailies.","title":"VFX"},{"location":"guides/rgc-user/#finishing","text":"Finishing software should have the ability to apply the RGC at a project, timeline, or clip level. This should give the colorist flexibility to choose what works best for the project. The RGC should be applied directly after the IDT , ideally before any scaling, grading, or other finishing work. In a pre-conformed timeline, apply the RGC as early as possible. If frames are coming back from VFX , it will be important to track those vs. non- VFX shots, so that the gamut compression is not applied twice.","title":"Finishing"},{"location":"guides/rgc-user/#production-realities","text":"","title":"Production Realities"},{"location":"guides/rgc-user/#order-of-operations","text":"The order in which the various operations are applied to an image has a significant impact on the end result. In particular, any scaling will produce a different result depending on whether it is done before or after the RGC , since its removal of negative values can reduce some scaling artifacts. Some applications may give the user detailed control over order of operations, but in others the underlying processes are hidden. This is an important consideration when planning workflows. In compositing in particular, there may be operations (edge despill in keying has been noted) where using the unmodified pixel values gives a preferable result. In these cases it may be necessary for the compositor to have access to both the original and gamut compressed image data in their node tree, choosing between them as necessary. For consistency, the RGC should still be applied at some other suitable point in the composite, such that the final renders delivered to DI still have the gamut compression applied as expected. Since normal practice in VFX is to return images with any pixel not touched by the compositing process unmodified from the original pulls, one might think that the RGC should be inverted for deliverables, as is done with CDL corrections, for example. However, it is better to think of the RGC more like a spill suppression, which is part of the composite, and would not be inverted out at the end. Inverting creates the possibility that elements added during compositing (CGI originally created in ACEScg, for example) which have not had the RGC applied may produce extreme values on inversion. An inverse mode is included in the algorithm, but is provided only for edge cases where it proves unavoidable. Some education of the various stakeholders may be required to establish why inverting is not preferable.","title":"Order of Operations"},{"location":"guides/rgc-user/#tracking","text":"In the long term, the expectation is that application of the RGC will be tracked using AMF (the ACES Metadata File). This will enable selective use of the algorithm, rather than the currently recommended default of \u201calways on\u201d. Since AMF is currently in development by the various software vendors, this will not be practical until AMF is widely implemented. Unless AMF can be relied upon to be correctly read and updated at every stage of the process, it will be of little use \u2013 incorrect metadata is worse that no metadata. The RGC is classed as an LMT (Look Modification Transform). But unlike most LMTs, it is applied first, immediately after the IDT , rather than last, just before the Output Transform. AMF can list multiple LMTs in its specification of the viewing pipeline for a shot, so will include one for the RGC as well as optionally one for a scene/show look. Compositing and grading work will be done between these two LMTs. LMT elements in an AMF include an applied attribute, so a shot which was previously viewed (e.g. on set) with the RGC enabled will include an LMT for the RGC , with the applied attribute set to false . If the shot is then passed through VFX , and the RGC is then baked in, the applied attribute should be set to true in the AMF returned with the shot to finishing. This will enable the finishing system to automatically apply the RGC to original footage, but disable it for shots from VFX . In the short term, manual tracking will be needed. This is the reason for the recommendation to have the RGC always enabled in the viewing pipeline (and therefore baked into any media which includes the Output Transform). A slight complexity is introduced by the requirement to apply the RGC before compositing work, and therefore bake it into any VFX renders. This means it is necessary for anybody working with a shot which has passed through VFX (including both colorists and VFX artists adding a secondary compositing pass) to take account of the fact that the RGC is already baked in, and not apply it a second time. Until AMF automates this process, careful communication, and agreement upon standard practices will be required. Please note that the workflows outlined in this guide are recommendations, but the needs may vary by facility and production.","title":"Tracking"},{"location":"guides/rgc-user/#3d-lut-implementation","text":"While it is generally recommended to use full precision CPU/GPU implementations of the ACES RGC transform some use cases may still require a 3D LUT based implementation instead. Examples for this include (but are not limited to): On-set monitoring of live camera feeds Implementations using legacy versions of OpenColorIO (v2.0 or earlier) Other DCC applications that do not yet support ACES v1.3 The two main considerations for a 3D LUT implementation of the ACES RGC are the LUT input color space and the transform precision.","title":"3D LUT Implementation"},{"location":"guides/rgc-user/#implementation-guide","text":"If you are a software developer or engineer looking for technical implementation guidelines for integrating the ACES Reference Gamut Compression in software, please see our Implementation Guide .","title":"Implementation Guide"},{"location":"guides/rgc-user/#appendix","text":"Before and after images, viewed through the Rec. 709 Output Transform @import \"../../stylesheets/sections.css\" Some implementations may also include a parametric version of the ACES gamut compression. If you choose to use this, it falls outside the scope of published ACES workflows, and therefore will need to be tracked manually. At that point it is simply another creative tool in the colorist\u2019s arsenal. \u21a9","title":"Appendix"}]}